{"version":3,"file":"\\packages\\mongo-livedata.js","sources":["mongo-livedata/mongo_driver.js","mongo-livedata/oplog_tailing.js","mongo-livedata/observe_multiplex.js","mongo-livedata/doc_fetcher.js","mongo-livedata/polling_observe_driver.js","mongo-livedata/oplog_observe_driver.js","mongo-livedata/local_collection_driver.js","mongo-livedata/remote_collection_driver.js","mongo-livedata/collection.js"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA,G;AACA,+D;AACA,qE;AACA,qB;AACA,E;AACA,uE;AACA,8C;AACA,G;;AAEA,+B;AACA,qC;AACA,kC;AACA,wD;;AAEA,oB;AACA,e;;AAEA,8E;AACA,sE;AACA,6C;AACA,kC;AACA,2B;AACA,8D;AACA,K;AACA,iB;AACA,yC;AACA,qD;AACA,O;AACA,e;AACA,G;AACA,e;AACA,E;;AAEA,4E;AACA,6B;AACA,2E;AACA,iD;AACA,oC;AACA,c;AACA,E;;AAEA,gE;AACA,kE;;AAEA,sD;AACA,2C;AACA,sC;AACA,kC;AACA,G;AACA,6C;AACA,kE;AACA,G;AACA,uD;AACA,kC;AACA,yE;AACA,G;AACA,8C;AACA,gF;AACA,4E;AACA,gF;AACA,+C;AACA,oB;AACA,G;AACA,mB;AACA,E;;AAEA,sD;AACA,iC;AACA,qE;AACA,+E;AACA,+B;AACA,oD;AACA,G;AACA,uD;AACA,wD;AACA,G;AACA,8C;AACA,gF;AACA,4E;AACA,gF;AACA,+C;AACA,oB;AACA,G;AACA,sC;AACA,qE;AACA,G;AACA,uE;AACA,4E;AACA,mB;AACA,E;;AAEA,yD;AACA,wD;AACA,oB;;AAEA,uD;AACA,yC;AACA,gC;;AAEA,qB;AACA,wC;AACA,yD;AACA,8B;AACA,kC;AACA,2B;AACA,gC;AACA,6B;AACA,K;AACA,K;AACA,a;AACA,E;;;AAGA,2C;AACA,kB;AACA,0B;AACA,8B;AACA,iC;AACA,kC;;AAEA,iE;;AAEA,qE;AACA,uE;AACA,sD;AACA,gD;AACA,8C;AACA,G;;AAEA,sE;AACA,sB;AACA,iE;AACA,oE;AACA,iB;AACA,wE;AACA,2C;AACA,kE;AACA,+C;AACA,0C;AACA,G;;AAEA,6E;AACA,4B;AACA,mC;AACA,6E;AACA,2E;AACA,oD;AACA,qD;AACA,G;;AAEA,+E;AACA,Y;AACA,gB;AACA,iB;AACA,gF;AACA,2E;AACA,yD;AACA,yB;AACA,6D;AACA,2C;AACA,8D;AACA,4B;AACA,6D;AACA,iC;AACA,8C;AACA,wC;AACA,2D;AACA,yB;AACA,0B;AACA,e;AACA,W;AACA,8C;AACA,yE;AACA,+E;AACA,gF;AACA,yE;AACA,+C;AACA,+B;AACA,S;AACA,Q;;AAEA,uC;AACA,iD;AACA,Y;AACA,O;AACA,M;;AAEA,0C;AACA,2B;;AAEA,sD;AACA,kC;AACA,gC;AACA,2C;AACA,O;AACA,+E;AACA,G;AACA,E;;AAEA,8C;AACA,kB;;AAEA,0B;AACA,sC;AACA,2B;AACA,kB;AACA,uB;;AAEA,+D;AACA,8D;AACA,2B;AACA,2D;AACA,E;;AAEA,yD;AACA,kB;AACA,gB;AACA,sB;AACA,U;AACA,0C;AACA,G;AACA,E;;AAEA,kD;AACA,sE;AACA,kB;;AAEA,0B;AACA,8B;AACA,qD;AACA,K;AACA,uB;AACA,E;;AAEA,6E;AACA,yE;AACA,kB;AACA,4B;AACA,8B;AACA,uE;AACA,2C;AACA,K;AACA,gB;AACA,E;;AAEA,gE;AACA,oE;AACA,kE;AACA,kE;AACA,gE;AACA,0D;AACA,kB;AACA,iD;AACA,Y;AACA,8B;AACA,M;AACA,uC;AACA,E;;AAEA,6E;AACA,kC;AACA,6D;AACA,iD;AACA,E;;;AAGA,kC;;AAEA,6E;AACA,8E;AACA,+E;AACA,4E;AACA,wB;AACA,E;AACA,oE;AACA,sE;AACA,mE;AACA,yE;AACA,4D;AACA,E;AACA,8D;AACA,mE;AACA,6D;;AAEA,yD;AACA,iC;AACA,gB;AACA,uD;AACA,gB;AACA,K;AACA,sB;AACA,iB;AACA,4B;AACA,iB;AACA,gB;AACA,I;AACA,E;;AAEA,mD;AACA,yD;AACA,E;;AAEA,wE;AACA,yD;AACA,kB;;AAEA,gC;AACA,iB;AACA,yB;AACA,Y;AACA,I;;AAEA,gE;AACA,sC;AACA,sB;AACA,iB;AACA,W;AACA,G;;AAEA,mD;AACA,0C;AACA,wB;AACA,sE;AACA,W;AACA,G;;AAEA,sC;AACA,6B;AACA,qE;AACA,I;AACA,8E;AACA,O;AACA,0D;AACA,yE;AACA,8C;AACA,e;AACA,sB;AACA,Y;AACA,G;AACA,E;;AAEA,2E;AACA,S;AACA,0E;AACA,kB;AACA,gD;AACA,2E;AACA,+E;AACA,8E;AACA,W;AACA,oE;AACA,oB;AACA,uC;AACA,qD;AACA,O;AACA,U;AACA,+B;AACA,G;AACA,E;;AAEA,wE;AACA,yD;AACA,kB;;AAEA,gE;AACA,sC;AACA,sB;AACA,iB;AACA,yB;AACA,Q;AACA,c;AACA,G;;AAEA,sC;AACA,6B;AACA,6C;AACA,I;AACA,8E;;AAEA,O;AACA,0D;AACA,yE;AACA,8C;AACA,e;AACA,sB;AACA,Y;AACA,G;AACA,E;;AAEA,2E;AACA,kB;;AAEA,sC;AACA,6B;AACA,yD;AACA,2C;AACA,I;AACA,kE;;AAEA,O;AACA,yD;AACA,wB;AACA,e;AACA,sB;AACA,Y;AACA,G;AACA,E;;AAEA,6E;AACA,kE;AACA,kB;;AAEA,kD;AACA,uB;AACA,mB;AACA,G;;AAEA,gE;AACA,sC;AACA,sB;AACA,iB;AACA,yB;AACA,Q;AACA,c;AACA,G;;AAEA,kE;AACA,gE;AACA,+D;AACA,uE;AACA,gB;AACA,sC;AACA,qE;;AAEA,6B;;AAEA,sC;AACA,6B;AACA,6C;AACA,I;AACA,qD;AACA,O;AACA,0D;AACA,iC;AACA,0D;AACA,gD;AACA,8C;;AAEA,2E;AACA,iE;;AAEA,+C;AACA,sD;;AAEA,8D;AACA,4E;AACA,gF;AACA,kD;AACA,mC;AACA,4C;AACA,0B;AACA,uE;AACA,6E;AACA,mC;AACA,gC;AACA,gF;AACA,+E;AACA,4E;AACA,gD;AACA,iD;AACA,c;AACA,kC;AACA,S;AACA,Q;AACA,Y;AACA,wB;AACA,2C;AACA,+D;AACA,sB;AACA,kD;AACA,kD;AACA,8D;AACA,6D;AACA,wC;AACA,8C;AACA,0C;AACA,4C;AACA,a;AACA,W;AACA,gC;AACA,Y;AACA,K;AACA,e;AACA,sB;AACA,Y;AACA,G;AACA,E;;AAEA,wC;AACA,oB;AACA,+B;AACA,kB;AACA,e;AACA,E;;AAEA,6B;;AAEA,sB;AACA,yD;AACA,+D;AACA,+B;AACA,oE;AACA,E;;AAEA,uE;AACA,2E;AACA,4E;AACA,0E;AACA,0E;AACA,iE;AACA,wE;AACA,qE;AACA,2E;AACA,6E;AACA,uE;AACA,yE;AACA,qE;AACA,wE;AACA,gB;;AAEA,a;AACA,iE;AACA,8C;AACA,iB;AACA,mE;AACA,gE;AACA,gE;AACA,mD;AACA,uE;AACA,gE;AACA,yB;AACA,U;AACA,iB;AACA,G;;AAEA,oD;AACA,4B;AACA,e;AACA,wB;AACA,I;AACA,4B;AACA,e;AACA,gB;AACA,I;;AAEA,mC;;AAEA,8B;AACA,Y;AACA,kB;AACA,qF;AACA,Y;AACA,0D;AACA,wE;AACA,kC;AACA,0C;AACA,0C;AACA,4C;AACA,oD;AACA,+B;AACA,8B;AACA,kD;AACA,4B;AACA,K;AACA,I;;AAEA,yC;AACA,qC;AACA,kE;AACA,c;AACA,sE;AACA,sE;AACA,kC;AACA,oD;AACA,uE;AACA,wE;AACA,4E;AACA,uC;AACA,kC;AACA,0C;AACA,2B;AACA,gC;AACA,0C;AACA,mD;AACA,kD;AACA,6B;AACA,yB;AACA,0B;AACA,I;;AAEA,a;AACA,E;;AAEA,4E;AACA,kE;AACA,oB;AACA,wE;AACA,I;AACA,G;;AAEA,+E;AACA,6E;AACA,Q;AACA,2E;AACA,iE;AACA,kB;AACA,oD;AACA,uB;AACA,iB;AACA,G;;AAEA,mD;AACA,4C;AACA,oC;AACA,0C;AACA,mC;AACA,E;;AAEA,+E;AACA,kB;;AAEA,6B;AACA,kB;;AAEA,oB;AACA,oE;AACA,E;;AAEA,wE;AACA,wD;AACA,kB;AACA,6B;AACA,kB;;AAEA,0B;AACA,oB;AACA,kE;AACA,E;;AAEA,6E;AACA,oC;AACA,yE;AACA,6D;AACA,kB;AACA,4C;;AAEA,+E;AACA,+C;AACA,uD;AACA,0B;AACA,4E;AACA,gB;AACA,E;AACA,yE;AACA,kB;;AAEA,8E;AACA,mC;AACA,uD;AACA,0B;AACA,iE;AACA,gB;AACA,E;;AAEA,U;;AAEA,qD;AACA,E;AACA,yE;AACA,6E;AACA,6E;AACA,4E;AACA,mD;AACA,E;AACA,yD;AACA,6D;AACA,E;AACA,yE;AACA,+E;AACA,8E;AACA,gC;AACA,E;AACA,+E;AACA,sC;AACA,E;AACA,gF;AACA,yB;AACA,E;AACA,mE;AACA,4E;AACA,iB;AACA,6E;AACA,wB;AACA,+E;AACA,4E;AACA,8E;;AAEA,kE;AACA,kB;AACA,uC;AACA,+D;AACA,+B;AACA,E;;AAEA,8C;AACA,kB;;AAEA,sB;AACA,8C;AACA,iC;AACA,E;;AAEA,gE;AACA,0C;AACA,oB;;AAEA,8C;AACA,iD;AACA,yE;;AAEA,mC;AACA,qE;AACA,kC;AACA,+E;AACA,+C;AACA,iC;AACA,4B;AACA,W;AACA,K;;AAEA,iD;AACA,0C;AACA,I;AACA,G;;AAEA,2E;AACA,2E;AACA,uD;AACA,wB;AACA,uC;AACA,E;;AAEA,6C;AACA,mD;AACA,E;;AAEA,gF;AACA,+E;AACA,a;;AAEA,kD;AACA,kB;AACA,0D;AACA,iE;AACA,E;;AAEA,yE;AACA,wE;AACA,+C;AACA,mD;AACA,kB;AACA,gD;AACA,C;;AAEA,iD;AACA,kB;AACA,qE;AACA,E;;AAEA,wD;AACA,kB;AACA,8E;AACA,qC;AACA,iD;AACA,E;;AAEA,8D;AACA,iC;AACA,kB;AACA,sE;;AAEA,yE;AACA,gD;AACA,sB;AACA,6B;AACA,+B;AACA,4B;AACA,I;;AAEA,2E;AACA,+B;AACA,mC;AACA,iC;AACA,8E;AACA,+D;AACA,kC;AACA,gF;AACA,+B;AACA,sC;AACA,8E;AACA,gF;AACA,8E;AACA,8E;AACA,oC;AACA,gE;AACA,wC;AACA,sC;AACA,K;AACA,G;;AAEA,iC;AACA,yE;AACA,wC;;AAEA,qE;AACA,E;;AAEA,yE;AACA,kB;AACA,sE;;AAEA,4B;AACA,8C;AACA,0E;AACA,uE;AACA,4D;AACA,oE;AACA,oD;AACA,2C;AACA,U;AACA,2B;AACA,G;;AAEA,2E;AACA,wE;AACA,kE;AACA,4C;AACA,2C;AACA,sE;AACA,gD;AACA,E;;AAEA,uC;AACA,4B;AACA,oB;;AAEA,kB;AACA,qD;;AAEA,4B;AACA,0D;;AAEA,2E;AACA,2E;AACA,gF;AACA,+E;AACA,gF;AACA,gF;AACA,uE;AACA,oD;AACA,4C;AACA,O;;AAEA,0B;AACA,mC;;AAEA,iB;AACA,K;AACA,I;;AAEA,yC;AACA,oB;;AAEA,iC;AACA,mB;;AAEA,0E;AACA,8E;AACA,2D;AACA,kB;AACA,kB;AACA,mC;AACA,uB;AACA,mE;AACA,K;AACA,I;;AAEA,kE;AACA,qC;AACA,oB;AACA,iB;AACA,wC;AACA,2E;AACA,O;AACA,e;AACA,I;;AAEA,wB;AACA,oB;;AAEA,8B;AACA,4B;;AAEA,kD;AACA,I;;AAEA,wC;AACA,sB;AACA,oB;;AAEA,2B;AACA,I;;AAEA,sB;AACA,oB;AACA,gC;AACA,I;;AAEA,sB;AACA,oB;AACA,2C;AACA,I;;AAEA,0C;AACA,qC;AACA,oB;AACA,kB;AACA,0B;AACA,Y;AACA,+C;AACA,mC;AACA,kC;AACA,S;AACA,qB;AACA,K;AACA,G;AACA,G;;AAEA,4E;AACA,kB;AACA,0C;AACA,uD;;AAEA,gE;;AAEA,sB;AACA,yB;AACA,0B;AACA,kB;AACA,kB;AACA,e;AACA,W;AACA,uC;AACA,qB;AACA,0E;AACA,2E;AACA,oE;AACA,mB;AACA,O;AACA,6E;AACA,wD;AACA,kB;AACA,e;AACA,gB;AACA,6E;AACA,8E;AACA,+E;AACA,qD;AACA,wB;AACA,yB;AACA,c;AACA,8D;AACA,qB;AACA,yC;AACA,S;AACA,qE;AACA,2C;AACA,sB;AACA,sC;AACA,6E;AACA,yE;AACA,oB;AACA,qC;AACA,c;AACA,O;AACA,K;AACA,I;;AAEA,qB;;AAEA,U;AACA,uB;AACA,qB;AACA,qB;AACA,K;AACA,I;AACA,E;;AAEA,sD;AACA,4C;AACA,kB;;AAEA,2C;AACA,+E;AACA,G;;AAEA,gF;AACA,oC;AACA,yC;AACA,oD;AACA,yD;AACA,wE;AACA,G;;AAEA,kC;AACA,qD;;AAEA,iC;AACA,0B;;AAEA,gF;AACA,6E;AACA,2E;AACA,uC;AACA,uD;AACA,0D;AACA,Y;AACA,yB;AACA,yC;AACA,4C;AACA,yB;AACA,6B;AACA,+B;AACA,uD;AACA,S;AACA,S;AACA,0D;AACA,K;AACA,K;;AAEA,gE;;AAEA,oB;AACA,wB;AACA,6B;AACA,mB;AACA,8E;AACA,4E;AACA,6B;AACA,+C;AACA,2C;AACA,sB;AACA,+E;AACA,wE;AACA,a;AACA,sE;AACA,sB;AACA,qB;AACA,wE;AACA,iE;AACA,uB;AACA,S;AACA,sB;AACA,8D;AACA,8E;AACA,sB;AACA,4E;AACA,yB;AACA,4C;AACA,sB;AACA,a;AACA,uE;AACA,8D;AACA,sB;AACA,qB;AACA,wE;AACA,iE;AACA,uB;AACA,S;AACA,iE;;AAEA,8E;AACA,qC;AACA,2C;AACA,wB;AACA,+B;AACA,uB;AACA,8C;AACA,4C;AACA,4D;AACA,O;;AAEA,+C;AACA,+C;AACA,G;;AAEA,kD;AACA,yD;;AAEA,uB;AACA,E;;AAEA,wE;AACA,8E;AACA,0E;AACA,8E;AACA,kC;;AAEA,0D;AACA,qB;AACA,wD;AACA,0D;AACA,gC;AACA,K;;AAEA,U;AACA,uB;AACA,6C;AACA,wB;AACA,S;AACA,K;AACA,I;AACA,E;;AAEA,gE;AACA,2D;AACA,0D;AACA,gC;AACA,oB;AACA,uC;AACA,+C;AACA,O;AACA,qE;AACA,U;AACA,yB;AACA,G;AACA,E;;AAEA,6D;AACA,E;AACA,wC;AACA,8E;AACA,gF;AACA,U;AACA,8E;AACA,2E;AACA,kE;AACA,2E;AACA,yE;AACA,gF;AACA,4E;AACA,iD;AACA,yE;AACA,6E;AACA,wD;AACA,yC;AACA,gF;AACA,4E;AACA,8E;AACA,+E;AACA,gF;AACA,uE;AACA,2E;AACA,0E;AACA,8E;AACA,4B;AACA,8D;AACA,4C;AACA,kB;;AAEA,4E;AACA,sC;AACA,4C;AACA,uC;AACA,6E;AACA,mD;AACA,yE;AACA,G;;AAEA,sD;AACA,qB;AACA,mB;AACA,mD;AACA,kB;AACA,kB;AACA,2C;AACA,Y;AACA,+B;AACA,K;AACA,K;AACA,E;;AAEA,sE;AACA,6D;AACA,sE;AACA,kD;;AAEA,4C;AACA,mC;;;;;;;;;;;;;;;;;;;ACxrCA,0C;;AAEA,8B;AACA,0C;;AAEA,+D;AACA,+D;AACA,iD;AACA,gC;AACA,gD;AACA,E;;AAEA,4B;AACA,wE;AACA,E;;AAEA,yB;AACA,oB;AACA,oB;AACA,yB;AACA,oB;AACA,yB;AACA,qB;AACA,yB;AACA,mE;AACA,qC;AACA,M;AACA,sD;AACA,E;;AAEA,2C;AACA,kB;AACA,4B;AACA,wB;;AAEA,wC;AACA,mC;AACA,wB;AACA,0B;AACA,mC;AACA,4C;AACA,6D;AACA,K;AACA,+B;AACA,6B;AACA,0D;AACA,U;AACA,qC;AACA,qD;AACA,+C;AACA,I;AACA,Y;AACA,+B;;AAEA,uB;AACA,E;;AAEA,iC;AACA,qB;AACA,oB;AACA,sB;AACA,a;AACA,yB;AACA,yB;AACA,8B;AACA,uC;AACA,I;AACA,8C;AACA,oB;AACA,sB;AACA,gE;;AAEA,4E;AACA,6B;;AAEA,oC;AACA,+D;AACA,gE;AACA,kD;AACA,uB;AACA,0D;AACA,O;AACA,gE;AACA,Y;AACA,yB;AACA,4B;AACA,O;AACA,M;AACA,I;AACA,6E;AACA,uE;AACA,uB;AACA,4E;AACA,yB;AACA,kC;AACA,oB;AACA,sB;AACA,qE;;AAEA,gF;AACA,gB;AACA,6B;;AAEA,4B;AACA,2E;AACA,+E;AACA,gE;AACA,W;AACA,+D;AACA,oD;AACA,mD;AACA,c;AACA,mB;AACA,8E;AACA,+B;AACA,sE;AACA,gC;AACA,O;AACA,K;;AAEA,sB;AACA,a;;AAEA,qB;AACA,wE;AACA,a;AACA,K;;AAEA,0B;AACA,Y;AACA,2E;;AAEA,6E;AACA,yC;AACA,a;AACA,K;;;AAGA,+E;AACA,6E;AACA,kD;AACA,qD;AACA,8B;AACA,4E;AACA,oB;AACA,K;AACA,uB;AACA,wE;AACA,a;AACA,I;AACA,8B;AACA,oB;AACA,uE;AACA,6E;AACA,0E;AACA,6E;AACA,sE;AACA,8E;AACA,gF;AACA,uB;AACA,M;AACA,8E;AACA,2D;AACA,oD;AACA,qC;AACA,0D;AACA,yE;AACA,8D;AACA,yD;AACA,qC;;AAEA,6E;AACA,gF;AACA,6D;AACA,8B;AACA,qB;AACA,8E;AACA,yC;;AAEA,iC;AACA,gE;AACA,qE;;AAEA,yD;AACA,yB;AACA,0D;AACA,kD;AACA,2E;AACA,yE;AACA,8B;AACA,gD;AACA,K;;AAEA,kD;AACA,yD;;AAEA,sD;AACA,yC;AACA,kE;AACA,2D;AACA,sC;AACA,2C;AACA,S;;AAEA,0E;AACA,6C;AACA,gC;;AAEA,8E;AACA,uB;AACA,4C;AACA,0C;AACA,wC;AACA,4B;AACA,gB;AACA,sC;AACA,oC;AACA,S;;AAEA,qC;;AAEA,+E;AACA,oB;AACA,yE;AACA,uC;AACA,kD;AACA,gE;AACA,0C;AACA,0D;AACA,oC;AACA,S;AACA,S;AACA,+B;AACA,G;AACA,G;;;;;;;;;;;;;;;;;;;AC1OA,0C;;AAEA,yC;AACA,kB;;AAEA,6C;AACA,0C;;AAEA,2D;AACA,iD;;AAEA,kC;AACA,kD;AACA,+C;AACA,qB;AACA,iC;AACA,4D;AACA,+B;AACA,sE;AACA,4E;AACA,c;AACA,mD;;AAEA,wD;AACA,+C;AACA,8D;AACA,M;AACA,K;AACA,E;;AAEA,wC;AACA,kD;AACA,oB;;AAEA,2E;AACA,qE;AACA,qE;AACA,uB;AACA,qC;AACA,sB;AACA,gF;AACA,mD;;AAEA,6D;AACA,8C;;AAEA,qC;AACA,yC;AACA,qE;AACA,+B;AACA,6B;AACA,qD;AACA,O;AACA,wD;AACA,6B;AACA,I;;AAEA,0E;AACA,yE;AACA,I;AACA,8E;AACA,8E;AACA,8D;AACA,+B;AACA,oB;;AAEA,4E;AACA,+E;AACA,0B;AACA,uB;AACA,2E;;AAEA,6B;;AAEA,6D;AACA,+C;;AAEA,mC;AACA,6D;AACA,mB;AACA,K;AACA,I;AACA,sB;AACA,oB;AACA,yE;AACA,iD;AACA,uB;AACA,iD;;AAEA,4E;AACA,kE;AACA,mB;AACA,6D;AACA,oD;;AAEA,8E;AACA,4D;AACA,yB;AACA,I;AACA,+E;AACA,8C;AACA,sB;AACA,oB;AACA,uC;AACA,wB;AACA,gE;AACA,iC;AACA,O;AACA,I;AACA,8E;AACA,8E;AACA,4E;AACA,0B;AACA,oB;AACA,uC;AACA,yB;AACA,6E;AACA,W;AACA,O;AACA,I;AACA,8B;AACA,oB;AACA,sB;AACA,kE;AACA,Q;AACA,6C;AACA,I;AACA,uB;AACA,0C;AACA,I;AACA,iD;AACA,oB;AACA,uC;AACA,mD;AACA,yB;AACA,e;;AAEA,8C;AACA,8E;AACA,2E;AACA,0E;AACA,gB;AACA,2E;;AAEA,gF;AACA,c;AACA,2B;AACA,yE;AACA,wE;AACA,O;;AAEA,2E;AACA,gF;AACA,gF;AACA,6E;AACA,wE;AACA,yD;AACA,8D;AACA,oB;AACA,iB;AACA,kD;AACA,uE;AACA,4D;AACA,S;AACA,O;AACA,I;;AAEA,gF;AACA,2E;AACA,gF;AACA,qE;AACA,gC;AACA,oB;AACA,oC;AACA,sE;AACA,kE;AACA,a;AACA,a;AACA,oD;AACA,iD;AACA,4C;AACA,uE;AACA,oC;AACA,wB;AACA,wB;AACA,qE;AACA,U;AACA,wB;AACA,O;AACA,G;AACA,G;;;AAGA,4B;AACA,mD;AACA,kB;AACA,wE;AACA,2C;AACA,kC;AACA,uD;AACA,0B;AACA,yC;AACA,2D;AACA,2E;AACA,6E;AACA,0E;AACA,gB;AACA,yD;AACA,oC;AACA,Q;AACA,K;AACA,K;AACA,wB;AACA,mC;AACA,E;AACA,4C;AACA,kB;AACA,oB;AACA,W;AACA,uB;AACA,2C;AACA,E;;;;;;;;;;;;;;;;;;;AC7NA,kC;AACA,0C;;AAEA,yC;AACA,kB;AACA,0C;AACA,qC;AACA,kC;AACA,E;;AAEA,gC;AACA,2E;AACA,W;AACA,I;AACA,6E;AACA,2E;AACA,kD;AACA,I;AACA,4E;AACA,iC;AACA,4D;AACA,oB;;AAEA,kC;AACA,gC;AACA,4B;;AAEA,8E;AACA,gD;AACA,sD;AACA,0D;AACA,a;AACA,K;;AAEA,sE;;AAEA,uB;AACA,W;AACA,gD;AACA,6C;AACA,yE;AACA,uD;AACA,uC;AACA,+E;AACA,yE;AACA,+E;AACA,kC;AACA,2C;AACA,2C;AACA,S;AACA,mB;AACA,uC;AACA,6B;AACA,S;AACA,iB;AACA,0E;AACA,kC;AACA,oD;AACA,O;AACA,a;AACA,G;AACA,G;;AAEA,kC;;;;;;;;;;;;;;;;;;;AC/DA,2C;AACA,kB;;AAEA,sD;AACA,0C;AACA,kC;AACA,0C;AACA,2B;AACA,wB;;AAEA,uE;AACA,6B;;AAEA,kE;AACA,kC;AACA,uB;;AAEA,+E;AACA,gF;AACA,6E;AACA,+E;AACA,0E;AACA,+E;AACA,iD;AACA,wC;AACA,sE;;AAEA,iE;AACA,iC;AACA,2C;AACA,yD;;AAEA,4C;AACA,mD;;AAEA,kC;AACA,sD;AACA,8E;AACA,8E;AACA,mE;AACA,qD;AACA,gB;AACA,qD;AACA,0E;AACA,6E;AACA,sD;AACA,kD;AACA,sC;AACA,K;AACA,I;AACA,oE;;AAEA,yE;AACA,sE;AACA,c;AACA,I;AACA,6E;AACA,+E;AACA,U;AACA,sC;AACA,+D;AACA,U;AACA,4C;AACA,4D;AACA,0C;AACA,2C;AACA,O;AACA,G;;AAEA,qC;AACA,2C;;AAEA,2D;AACA,oD;AACA,E;;AAEA,0C;AACA,uE;AACA,kD;AACA,oB;AACA,8C;AACA,a;AACA,wC;AACA,2C;AACA,wB;AACA,O;AACA,I;;AAEA,iD;AACA,I;AACA,+E;AACA,oE;AACA,2E;AACA,a;AACA,I;AACA,yE;AACA,+B;AACA,oB;AACA,sE;AACA,4D;AACA,wC;AACA,yE;AACA,2C;;AAEA,8E;AACA,uB;AACA,gD;AACA,0D;AACA,yD;AACA,I;AACA,8B;AACA,oB;AACA,uE;AACA,gD;AACA,0D;AACA,yD;AACA,0D;AACA,4D;AACA,yC;AACA,wB;AACA,O;AACA,I;;AAEA,2B;AACA,oB;AACA,wC;;AAEA,sB;AACA,mC;AACA,sB;AACA,mB;AACA,2C;AACA,mE;AACA,K;;AAEA,+D;;AAEA,oE;AACA,6C;AACA,6B;;AAEA,gD;AACA,S;AACA,4E;AACA,iB;AACA,uE;AACA,8E;AACA,4D;AACA,sE;AACA,c;AACA,K;;AAEA,iB;AACA,yB;AACA,wC;AACA,kE;AACA,K;;AAEA,gF;AACA,mE;AACA,4B;AACA,c;AACA,gC;;AAEA,gF;AACA,wE;AACA,+C;AACA,+B;;AAEA,8E;AACA,mE;AACA,yE;AACA,qD;AACA,2C;AACA,2C;AACA,sB;AACA,S;AACA,O;AACA,I;;AAEA,qB;AACA,oB;AACA,yB;AACA,uD;AACA,6D;AACA,uD;AACA,G;AACA,G;;;;;;;;;;;;;;;;;;;AC3LA,kC;AACA,0C;;AAEA,a;AACA,uB;AACA,uB;AACA,kB;AACA,E;;AAEA,yE;AACA,6C;AACA,qC;AACA,4C;AACA,sB;AACA,S;AACA,+B;AACA,iB;AACA,0C;AACA,gB;AACA,K;AACA,I;AACA,E;;AAEA,6E;AACA,6E;AACA,uE;AACA,+E;AACA,mC;AACA,yC;AACA,kB;AACA,gD;;AAEA,sD;AACA,0C;AACA,0C;;AAEA,wB;AACA,6E;AACA,G;;AAEA,8B;AACA,8E;AACA,6C;AACA,oD;;AAEA,gD;AACA,8D;AACA,oC;AACA,2E;AACA,qD;AACA,6E;AACA,6E;AACA,+C;AACA,8D;;AAEA,wD;AACA,wD;AACA,kC;AACA,0B;AACA,sE;AACA,+E;AACA,2D;AACA,U;AACA,oB;AACA,4B;AACA,wB;AACA,mC;AACA,iD;AACA,G;;AAEA,8E;AACA,8E;AACA,mD;AACA,mC;;AAEA,wB;AACA,yB;;AAEA,2D;AACA,kD;;AAEA,4C;;AAEA,kD;AACA,kC;AACA,gE;AACA,sE;AACA,+E;AACA,+B;AACA,2E;AACA,a;AACA,kF;AACA,gE;AACA,4B;;AAEA,iD;AACA,iC;AACA,4B;;AAEA,yC;AACA,6C;;AAEA,8D;AACA,uE;AACA,wC;AACA,qE;AACA,mC;AACA,4C;AACA,8E;AACA,gF;AACA,4B;AACA,oC;AACA,kB;AACA,uE;AACA,+C;AACA,iD;AACA,gB;AACA,yD;AACA,W;AACA,Y;AACA,O;AACA,O;AACA,K;;AAEA,yC;AACA,mC;AACA,sD;AACA,qE;AACA,qD;AACA,iB;AACA,e;AACA,qC;AACA,gF;AACA,0D;AACA,gC;AACA,2D;AACA,4B;AACA,uD;AACA,4B;AACA,kD;AACA,yE;AACA,+E;AACA,oB;AACA,iD;AACA,8B;AACA,a;AACA,gB;AACA,4D;AACA,S;AACA,S;AACA,K;AACA,K;;AAEA,gF;AACA,sC;AACA,+E;AACA,iB;AACA,8B;AACA,S;;AAEA,sE;AACA,uD;AACA,oD;AACA,4B;AACA,M;AACA,E;;AAEA,wC;AACA,qC;AACA,oB;AACA,8B;AACA,sB;AACA,2D;AACA,4D;;AAEA,wE;AACA,+E;AACA,gF;AACA,mC;AACA,8D;AACA,oE;AACA,uD;AACA,uD;AACA,gE;AACA,8D;AACA,O;;AAEA,4D;AACA,iE;;AAEA,+C;AACA,oF;AACA,O;;AAEA,+C;AACA,kD;AACA,0D;AACA,K;AACA,I;AACA,mC;AACA,oB;AACA,+B;AACA,kC;AACA,gE;AACA,a;;AAEA,6C;AACA,iD;;AAEA,6E;AACA,2E;;AAEA,2C;AACA,uE;AACA,oB;AACA,4D;AACA,yD;AACA,qC;AACA,2C;AACA,a;AACA,K;;AAEA,2E;;AAEA,8E;AACA,2E;AACA,gF;AACA,2E;AACA,0D;AACA,uC;AACA,a;;AAEA,kE;AACA,4E;AACA,8E;AACA,4E;AACA,iC;AACA,a;;AAEA,0E;AACA,sE;AACA,0E;AACA,gF;AACA,gF;AACA,qC;;AAEA,iD;AACA,I;AACA,mD;AACA,oB;AACA,8D;AACA,8E;AACA,0C;AACA,4B;AACA,6C;AACA,I;AACA,oC;AACA,oB;AACA,mE;;AAEA,2E;AACA,uD;AACA,iE;;AAEA,oD;;AAEA,+E;AACA,mC;AACA,uC;AACA,K;AACA,I;AACA,+E;AACA,mC;AACA,kC;AACA,oB;AACA,uC;AACA,6E;AACA,gF;AACA,2C;AACA,uE;AACA,8B;AACA,I;AACA,kE;AACA,+E;AACA,sC;AACA,gC;AACA,oB;AACA,qB;AACA,gC;AACA,oE;AACA,uD;AACA,4E;;AAEA,4B;AACA,sC;AACA,8D;AACA,iE;AACA,qE;AACA,iF;AACA,+E;AACA,6E;AACA,uC;AACA,gE;AACA,sD;;AAEA,4E;AACA,+E;AACA,6D;AACA,qE;AACA,mE;;AAEA,0E;AACA,+B;AACA,0D;AACA,gE;;AAEA,4D;;AAEA,oB;AACA,kC;AACA,0B;AACA,iC;AACA,Y;AACA,gD;AACA,uC;AACA,K;AACA,I;AACA,8D;AACA,+E;AACA,sC;AACA,kC;AACA,oB;AACA,mD;AACA,6E;;AAEA,kC;AACA,gC;AACA,iD;AACA,+B;AACA,K;AACA,I;AACA,qC;AACA,oB;AACA,4E;;AAEA,kD;AACA,wE;AACA,yD;;AAEA,sC;AACA,gC;AACA,6C;AACA,+B;AACA,4C;AACA,2C;AACA,wC;AACA,wE;AACA,4E;;AAEA,4B;AACA,+E;AACA,gF;AACA,mE;AACA,gF;AACA,yE;AACA,4E;AACA,oC;AACA,+C;AACA,sE;AACA,oE;;AAEA,+B;AACA,oD;AACA,gB;AACA,0E;AACA,oC;AACA,wD;AACA,gG;;AAEA,oD;AACA,+E;;AAEA,yB;AACA,0C;AACA,kB;AACA,4D;AACA,6C;AACA,W;AACA,S;AACA,kC;AACA,iD;AACA,8E;AACA,gF;AACA,4E;AACA,e;AACA,2C;;AAEA,+E;AACA,gI;;AAEA,mE;AACA,6D;;AAEA,mD;AACA,wE;AACA,8E;;AAEA,wB;AACA,yC;AACA,mC;AACA,wC;AACA,kD;AACA,gB;AACA,0D;AACA,2C;AACA,+E;AACA,4D;AACA,iD;AACA,oC;AACA,W;AACA,S;AACA,c;AACA,qG;AACA,O;AACA,K;AACA,I;AACA,wC;AACA,oB;AACA,8C;AACA,gF;AACA,sB;AACA,sD;AACA,4D;AACA,6C;AACA,6E;AACA,0E;AACA,2E;AACA,gB;AACA,S;;AAEA,0D;AACA,2C;AACA,6E;;AAEA,oD;AACA,qD;AACA,uD;AACA,wB;AACA,6B;AACA,4E;AACA,2D;AACA,iE;AACA,oB;AACA,8C;AACA,iE;AACA,yD;AACA,mB;AACA,0B;AACA,4E;AACA,qC;AACA,gF;AACA,6E;AACA,+E;AACA,oC;AACA,uD;AACA,4C;AACA,mB;AACA,2E;AACA,yE;AACA,6E;AACA,wE;AACA,2E;AACA,gD;AACA,2C;AACA,iB;AACA,yB;AACA,0B;AACA,+E;AACA,gF;AACA,yB;AACA,kC;AACA,+B;AACA,e;AACA,gB;AACA,W;AACA,mB;AACA,8E;AACA,2C;AACA,iB;AACA,uC;AACA,O;AACA,gF;AACA,yC;AACA,yC;AACA,yB;AACA,Q;AACA,I;AACA,0B;AACA,oB;AACA,4C;AACA,uD;AACA,+C;AACA,2C;AACA,mC;AACA,sB;AACA,S;AACA,O;AACA,I;AACA,4C;AACA,oB;AACA,yD;AACA,I;AACA,oD;AACA,oB;AACA,yB;AACA,+E;AACA,gD;AACA,yC;AACA,wE;AACA,sC;AACA,kD;AACA,a;AACA,K;;AAEA,wB;AACA,sF;AACA,iC;AACA,+B;AACA,kC;AACA,6E;AACA,qE;AACA,0E;;AAEA,+E;AACA,e;AACA,qD;AACA,gC;AACA,+B;AACA,0E;AACA,gF;AACA,wE;AACA,mB;AACA,qE;AACA,6E;AACA,wD;AACA,6E;AACA,+B;AACA,gC;AACA,6D;;AAEA,oD;AACA,0E;;AAEA,sB;AACA,uD;AACA,+E;AACA,2E;AACA,yB;AACA,8C;AACA,mC;AACA,0C;AACA,qC;;AAEA,wB;AACA,8C;AACA,8D;AACA,yC;AACA,+D;AACA,2E;AACA,oD;AACA,yC;AACA,yC;AACA,O;AACA,Y;AACA,qD;AACA,K;AACA,I;AACA,iC;AACA,oB;AACA,sB;AACA,0D;;AAEA,qB;;AAEA,sB;AACA,mD;AACA,2E;AACA,4B;AACA,8B;;AAEA,yB;AACA,I;;AAEA,gF;AACA,yE;AACA,I;AACA,0E;AACA,a;AACA,I;AACA,gF;AACA,W;AACA,I;AACA,4E;AACA,2E;AACA,qE;AACA,sE;AACA,qE;AACA,2B;AACA,oB;;AAEA,sB;AACA,a;;AAEA,6E;AACA,mD;AACA,mC;AACA,6D;AACA,8C;;AAEA,gF;AACA,8D;AACA,8B;AACA,uB;AACA,2B;AACA,O;AACA,I;;AAEA,0B;AACA,oB;AACA,8B;;AAEA,iD;AACA,kB;AACA,uE;AACA,wB;AACA,e;;AAEA,8C;AACA,6C;;AAEA,gF;AACA,4E;AACA,qE;AACA,qB;AACA,gD;AACA,8E;AACA,kC;AACA,oE;AACA,W;AACA,0C;AACA,8C;AACA,yC;AACA,c;AACA,wC;AACA,W;AACA,c;AACA,mB;AACA,8E;AACA,+B;AACA,iE;AACA,gC;AACA,O;AACA,K;;AAEA,sB;AACA,a;;AAEA,mD;AACA,I;;AAEA,gF;AACA,4C;AACA,I;AACA,0E;AACA,8E;AACA,2D;AACA,8E;AACA,qE;AACA,I;AACA,gF;AACA,0D;AACA,wC;AACA,iC;AACA,oB;AACA,sB;AACA,a;;AAEA,gF;AACA,yB;AACA,yC;AACA,wB;AACA,gC;AACA,K;;AAEA,4E;AACA,6B;AACA,0C;AACA,I;;AAEA,8B;AACA,oB;;AAEA,sB;AACA,a;AACA,uD;;AAEA,sB;AACA,a;AACA,uC;AACA,uD;;AAEA,yC;AACA,6C;AACA,wB;AACA,2C;AACA,uB;AACA,Y;AACA,qC;AACA,K;AACA,I;;AAEA,gD;AACA,oB;;AAEA,+E;AACA,6E;AACA,wE;AACA,4E;AACA,kE;AACA,2D;;AAEA,+E;AACA,wB;AACA,wC;;AAEA,4C;AACA,6B;AACA,2E;AACA,4C;AACA,6C;AACA,uC;AACA,e;AACA,sD;AACA,I;;;AAGA,gF;AACA,kC;AACA,oD;AACA,I;AACA,+E;AACA,kF;AACA,wE;AACA,wD;AACA,oB;;AAEA,6E;AACA,qB;AACA,sB;AACA,sC;AACA,K;;AAEA,kE;AACA,+C;AACA,yB;AACA,gD;AACA,8B;AACA,6B;AACA,O;AACA,uC;AACA,gC;AACA,O;;AAEA,+B;AACA,qE;AACA,yD;AACA,2C;AACA,+B;AACA,O;;AAEA,4E;AACA,a;AACA,2C;AACA,uD;AACA,gE;AACA,K;AACA,gD;AACA,8B;AACA,2E;AACA,O;;AAEA,kC;AACA,0C;AACA,iC;AACA,O;;AAEA,8D;AACA,I;;AAEA,gF;AACA,0E;AACA,W;AACA,I;AACA,6E;AACA,e;AACA,qB;AACA,oB;AACA,sB;AACA,a;AACA,yB;AACA,iD;AACA,oB;AACA,O;;AAEA,sE;AACA,yE;AACA,8E;AACA,yE;AACA,0B;AACA,gE;AACA,oB;AACA,O;AACA,iD;;AAEA,6D;AACA,2B;AACA,mC;AACA,6B;AACA,mC;AACA,kC;AACA,iC;;AAEA,6D;AACA,qD;AACA,I;;AAEA,0C;AACA,oB;AACA,uB;;AAEA,sB;AACA,gD;AACA,+D;AACA,+E;AACA,K;;AAEA,wB;AACA,+B;AACA,G;AACA,G;;AAEA,8E;AACA,qE;AACA,+B;AACA,4E;AACA,8B;AACA,0C;;AAEA,oC;AACA,4B;AACA,iB;;AAEA,4E;AACA,+C;AACA,gF;AACA,0C;AACA,qE;;AAEA,uE;AACA,kD;AACA,uB;AACA,S;AACA,gE;AACA,iB;AACA,sC;AACA,qB;AACA,U;AACA,gB;AACA,K;AACA,G;;AAEA,4C;AACA,sE;AACA,0C;AACA,6E;AACA,4E;AACA,iC;AACA,6E;AACA,oE;AACA,uD;AACA,E;;AAEA,wD;AACA,uD;AACA,kD;AACA,oC;AACA,O;AACA,K;AACA,E;;AAEA,uD;;;;;;;;;;;;;;;;;;;ACp4BA,qC;AACA,kB;AACA,8B;AACA,E;;AAEA,qD;AACA,6B;AACA,kD;AACA,2B;AACA,E;;AAEA,2C;AACA,+B;AACA,oB;AACA,c;AACA,iC;AACA,iB;AACA,4D;AACA,K;AACA,2C;AACA,4C;AACA,6E;AACA,6C;AACA,oE;AACA,G;AACA,G;;AAEA,Y;AACA,kD;;;;;;;;;;;;;;;;;;;AC5BA,kD;AACA,uB;AACA,kB;AACA,uD;AACA,E;;AAEA,2D;AACA,yB;AACA,oB;AACA,iB;AACA,W;AACA,yD;AACA,yE;AACA,yB;AACA,oB;AACA,yD;AACA,S;AACA,e;AACA,G;AACA,G;;;AAGA,oE;AACA,qE;AACA,gE;AACA,mE;AACA,e;AACA,6B;;AAEA,kE;AACA,gF;AACA,4B;AACA,0B;;AAEA,qB;AACA,gD;AACA,K;;AAEA,8E;AACA,iB;AACA,4D;;;AAGA,gF;AACA,G;;;;;;;;;;;;;;;;;;;AC5CA,sE;AACA,iE;;AAEA,8C;AACA,kB;AACA,4C;AACA,kE;;AAEA,iC;AACA,6E;AACA,6E;AACA,oE;AACA,gB;AACA,G;;AAEA,kD;AACA,oB;AACA,0E;AACA,G;;AAEA,mC;AACA,yE;AACA,sF;AACA,e;AACA,4B;AACA,oC;AACA,G;AACA,uE;AACA,0D;AACA,yC;AACA,G;AACA,sB;AACA,0B;AACA,2B;AACA,oB;AACA,uB;AACA,8B;AACA,c;;AAEA,iC;AACA,e;AACA,mC;AACA,wE;AACA,+D;AACA,M;AACA,U;AACA,gB;AACA,U;AACA,mC;AACA,wE;AACA,sB;AACA,M;AACA,U;AACA,G;;AAEA,qE;;AAEA,4C;AACA,yD;AACA,4B;AACA,8B;AACA,0C;AACA,2B;AACA,yC;AACA,M;AACA,qC;;AAEA,yB;AACA,qD;AACA,gD;AACA,uD;AACA,uE;AACA,Y;AACA,8C;AACA,K;AACA,G;;AAEA,kE;AACA,oB;;AAEA,2D;AACA,6D;AACA,qE;AACA,oC;AACA,mD;AACA,+E;AACA,mC;AACA,Q;AACA,+E;AACA,wE;AACA,0E;AACA,0E;AACA,+E;AACA,6E;AACA,yC;AACA,gD;AACA,2E;AACA,0E;AACA,gF;AACA,gF;AACA,gB;AACA,mC;AACA,4C;;AAEA,kB;AACA,sC;AACA,Q;;AAEA,yB;AACA,4E;AACA,8B;AACA,uD;AACA,oD;;AAEA,+E;AACA,2E;AACA,sC;AACA,oC;AACA,oC;AACA,yB;AACA,oB;AACA,+C;AACA,4B;AACA,6C;AACA,kB;AACA,kD;AACA,sD;AACA,W;AACA,iB;AACA,yC;AACA,oB;AACA,0F;AACA,W;AACA,wE;AACA,2C;AACA,mB;AACA,uF;AACA,2C;AACA,2C;AACA,mB;AACA,qE;AACA,uC;AACA,8B;AACA,sD;AACA,wC;AACA,qC;AACA,uC;AACA,yC;AACA,sB;AACA,mC;AACA,qC;AACA,2C;AACA,e;AACA,e;AACA,uD;AACA,W;AACA,gB;AACA,wE;AACA,S;;AAEA,Q;;AAEA,iD;AACA,8B;AACA,2C;AACA,Q;;AAEA,+E;AACA,+B;AACA,kC;AACA,yC;AACA,Q;AACA,sC;AACA,oD;AACA,O;AACA,O;;AAEA,Y;AACA,4E;AACA,G;;AAEA,gC;;AAEA,gB;AACA,6E;AACA,oC;AACA,gD;AACA,yB;AACA,wB;AACA,G;AACA,E;;AAEA,G;AACA,uB;AACA,G;;;AAGA,uC;;AAEA,qC;AACA,yB;AACA,gB;AACA,Q;AACA,qB;AACA,I;;AAEA,oC;AACA,oB;AACA,0B;AACA,4C;AACA,Y;AACA,2D;AACA,+D;AACA,oE;AACA,8D;AACA,4D;AACA,U;;AAEA,uB;AACA,kC;AACA,kB;AACA,K;AACA,I;;AAEA,4C;AACA,8D;AACA,8D;AACA,6C;AACA,oB;AACA,wC;AACA,iE;AACA,iE;AACA,I;;AAEA,+C;AACA,oB;AACA,wC;AACA,oE;AACA,oE;AACA,G;;AAEA,G;;AAEA,uE;AACA,6C;AACA,kC;AACA,wC;AACA,M;AACA,oC;AACA,0C;AACA,M;AACA,4B;AACA,kC;AACA,K;AACA,K;;AAEA,6E;AACA,kE;;AAEA,wD;AACA,kD;AACA,E;;AAEA,0E;AACA,+E;AACA,wE;AACA,sB;AACA,0D;AACA,mC;AACA,8C;AACA,+B;;AAEA,0D;AACA,2B;AACA,8B;;AAEA,e;AACA,0C;AACA,sE;AACA,kC;AACA,qD;AACA,yD;AACA,4D;AACA,iE;AACA,yC;AACA,uC;AACA,2C;AACA,K;AACA,sD;AACA,gD;AACA,4C;AACA,qD;AACA,S;AACA,Y;AACA,uB;AACA,K;AACA,K;AACA,a;AACA,E;;AAEA,qE;AACA,W;AACA,sD;AACA,uC;;AAEA,yC;AACA,wB;AACA,sE;AACA,oE;AACA,wB;AACA,wB;AACA,uB;AACA,wB;AACA,mB;AACA,qC;;AAEA,kB;AACA,E;;AAEA,8D;AACA,gE;AACA,2B;AACA,mE;AACA,6B;AACA,G;AACA,E;;AAEA,gE;AACA,0E;AACA,0E;AACA,gE;AACA,8E;AACA,iC;AACA,E;AACA,qE;AACA,6D;AACA,qE;AACA,oE;AACA,gF;AACA,gF;AACA,8E;AACA,gE;AACA,E;AACA,0D;AACA,6D;AACA,uB;AACA,E;AACA,gE;AACA,qE;AACA,iB;AACA,E;AACA,mE;AACA,oE;AACA,8D;AACA,kE;AACA,O;AACA,wD;AACA,kE;AACA,oB;AACA,oC;AACA,iB;AACA,iB;AACA,Y;;AAEA,iE;AACA,4B;;AAEA,4B;AACA,uB;AACA,uD;AACA,qD;AACA,sC;AACA,6B;AACA,+B;AACA,uD;AACA,iE;AACA,sG;AACA,c;AACA,8B;AACA,6E;AACA,4E;AACA,qC;AACA,qE;AACA,uD;AACA,2B;AACA,+B;AACA,W;AACA,S;AACA,yB;AACA,qD;AACA,S;AACA,O;AACA,Y;AACA,4D;;AAEA,8B;AACA,2E;AACA,+E;AACA,2E;AACA,wB;AACA,uD;AACA,yE;AACA,6E;AACA,mC;AACA,wD;AACA,+E;AACA,uE;AACA,kB;AACA,mD;AACA,W;AACA,S;AACA,O;AACA,K;;AAEA,uE;AACA,8D;AACA,mE;AACA,8B;AACA,kC;AACA,4B;AACA,S;AACA,wB;AACA,c;AACA,sB;AACA,O;AACA,M;;AAEA,wB;AACA,mB;AACA,kD;AACA,kF;AACA,Q;AACA,K;;AAEA,iE;AACA,mE;AACA,mB;;AAEA,mD;AACA,oE;;AAEA,yE;AACA,sE;AACA,qE;AACA,kE;AACA,uE;AACA,gB;AACA,+E;AACA,+E;AACA,gC;AACA,0C;AACA,kB;AACA,0E;AACA,U;AACA,O;;AAEA,sD;AACA,8E;AACA,6E;AACA,4E;AACA,8C;AACA,O;;AAEA,kD;AACA,mG;AACA,Q;;AAEA,Y;AACA,gE;AACA,qC;AACA,iC;AACA,W;AACA,6E;AACA,6E;AACA,gE;AACA,4E;AACA,8D;AACA,mB;AACA,uB;AACA,sB;AACA,sB;AACA,S;AACA,gB;AACA,O;AACA,K;;AAEA,oE;AACA,+E;AACA,uD;AACA,e;AACA,I;AACA,G;;AAEA,kE;AACA,mE;AACA,kB;AACA,oD;AACA,uB;AACA,iB;AACA,G;AACA,wC;AACA,2E;AACA,wB;AACA,E;;AAEA,6E;AACA,oC;AACA,sE;AACA,kB;AACA,qC;AACA,wE;AACA,gD;AACA,E;AACA,2D;AACA,kB;AACA,mC;AACA,sE;AACA,qC;AACA,E;AACA,2D;AACA,kB;AACA,uC;AACA,2E;AACA,oC;AACA,E;AACA,2E;AACA,kB;AACA,gD;AACA,mF;AACA,qD;AACA,E;;AAEA,uD;;AAEA,G;AACA,sC;AACA,G;;AAEA,uE;AACA,gB;AACA,E;AACA,yC;AACA,mD;AACA,E;AACA,4D;AACA,wD;AACA,qE;AACA,E;AACA,0C;AACA,uD;AACA,E;AACA,wB;AACA,uE;AACA,0D;AACA,E;AACA,kE;AACA,wB;AACA,qE;AACA,oE;AACA,uB;AACA,2E;AACA,6E;AACA,sC;AACA,E;AACA,8E;AACA,6E;AACA,mC;;AAEA,c;AACA,qD;AACA,oB;AACA,0E;AACA,4C;AACA,uC;AACA,+D;AACA,O;;AAEA,oB;AACA,4B;;AAEA,4D;AACA,0B;AACA,mD;AACA,yF;AACA,S;;AAEA,6E;AACA,uE;AACA,sB;AACA,8C;AACA,wE;AACA,gB;AACA,kE;AACA,+B;AACA,S;;AAEA,gE;AACA,O;AACA,O;;AAEA,sE;AACA,0E;AACA,6B;AACA,4D;AACA,+D;AACA,8E;AACA,O;AACA,uC;AACA,K;AACA,I;;AAEA,yD;AACA,8C;AACA,I;AACA,wD;AACA,6C;AACA,I;AACA,K;;;AAGA,iE;AACA,kB;;AAEA,qE;AACA,iE;AACA,2B;;AAEA,8E;AACA,4E;AACA,+E;AACA,uB;AACA,6B;;AAEA,sB;AACA,kC;AACA,kC;AACA,kC;AACA,oE;AACA,c;AACA,yB;AACA,I;;AAEA,kB;AACA,mC;;AAEA,gE;AACA,gC;AACA,wC;;AAEA,qB;AACA,yB;AACA,e;;AAEA,8D;AACA,uD;AACA,6E;AACA,sC;AACA,wC;AACA,a;AACA,6E;AACA,gF;AACA,+E;AACA,uE;AACA,2E;AACA,yE;AACA,Y;AACA,4E;AACA,yE;AACA,qE;AACA,qD;AACA,iC;AACA,8D;AACA,4C;AACA,W;;AAEA,kC;AACA,2E;AACA,iC;AACA,qC;AACA,wC;AACA,kD;AACA,sC;AACA,W;;AAEA,wE;;AAEA,kF;AACA,iC;AACA,kC;AACA,oD;;AAEA,iC;AACA,6D;AACA,8D;AACA,qC;AACA,8E;AACA,6D;AACA,a;;AAEA,qC;AACA,kF;AACA,sC;AACA,0D;AACA,+D;AACA,0C;AACA,qC;AACA,wC;AACA,6E;AACA,0E;AACA,kB;AACA,+E;AACA,4B;AACA,yD;AACA,W;AACA,qB;AACA,uE;AACA,sD;AACA,kB;AACA,oB;AACA,W;AACA,S;AACA,Q;AACA,O;AACA,iE;AACA,sD;AACA,oE;AACA,8D;AACA,kC;AACA,G;AACA,E;;;AAGA,8D;AACA,kB;;AAEA,yC;AACA,iB;AACA,uE;AACA,Y;AACA,6C;AACA,oE;AACA,oC;AACA,K;AACA,G;AACA,E;;AAEA,uD;AACA,kB;AACA,mC;AACA,8B;AACA,wB;AACA,E;;AAEA,4D;AACA,gB;AACA,4B;AACA,2B;AACA,gF;AACA,2E;AACA,+E;AACA,mD;AACA,yD;AACA,+B;AACA,4B;AACA,K;AACA,mC;AACA,G;AACA,a;AACA,E;;AAEA,qE;AACA,uE;AACA,kB;;AAEA,0B;AACA,wC;AACA,+D;AACA,yE;AACA,O;AACA,iD;AACA,G;AACA,wE;AACA,gE;AACA,0E;AACA,O;AACA,iD;AACA,G;;AAEA,0E;AACA,+B;AACA,2B;AACA,0B;;AAEA,sD;AACA,E;;AAEA,8C;AACA,0B;AACA,oC;AACA,a;AACA,E;;AAEA,uE;AACA,mE;AACA,kE;AACA,2C;AACA,wD;AACA,yC;AACA,kB;;AAEA,0B;;AAEA,8D;AACA,iE;;AAEA,2E;AACA,W;AACA,qB;AACA,+D;AACA,kE;;AAEA,4B;AACA,kB;AACA,yC;AACA,+B;AACA,6B;AACA,wJ;AACA,uD;AACA,6B;AACA,2F;AACA,Y;AACA,+C;AACA,6D;AACA,yB;AACA,sC;AACA,yD;;AAEA,mD;AACA,uC;AACA,6B;AACA,S;AACA,K;AACA,K;;AAEA,sC;AACA,yC;AACA,4B;AACA,wD;AACA,wC;AACA,O;AACA,G;;AAEA,4D;AACA,+B;AACA,a;;AAEA,mB;;AAEA,0B;AACA,wC;AACA,+D;AACA,sB;AACA,kD;AACA,4B;AACA,kC;AACA,4B;AACA,8B;AACA,O;AACA,iD;AACA,G;AACA,wE;AACA,gE;AACA,sB;AACA,kD;AACA,6B;AACA,mC;AACA,6B;AACA,+B;AACA,O;AACA,iD;AACA,G;;AAEA,4E;AACA,6E;AACA,+E;AACA,4B;;AAEA,sC;AACA,kD;AACA,E;;AAEA,iE;AACA,8D;AACA,oE;AACA,8D;AACA,uE;AACA,6D;AACA,iC;AACA,qE;AACA,6B;AACA,E;;AAEA,sE;AACA,8B;AACA,2E;AACA,kB;;AAEA,sC;AACA,yC;AACA,4B;AACA,wD;AACA,wC;AACA,O;AACA,G;;AAEA,4D;AACA,W;AACA,a;;AAEA,0B;AACA,wC;AACA,+D;AACA,2D;AACA,O;AACA,iD;AACA,G;AACA,wE;AACA,gE;AACA,4D;AACA,O;AACA,iD;AACA,G;;AAEA,4E;AACA,gF;AACA,8E;AACA,sC;;AAEA,kE;AACA,E","sourcesContent":["/**\r\n * Provide a synchronous Collection API using fibers, backed by\r\n * MongoDB.  This is only for use on the server, and mostly identical\r\n * to the client API.\r\n *\r\n * NOTE: the public API methods must be run within a fiber. If you call\r\n * these outside of a fiber they will explode!\r\n */\r\n\r\nvar path = Npm.require('path');\r\nvar MongoDB = Npm.require('mongodb');\r\nvar Fiber = Npm.require('fibers');\r\nvar Future = Npm.require(path.join('fibers', 'future'));\r\n\r\nMongoInternals = {};\r\nMongoTest = {};\r\n\r\n// This is used to add or remove EJSON from the beginning of everything nested\r\n// inside an EJSON custom type. It should only be called on pure JSON!\r\nvar replaceNames = function (filter, thing) {\r\n  if (typeof thing === \"object\") {\r\n    if (_.isArray(thing)) {\r\n      return _.map(thing, _.bind(replaceNames, null, filter));\r\n    }\r\n    var ret = {};\r\n    _.each(thing, function (value, key) {\r\n      ret[filter(key)] = replaceNames(filter, value);\r\n    });\r\n    return ret;\r\n  }\r\n  return thing;\r\n};\r\n\r\n// Ensure that EJSON.clone keeps a Timestamp as a Timestamp (instead of just\r\n// doing a structural clone).\r\n// XXX how ok is this? what if there are multiple copies of MongoDB loaded?\r\nMongoDB.Timestamp.prototype.clone = function () {\r\n  // Timestamps should be immutable.\r\n  return this;\r\n};\r\n\r\nvar makeMongoLegal = function (name) { return \"EJSON\" + name; };\r\nvar unmakeMongoLegal = function (name) { return name.substr(5); };\r\n\r\nvar replaceMongoAtomWithMeteor = function (document) {\r\n  if (document instanceof MongoDB.Binary) {\r\n    var buffer = document.value(true);\r\n    return new Uint8Array(buffer);\r\n  }\r\n  if (document instanceof MongoDB.ObjectID) {\r\n    return new Meteor.Collection.ObjectID(document.toHexString());\r\n  }\r\n  if (document[\"EJSON$type\"] && document[\"EJSON$value\"]\r\n      && _.size(document) === 2) {\r\n    return EJSON.fromJSONValue(replaceNames(unmakeMongoLegal, document));\r\n  }\r\n  if (document instanceof MongoDB.Timestamp) {\r\n    // For now, the Meteor representation of a Mongo timestamp type (not a date!\r\n    // this is a weird internal thing used in the oplog!) is the same as the\r\n    // Mongo representation. We need to do this explicitly or else we would do a\r\n    // structural clone and lose the prototype.\r\n    return document;\r\n  }\r\n  return undefined;\r\n};\r\n\r\nvar replaceMeteorAtomWithMongo = function (document) {\r\n  if (EJSON.isBinary(document)) {\r\n    // This does more copies than we'd like, but is necessary because\r\n    // MongoDB.BSON only looks like it takes a Uint8Array (and doesn't actually\r\n    // serialize it correctly).\r\n    return new MongoDB.Binary(new Buffer(document));\r\n  }\r\n  if (document instanceof Meteor.Collection.ObjectID) {\r\n    return new MongoDB.ObjectID(document.toHexString());\r\n  }\r\n  if (document instanceof MongoDB.Timestamp) {\r\n    // For now, the Meteor representation of a Mongo timestamp type (not a date!\r\n    // this is a weird internal thing used in the oplog!) is the same as the\r\n    // Mongo representation. We need to do this explicitly or else we would do a\r\n    // structural clone and lose the prototype.\r\n    return document;\r\n  }\r\n  if (EJSON._isCustomType(document)) {\r\n    return replaceNames(makeMongoLegal, EJSON.toJSONValue(document));\r\n  }\r\n  // It is not ordinarily possible to stick dollar-sign keys into mongo\r\n  // so we don't bother checking for things that need escaping at this time.\r\n  return undefined;\r\n};\r\n\r\nvar replaceTypes = function (document, atomTransformer) {\r\n  if (typeof document !== 'object' || document === null)\r\n    return document;\r\n\r\n  var replacedTopLevelAtom = atomTransformer(document);\r\n  if (replacedTopLevelAtom !== undefined)\r\n    return replacedTopLevelAtom;\r\n\r\n  var ret = document;\r\n  _.each(document, function (val, key) {\r\n    var valReplaced = replaceTypes(val, atomTransformer);\r\n    if (val !== valReplaced) {\r\n      // Lazy clone. Shallow copy.\r\n      if (ret === document)\r\n        ret = _.clone(document);\r\n      ret[key] = valReplaced;\r\n    }\r\n  });\r\n  return ret;\r\n};\r\n\r\n\r\nMongoConnection = function (url, options) {\r\n  var self = this;\r\n  options = options || {};\r\n  self._connectCallbacks = [];\r\n  self._observeMultiplexers = {};\r\n  self._onFailoverHook = new Hook;\r\n\r\n  var mongoOptions = {db: {safe: true}, server: {}, replSet: {}};\r\n\r\n  // Set autoReconnect to true, unless passed on the URL. Why someone\r\n  // would want to set autoReconnect to false, I'm not really sure, but\r\n  // keeping this for backwards compatibility for now.\r\n  if (!(/[\\?&]auto_?[rR]econnect=/.test(url))) {\r\n    mongoOptions.server.auto_reconnect = true;\r\n  }\r\n\r\n  // Disable the native parser by default, unless specifically enabled\r\n  // in the mongo URL.\r\n  // - The native driver can cause errors which normally would be\r\n  //   thrown, caught, and handled into segfaults that take down the\r\n  //   whole app.\r\n  // - Binary modules don't yet work when you bundle and move the bundle\r\n  //   to a different platform (aka deploy)\r\n  // We should revisit this after binary npm module support lands.\r\n  if (!(/[\\?&]native_?[pP]arser=/.test(url))) {\r\n    mongoOptions.db.native_parser = false;\r\n  }\r\n\r\n  // XXX maybe we should have a better way of allowing users to configure the\r\n  // underlying Mongo driver\r\n  if (_.has(options, 'poolSize')) {\r\n    // If we just set this for \"server\", replSet will override it. If we just\r\n    // set it for replSet, it will be ignored if we're not using a replSet.\r\n    mongoOptions.server.poolSize = options.poolSize;\r\n    mongoOptions.replSet.poolSize = options.poolSize;\r\n  }\r\n\r\n  MongoDB.connect(url, mongoOptions, Meteor.bindEnvironment(function(err, db) {\r\n    if (err)\r\n      throw err;\r\n    self.db = db;\r\n    // We keep track of the ReplSet's primary, so that we can trigger hooks when\r\n    // it changes.  The Node driver's joined callback seems to fire way too\r\n    // often, which is why we need to track it ourselves.\r\n    self._primary = null;\r\n    // First, figure out what the current primary is, if any.\r\n    if (self.db.serverConfig._state.master)\r\n      self._primary = self.db.serverConfig._state.master.name;\r\n    self.db.serverConfig.on(\r\n      'joined', Meteor.bindEnvironment(function (kind, doc) {\r\n        if (kind === 'primary') {\r\n          if (doc.primary !== self._primary) {\r\n            self._primary = doc.primary;\r\n            self._onFailoverHook.each(function (callback) {\r\n              callback();\r\n              return true;\r\n            });\r\n          }\r\n        } else if (doc.me === self._primary) {\r\n          // The thing we thought was primary is now something other than\r\n          // primary.  Forget that we thought it was primary.  (This means that\r\n          // if a server stops being primary and then starts being primary again\r\n          // without another server becoming primary in the middle, we'll\r\n          // correctly count it as a failover.)\r\n          self._primary = null;\r\n        }\r\n    }));\r\n\r\n    // drain queue of pending callbacks\r\n    _.each(self._connectCallbacks, function (c) {\r\n      c(db);\r\n    });\r\n  }));\r\n\r\n  self._docFetcher = new DocFetcher(self);\r\n  self._oplogHandle = null;\r\n\r\n  if (options.oplogUrl && !Package['disable-oplog']) {\r\n    var dbNameFuture = new Future;\r\n    self._withDb(function (db) {\r\n      dbNameFuture.return(db.databaseName);\r\n    });\r\n    self._oplogHandle = new OplogHandle(options.oplogUrl, dbNameFuture.wait());\r\n  }\r\n};\r\n\r\nMongoConnection.prototype.close = function() {\r\n  var self = this;\r\n\r\n  // XXX probably untested\r\n  var oplogHandle = self._oplogHandle;\r\n  self._oplogHandle = null;\r\n  if (oplogHandle)\r\n    oplogHandle.stop();\r\n\r\n  // Use Future.wrap so that errors get thrown. This happens to\r\n  // work even outside a fiber since the 'close' method is not\r\n  // actually asynchronous.\r\n  Future.wrap(_.bind(self.db.close, self.db))(true).wait();\r\n};\r\n\r\nMongoConnection.prototype._withDb = function (callback) {\r\n  var self = this;\r\n  if (self.db) {\r\n    callback(self.db);\r\n  } else {\r\n    self._connectCallbacks.push(callback);\r\n  }\r\n};\r\n\r\n// Returns the Mongo Collection object; may yield.\r\nMongoConnection.prototype._getCollection = function (collectionName) {\r\n  var self = this;\r\n\r\n  var future = new Future;\r\n  self._withDb(function (db) {\r\n    db.collection(collectionName, future.resolver());\r\n  });\r\n  return future.wait();\r\n};\r\n\r\nMongoConnection.prototype._createCappedCollection = function (collectionName,\r\n                                                              byteSize) {\r\n  var self = this;\r\n  var future = new Future();\r\n  self._withDb(function (db) {\r\n    db.createCollection(collectionName, {capped: true, size: byteSize},\r\n                        future.resolver());\r\n  });\r\n  future.wait();\r\n};\r\n\r\n// This should be called synchronously with a write, to create a\r\n// transaction on the current write fence, if any. After we can read\r\n// the write, and after observers have been notified (or at least,\r\n// after the observer notifiers have added themselves to the write\r\n// fence), you should call 'committed()' on the object returned.\r\nMongoConnection.prototype._maybeBeginWrite = function () {\r\n  var self = this;\r\n  var fence = DDPServer._CurrentWriteFence.get();\r\n  if (fence)\r\n    return fence.beginWrite();\r\n  else\r\n    return {committed: function () {}};\r\n};\r\n\r\n// Internal interface: adds a callback which is called when the Mongo primary\r\n// changes. Returns a stop handle.\r\nMongoConnection.prototype._onFailover = function (callback) {\r\n  return this._onFailoverHook.register(callback);\r\n};\r\n\r\n\r\n//////////// Public API //////////\r\n\r\n// The write methods block until the database has confirmed the write (it may\r\n// not be replicated or stable on disk, but one server has confirmed it) if no\r\n// callback is provided. If a callback is provided, then they call the callback\r\n// when the write is confirmed. They return nothing on success, and raise an\r\n// exception on failure.\r\n//\r\n// After making a write (with insert, update, remove), observers are\r\n// notified asynchronously. If you want to receive a callback once all\r\n// of the observer notifications have landed for your write, do the\r\n// writes inside a write fence (set DDPServer._CurrentWriteFence to a new\r\n// _WriteFence, and then set a callback on the write fence.)\r\n//\r\n// Since our execution environment is single-threaded, this is\r\n// well-defined -- a write \"has been made\" if it's returned, and an\r\n// observer \"has been notified\" if its callback has returned.\r\n\r\nvar writeCallback = function (write, refresh, callback) {\r\n  return function (err, result) {\r\n    if (! err) {\r\n      // XXX We don't have to run this on error, right?\r\n      refresh();\r\n    }\r\n    write.committed();\r\n    if (callback)\r\n      callback(err, result);\r\n    else if (err)\r\n      throw err;\r\n  };\r\n};\r\n\r\nvar bindEnvironmentForWrite = function (callback) {\r\n  return Meteor.bindEnvironment(callback, \"Mongo write\");\r\n};\r\n\r\nMongoConnection.prototype._insert = function (collection_name, document,\r\n                                              callback) {\r\n  var self = this;\r\n\r\n  var sendError = function (e) {\r\n    if (callback)\r\n      return callback(e);\r\n    throw e;\r\n  };\r\n\r\n  if (collection_name === \"___meteor_failure_test_collection\") {\r\n    var e = new Error(\"Failure test\");\r\n    e.expected = true;\r\n    sendError(e);\r\n    return;\r\n  }\r\n\r\n  if (!(LocalCollection._isPlainObject(document) &&\r\n        !EJSON._isCustomType(document))) {\r\n    sendError(new Error(\r\n      \"Only documents (plain objects) may be inserted into MongoDB\"));\r\n    return;\r\n  }\r\n\r\n  var write = self._maybeBeginWrite();\r\n  var refresh = function () {\r\n    Meteor.refresh({collection: collection_name, id: document._id });\r\n  };\r\n  callback = bindEnvironmentForWrite(writeCallback(write, refresh, callback));\r\n  try {\r\n    var collection = self._getCollection(collection_name);\r\n    collection.insert(replaceTypes(document, replaceMeteorAtomWithMongo),\r\n                      {safe: true}, callback);\r\n  } catch (e) {\r\n    write.committed();\r\n    throw e;\r\n  }\r\n};\r\n\r\n// Cause queries that may be affected by the selector to poll in this write\r\n// fence.\r\nMongoConnection.prototype._refresh = function (collectionName, selector) {\r\n  var self = this;\r\n  var refreshKey = {collection: collectionName};\r\n  // If we know which documents we're removing, don't poll queries that are\r\n  // specific to other documents. (Note that multiple notifications here should\r\n  // not cause multiple polls, since all our listener is doing is enqueueing a\r\n  // poll.)\r\n  var specificIds = LocalCollection._idsMatchedBySelector(selector);\r\n  if (specificIds) {\r\n    _.each(specificIds, function (id) {\r\n      Meteor.refresh(_.extend({id: id}, refreshKey));\r\n    });\r\n  } else {\r\n    Meteor.refresh(refreshKey);\r\n  }\r\n};\r\n\r\nMongoConnection.prototype._remove = function (collection_name, selector,\r\n                                              callback) {\r\n  var self = this;\r\n\r\n  if (collection_name === \"___meteor_failure_test_collection\") {\r\n    var e = new Error(\"Failure test\");\r\n    e.expected = true;\r\n    if (callback)\r\n      return callback(e);\r\n    else\r\n      throw e;\r\n  }\r\n\r\n  var write = self._maybeBeginWrite();\r\n  var refresh = function () {\r\n    self._refresh(collection_name, selector);\r\n  };\r\n  callback = bindEnvironmentForWrite(writeCallback(write, refresh, callback));\r\n\r\n  try {\r\n    var collection = self._getCollection(collection_name);\r\n    collection.remove(replaceTypes(selector, replaceMeteorAtomWithMongo),\r\n                      {safe: true}, callback);\r\n  } catch (e) {\r\n    write.committed();\r\n    throw e;\r\n  }\r\n};\r\n\r\nMongoConnection.prototype._dropCollection = function (collectionName, cb) {\r\n  var self = this;\r\n\r\n  var write = self._maybeBeginWrite();\r\n  var refresh = function () {\r\n    Meteor.refresh({collection: collectionName, id: null,\r\n                    dropCollection: true});\r\n  };\r\n  cb = bindEnvironmentForWrite(writeCallback(write, refresh, cb));\r\n\r\n  try {\r\n    var collection = self._getCollection(collectionName);\r\n    collection.drop(cb);\r\n  } catch (e) {\r\n    write.committed();\r\n    throw e;\r\n  }\r\n};\r\n\r\nMongoConnection.prototype._update = function (collection_name, selector, mod,\r\n                                              options, callback) {\r\n  var self = this;\r\n\r\n  if (! callback && options instanceof Function) {\r\n    callback = options;\r\n    options = null;\r\n  }\r\n\r\n  if (collection_name === \"___meteor_failure_test_collection\") {\r\n    var e = new Error(\"Failure test\");\r\n    e.expected = true;\r\n    if (callback)\r\n      return callback(e);\r\n    else\r\n      throw e;\r\n  }\r\n\r\n  // explicit safety check. null and undefined can crash the mongo\r\n  // driver. Although the node driver and minimongo do 'support'\r\n  // non-object modifier in that they don't crash, they are not\r\n  // meaningful operations and do not do anything. Defensively throw an\r\n  // error here.\r\n  if (!mod || typeof mod !== 'object')\r\n    throw new Error(\"Invalid modifier. Modifier must be an object.\");\r\n\r\n  if (!options) options = {};\r\n\r\n  var write = self._maybeBeginWrite();\r\n  var refresh = function () {\r\n    self._refresh(collection_name, selector);\r\n  };\r\n  callback = writeCallback(write, refresh, callback);\r\n  try {\r\n    var collection = self._getCollection(collection_name);\r\n    var mongoOpts = {safe: true};\r\n    // explictly enumerate options that minimongo supports\r\n    if (options.upsert) mongoOpts.upsert = true;\r\n    if (options.multi) mongoOpts.multi = true;\r\n\r\n    var mongoSelector = replaceTypes(selector, replaceMeteorAtomWithMongo);\r\n    var mongoMod = replaceTypes(mod, replaceMeteorAtomWithMongo);\r\n\r\n    var isModify = isModificationMod(mongoMod);\r\n    var knownId = (isModify ? selector._id : mod._id);\r\n\r\n    if (options.upsert && (! knownId) && options.insertedId) {\r\n      // XXX In future we could do a real upsert for the mongo id generation\r\n      // case, if the the node mongo driver gives us back the id of the upserted\r\n      // doc (which our current version does not).\r\n      simulateUpsertWithInsertedId(\r\n        collection, mongoSelector, mongoMod,\r\n        isModify, options,\r\n        // This callback does not need to be bindEnvironment'ed because\r\n        // simulateUpsertWithInsertedId() wraps it and then passes it through\r\n        // bindEnvironmentForWrite.\r\n        function (err, result) {\r\n          // If we got here via a upsert() call, then options._returnObject will\r\n          // be set and we should return the whole object. Otherwise, we should\r\n          // just return the number of affected docs to match the mongo API.\r\n          if (result && ! options._returnObject)\r\n            callback(err, result.numberAffected);\r\n          else\r\n            callback(err, result);\r\n        }\r\n      );\r\n    } else {\r\n      collection.update(\r\n        mongoSelector, mongoMod, mongoOpts,\r\n        bindEnvironmentForWrite(function (err, result, extra) {\r\n          if (! err) {\r\n            if (result && options._returnObject) {\r\n              result = { numberAffected: result };\r\n              // If this was an upsert() call, and we ended up\r\n              // inserting a new doc and we know its id, then\r\n              // return that id as well.\r\n              if (options.upsert && knownId &&\r\n                  ! extra.updatedExisting)\r\n                result.insertedId = knownId;\r\n            }\r\n          }\r\n          callback(err, result);\r\n        }));\r\n    }\r\n  } catch (e) {\r\n    write.committed();\r\n    throw e;\r\n  }\r\n};\r\n\r\nvar isModificationMod = function (mod) {\r\n  for (var k in mod)\r\n    if (k.substr(0, 1) === '$')\r\n      return true;\r\n  return false;\r\n};\r\n\r\nvar NUM_OPTIMISTIC_TRIES = 3;\r\n\r\n// exposed for testing\r\nMongoConnection._isCannotChangeIdError = function (err) {\r\n  // either of these checks should work, but just to be safe...\r\n  return (err.code === 13596 ||\r\n          err.err.indexOf(\"cannot change _id of a document\") === 0);\r\n};\r\n\r\nvar simulateUpsertWithInsertedId = function (collection, selector, mod,\r\n                                             isModify, options, callback) {\r\n  // STRATEGY:  First try doing a plain update.  If it affected 0 documents,\r\n  // then without affecting the database, we know we should probably do an\r\n  // insert.  We then do a *conditional* insert that will fail in the case\r\n  // of a race condition.  This conditional insert is actually an\r\n  // upsert-replace with an _id, which will never successfully update an\r\n  // existing document.  If this upsert fails with an error saying it\r\n  // couldn't change an existing _id, then we know an intervening write has\r\n  // caused the query to match something.  We go back to step one and repeat.\r\n  // Like all \"optimistic write\" schemes, we rely on the fact that it's\r\n  // unlikely our writes will continue to be interfered with under normal\r\n  // circumstances (though sufficiently heavy contention with writers\r\n  // disagreeing on the existence of an object will cause writes to fail\r\n  // in theory).\r\n\r\n  var newDoc;\r\n  // Run this code up front so that it fails fast if someone uses\r\n  // a Mongo update operator we don't support.\r\n  if (isModify) {\r\n    // We've already run replaceTypes/replaceMeteorAtomWithMongo on\r\n    // selector and mod.  We assume it doesn't matter, as far as\r\n    // the behavior of modifiers is concerned, whether `_modify`\r\n    // is run on EJSON or on mongo-converted EJSON.\r\n    var selectorDoc = LocalCollection._removeDollarOperators(selector);\r\n    LocalCollection._modify(selectorDoc, mod, {isInsert: true});\r\n    newDoc = selectorDoc;\r\n  } else {\r\n    newDoc = mod;\r\n  }\r\n\r\n  var insertedId = options.insertedId; // must exist\r\n  var mongoOptsForUpdate = {\r\n    safe: true,\r\n    multi: options.multi\r\n  };\r\n  var mongoOptsForInsert = {\r\n    safe: true,\r\n    upsert: true\r\n  };\r\n\r\n  var tries = NUM_OPTIMISTIC_TRIES;\r\n\r\n  var doUpdate = function () {\r\n    tries--;\r\n    if (! tries) {\r\n      callback(new Error(\"Upsert failed after \" + NUM_OPTIMISTIC_TRIES + \" tries.\"));\r\n    } else {\r\n      collection.update(selector, mod, mongoOptsForUpdate,\r\n                        bindEnvironmentForWrite(function (err, result) {\r\n                          if (err)\r\n                            callback(err);\r\n                          else if (result)\r\n                            callback(null, {\r\n                              numberAffected: result\r\n                            });\r\n                          else\r\n                            doConditionalInsert();\r\n                        }));\r\n    }\r\n  };\r\n\r\n  var doConditionalInsert = function () {\r\n    var replacementWithId = _.extend(\r\n      replaceTypes({_id: insertedId}, replaceMeteorAtomWithMongo),\r\n      newDoc);\r\n    collection.update(selector, replacementWithId, mongoOptsForInsert,\r\n                      bindEnvironmentForWrite(function (err, result) {\r\n                        if (err) {\r\n                          // figure out if this is a\r\n                          // \"cannot change _id of document\" error, and\r\n                          // if so, try doUpdate() again, up to 3 times.\r\n                          if (MongoConnection._isCannotChangeIdError(err)) {\r\n                            doUpdate();\r\n                          } else {\r\n                            callback(err);\r\n                          }\r\n                        } else {\r\n                          callback(null, {\r\n                            numberAffected: result,\r\n                            insertedId: insertedId\r\n                          });\r\n                        }\r\n                      }));\r\n  };\r\n\r\n  doUpdate();\r\n};\r\n\r\n_.each([\"insert\", \"update\", \"remove\", \"dropCollection\"], function (method) {\r\n  MongoConnection.prototype[method] = function (/* arguments */) {\r\n    var self = this;\r\n    return Meteor._wrapAsync(self[\"_\" + method]).apply(self, arguments);\r\n  };\r\n});\r\n\r\n// XXX MongoConnection.upsert() does not return the id of the inserted document\r\n// unless you set it explicitly in the selector or modifier (as a replacement\r\n// doc).\r\nMongoConnection.prototype.upsert = function (collectionName, selector, mod,\r\n                                             options, callback) {\r\n  var self = this;\r\n  if (typeof options === \"function\" && ! callback) {\r\n    callback = options;\r\n    options = {};\r\n  }\r\n\r\n  return self.update(collectionName, selector, mod,\r\n                     _.extend({}, options, {\r\n                       upsert: true,\r\n                       _returnObject: true\r\n                     }), callback);\r\n};\r\n\r\nMongoConnection.prototype.find = function (collectionName, selector, options) {\r\n  var self = this;\r\n\r\n  if (arguments.length === 1)\r\n    selector = {};\r\n\r\n  return new Cursor(\r\n    self, new CursorDescription(collectionName, selector, options));\r\n};\r\n\r\nMongoConnection.prototype.findOne = function (collection_name, selector,\r\n                                              options) {\r\n  var self = this;\r\n  if (arguments.length === 1)\r\n    selector = {};\r\n\r\n  options = options || {};\r\n  options.limit = 1;\r\n  return self.find(collection_name, selector, options).fetch()[0];\r\n};\r\n\r\n// We'll actually design an index API later. For now, we just pass through to\r\n// Mongo's, but make it synchronous.\r\nMongoConnection.prototype._ensureIndex = function (collectionName, index,\r\n                                                   options) {\r\n  var self = this;\r\n  options = _.extend({safe: true}, options);\r\n\r\n  // We expect this function to be called at startup, not from within a method,\r\n  // so we don't interact with the write fence.\r\n  var collection = self._getCollection(collectionName);\r\n  var future = new Future;\r\n  var indexName = collection.ensureIndex(index, options, future.resolver());\r\n  future.wait();\r\n};\r\nMongoConnection.prototype._dropIndex = function (collectionName, index) {\r\n  var self = this;\r\n\r\n  // This function is only used by test code, not within a method, so we don't\r\n  // interact with the write fence.\r\n  var collection = self._getCollection(collectionName);\r\n  var future = new Future;\r\n  var indexName = collection.dropIndex(index, future.resolver());\r\n  future.wait();\r\n};\r\n\r\n// CURSORS\r\n\r\n// There are several classes which relate to cursors:\r\n//\r\n// CursorDescription represents the arguments used to construct a cursor:\r\n// collectionName, selector, and (find) options.  Because it is used as a key\r\n// for cursor de-dup, everything in it should either be JSON-stringifiable or\r\n// not affect observeChanges output (eg, options.transform functions are not\r\n// stringifiable but do not affect observeChanges).\r\n//\r\n// SynchronousCursor is a wrapper around a MongoDB cursor\r\n// which includes fully-synchronous versions of forEach, etc.\r\n//\r\n// Cursor is the cursor object returned from find(), which implements the\r\n// documented Meteor.Collection cursor API.  It wraps a CursorDescription and a\r\n// SynchronousCursor (lazily: it doesn't contact Mongo until you call a method\r\n// like fetch or forEach on it).\r\n//\r\n// ObserveHandle is the \"observe handle\" returned from observeChanges. It has a\r\n// reference to an ObserveMultiplexer.\r\n//\r\n// ObserveMultiplexer allows multiple identical ObserveHandles to be driven by a\r\n// single observe driver.\r\n//\r\n// There are two \"observe drivers\" which drive ObserveMultiplexers:\r\n//   - PollingObserveDriver caches the results of a query and reruns it when\r\n//     necessary.\r\n//   - OplogObserveDriver follows the Mongo operation log to directly observe\r\n//     database changes.\r\n// Both implementations follow the same simple interface: when you create them,\r\n// they start sending observeChanges callbacks (and a ready() invocation) to\r\n// their ObserveMultiplexer, and you stop them by calling their stop() method.\r\n\r\nCursorDescription = function (collectionName, selector, options) {\r\n  var self = this;\r\n  self.collectionName = collectionName;\r\n  self.selector = Meteor.Collection._rewriteSelector(selector);\r\n  self.options = options || {};\r\n};\r\n\r\nCursor = function (mongo, cursorDescription) {\r\n  var self = this;\r\n\r\n  self._mongo = mongo;\r\n  self._cursorDescription = cursorDescription;\r\n  self._synchronousCursor = null;\r\n};\r\n\r\n_.each(['forEach', 'map', 'fetch', 'count'], function (method) {\r\n  Cursor.prototype[method] = function () {\r\n    var self = this;\r\n\r\n    // You can only observe a tailable cursor.\r\n    if (self._cursorDescription.options.tailable)\r\n      throw new Error(\"Cannot call \" + method + \" on a tailable cursor\");\r\n\r\n    if (!self._synchronousCursor) {\r\n      self._synchronousCursor = self._mongo._createSynchronousCursor(\r\n        self._cursorDescription, {\r\n          // Make sure that the \"self\" argument to forEach/map callbacks is the\r\n          // Cursor, not the SynchronousCursor.\r\n          selfForIteration: self,\r\n          useTransform: true\r\n        });\r\n    }\r\n\r\n    return self._synchronousCursor[method].apply(\r\n      self._synchronousCursor, arguments);\r\n  };\r\n});\r\n\r\n// Since we don't actually have a \"nextObject\" interface, there's really no\r\n// reason to have a \"rewind\" interface.  All it did was make multiple calls\r\n// to fetch/map/forEach return nothing the second time.\r\n// XXX COMPAT WITH 0.8.1\r\nCursor.prototype.rewind = function () {\r\n};\r\n\r\nCursor.prototype.getTransform = function () {\r\n  return this._cursorDescription.options.transform;\r\n};\r\n\r\n// When you call Meteor.publish() with a function that returns a Cursor, we need\r\n// to transmute it into the equivalent subscription.  This is the function that\r\n// does that.\r\n\r\nCursor.prototype._publishCursor = function (sub) {\r\n  var self = this;\r\n  var collection = self._cursorDescription.collectionName;\r\n  return Meteor.Collection._publishCursor(self, sub, collection);\r\n};\r\n\r\n// Used to guarantee that publish functions return at most one cursor per\r\n// collection. Private, because we might later have cursors that include\r\n// documents from multiple collections somehow.\r\nCursor.prototype._getCollectionName = function () {\r\n  var self = this;\r\n  return self._cursorDescription.collectionName;\r\n}\r\n\r\nCursor.prototype.observe = function (callbacks) {\r\n  var self = this;\r\n  return LocalCollection._observeFromObserveChanges(self, callbacks);\r\n};\r\n\r\nCursor.prototype.observeChanges = function (callbacks) {\r\n  var self = this;\r\n  var ordered = LocalCollection._observeChangesCallbacksAreOrdered(callbacks);\r\n  return self._mongo._observeChanges(\r\n    self._cursorDescription, ordered, callbacks);\r\n};\r\n\r\nMongoConnection.prototype._createSynchronousCursor = function(\r\n    cursorDescription, options) {\r\n  var self = this;\r\n  options = _.pick(options || {}, 'selfForIteration', 'useTransform');\r\n\r\n  var collection = self._getCollection(cursorDescription.collectionName);\r\n  var cursorOptions = cursorDescription.options;\r\n  var mongoOptions = {\r\n    sort: cursorOptions.sort,\r\n    limit: cursorOptions.limit,\r\n    skip: cursorOptions.skip\r\n  };\r\n\r\n  // Do we want a tailable cursor (which only works on capped collections)?\r\n  if (cursorOptions.tailable) {\r\n    // We want a tailable cursor...\r\n    mongoOptions.tailable = true;\r\n    // ... and for the server to wait a bit if any getMore has no data (rather\r\n    // than making us put the relevant sleeps in the client)...\r\n    mongoOptions.awaitdata = true;\r\n    // ... and to keep querying the server indefinitely rather than just 5 times\r\n    // if there's no more data.\r\n    mongoOptions.numberOfRetries = -1;\r\n    // And if this is on the oplog collection and the cursor specifies a 'ts',\r\n    // then set the undocumented oplog replay flag, which does a special scan to\r\n    // find the first document (instead of creating an index on ts). This is a\r\n    // very hard-coded Mongo flag which only works on the oplog collection and\r\n    // only works with the ts field.\r\n    if (cursorDescription.collectionName === OPLOG_COLLECTION &&\r\n        cursorDescription.selector.ts) {\r\n      mongoOptions.oplogReplay = true;\r\n    }\r\n  }\r\n\r\n  var dbCursor = collection.find(\r\n    replaceTypes(cursorDescription.selector, replaceMeteorAtomWithMongo),\r\n    cursorOptions.fields, mongoOptions);\r\n\r\n  return new SynchronousCursor(dbCursor, cursorDescription, options);\r\n};\r\n\r\nvar SynchronousCursor = function (dbCursor, cursorDescription, options) {\r\n  var self = this;\r\n  options = _.pick(options || {}, 'selfForIteration', 'useTransform');\r\n\r\n  self._dbCursor = dbCursor;\r\n  self._cursorDescription = cursorDescription;\r\n  // The \"self\" argument passed to forEach/map callbacks. If we're wrapped\r\n  // inside a user-visible Cursor, we want to provide the outer cursor!\r\n  self._selfForIteration = options.selfForIteration || self;\r\n  if (options.useTransform && cursorDescription.options.transform) {\r\n    self._transform = LocalCollection.wrapTransform(\r\n      cursorDescription.options.transform);\r\n  } else {\r\n    self._transform = null;\r\n  }\r\n\r\n  // Need to specify that the callback is the first argument to nextObject,\r\n  // since otherwise when we try to call it with no args the driver will\r\n  // interpret \"undefined\" first arg as an options hash and crash.\r\n  self._synchronousNextObject = Future.wrap(\r\n    dbCursor.nextObject.bind(dbCursor), 0);\r\n  self._synchronousCount = Future.wrap(dbCursor.count.bind(dbCursor));\r\n  self._visitedIds = new LocalCollection._IdMap;\r\n};\r\n\r\n_.extend(SynchronousCursor.prototype, {\r\n  _nextObject: function () {\r\n    var self = this;\r\n\r\n    while (true) {\r\n      var doc = self._synchronousNextObject().wait();\r\n\r\n      if (!doc) return null;\r\n      doc = replaceTypes(doc, replaceMongoAtomWithMeteor);\r\n\r\n      if (!self._cursorDescription.options.tailable && _.has(doc, '_id')) {\r\n        // Did Mongo give us duplicate documents in the same cursor? If so,\r\n        // ignore this one. (Do this before the transform, since transform might\r\n        // return some unrelated value.) We don't do this for tailable cursors,\r\n        // because we want to maintain O(1) memory usage. And if there isn't _id\r\n        // for some reason (maybe it's the oplog), then we don't do this either.\r\n        // (Be careful to do this for falsey but existing _id, though.)\r\n        if (self._visitedIds.has(doc._id)) continue;\r\n        self._visitedIds.set(doc._id, true);\r\n      }\r\n\r\n      if (self._transform)\r\n        doc = self._transform(doc);\r\n\r\n      return doc;\r\n    }\r\n  },\r\n\r\n  forEach: function (callback, thisArg) {\r\n    var self = this;\r\n\r\n    // Get back to the beginning.\r\n    self._rewind();\r\n\r\n    // We implement the loop ourself instead of using self._dbCursor.each,\r\n    // because \"each\" will call its callback outside of a fiber which makes it\r\n    // much more complex to make this function synchronous.\r\n    var index = 0;\r\n    while (true) {\r\n      var doc = self._nextObject();\r\n      if (!doc) return;\r\n      callback.call(thisArg, doc, index++, self._selfForIteration);\r\n    }\r\n  },\r\n\r\n  // XXX Allow overlapping callback executions if callback yields.\r\n  map: function (callback, thisArg) {\r\n    var self = this;\r\n    var res = [];\r\n    self.forEach(function (doc, index) {\r\n      res.push(callback.call(thisArg, doc, index, self._selfForIteration));\r\n    });\r\n    return res;\r\n  },\r\n\r\n  _rewind: function () {\r\n    var self = this;\r\n\r\n    // known to be synchronous\r\n    self._dbCursor.rewind();\r\n\r\n    self._visitedIds = new LocalCollection._IdMap;\r\n  },\r\n\r\n  // Mostly usable for tailable cursors.\r\n  close: function () {\r\n    var self = this;\r\n\r\n    self._dbCursor.close();\r\n  },\r\n\r\n  fetch: function () {\r\n    var self = this;\r\n    return self.map(_.identity);\r\n  },\r\n\r\n  count: function () {\r\n    var self = this;\r\n    return self._synchronousCount().wait();\r\n  },\r\n\r\n  // This method is NOT wrapped in Cursor.\r\n  getRawObjects: function (ordered) {\r\n    var self = this;\r\n    if (ordered) {\r\n      return self.fetch();\r\n    } else {\r\n      var results = new LocalCollection._IdMap;\r\n      self.forEach(function (doc) {\r\n        results.set(doc._id, doc);\r\n      });\r\n      return results;\r\n    }\r\n  }\r\n});\r\n\r\nMongoConnection.prototype.tail = function (cursorDescription, docCallback) {\r\n  var self = this;\r\n  if (!cursorDescription.options.tailable)\r\n    throw new Error(\"Can only tail a tailable cursor\");\r\n\r\n  var cursor = self._createSynchronousCursor(cursorDescription);\r\n\r\n  var stopped = false;\r\n  var lastTS = undefined;\r\n  var loop = function () {\r\n    while (true) {\r\n      if (stopped)\r\n        return;\r\n      try {\r\n        var doc = cursor._nextObject();\r\n      } catch (err) {\r\n        // There's no good way to figure out if this was actually an error\r\n        // from Mongo. Ah well. But either way, we need to retry the cursor\r\n        // (unless the failure was because the observe got stopped).\r\n        doc = null;\r\n      }\r\n      // Since cursor._nextObject can yield, we need to check again to see if\r\n      // we've been stopped before calling the callback.\r\n      if (stopped)\r\n        return;\r\n      if (doc) {\r\n        // If a tailable cursor contains a \"ts\" field, use it to recreate the\r\n        // cursor on error. (\"ts\" is a standard that Mongo uses internally for\r\n        // the oplog, and there's a special flag that lets you do binary search\r\n        // on it instead of needing to use an index.)\r\n        lastTS = doc.ts;\r\n        docCallback(doc);\r\n      } else {\r\n        var newSelector = _.clone(cursorDescription.selector);\r\n        if (lastTS) {\r\n          newSelector.ts = {$gt: lastTS};\r\n        }\r\n        cursor = self._createSynchronousCursor(new CursorDescription(\r\n          cursorDescription.collectionName,\r\n          newSelector,\r\n          cursorDescription.options));\r\n        // Mongo failover takes many seconds.  Retry in a bit.  (Without this\r\n        // setTimeout, we peg the CPU at 100% and never notice the actual\r\n        // failover.\r\n        Meteor.setTimeout(loop, 100);\r\n        break;\r\n      }\r\n    }\r\n  };\r\n\r\n  Meteor.defer(loop);\r\n\r\n  return {\r\n    stop: function () {\r\n      stopped = true;\r\n      cursor.close();\r\n    }\r\n  };\r\n};\r\n\r\nMongoConnection.prototype._observeChanges = function (\r\n    cursorDescription, ordered, callbacks) {\r\n  var self = this;\r\n\r\n  if (cursorDescription.options.tailable) {\r\n    return self._observeChangesTailable(cursorDescription, ordered, callbacks);\r\n  }\r\n\r\n  // You may not filter out _id when observing changes, because the id is a core\r\n  // part of the observeChanges API.\r\n  if (cursorDescription.options.fields &&\r\n      (cursorDescription.options.fields._id === 0 ||\r\n       cursorDescription.options.fields._id === false)) {\r\n    throw Error(\"You may not observe a cursor with {fields: {_id: 0}}\");\r\n  }\r\n\r\n  var observeKey = JSON.stringify(\r\n    _.extend({ordered: ordered}, cursorDescription));\r\n\r\n  var multiplexer, observeDriver;\r\n  var firstHandle = false;\r\n\r\n  // Find a matching ObserveMultiplexer, or create a new one. This next block is\r\n  // guaranteed to not yield (and it doesn't call anything that can observe a\r\n  // new query), so no other calls to this function can interleave with it.\r\n  Meteor._noYieldsAllowed(function () {\r\n    if (_.has(self._observeMultiplexers, observeKey)) {\r\n      multiplexer = self._observeMultiplexers[observeKey];\r\n    } else {\r\n      firstHandle = true;\r\n      // Create a new ObserveMultiplexer.\r\n      multiplexer = new ObserveMultiplexer({\r\n        ordered: ordered,\r\n        onStop: function () {\r\n          observeDriver.stop();\r\n          delete self._observeMultiplexers[observeKey];\r\n        }\r\n      });\r\n      self._observeMultiplexers[observeKey] = multiplexer;\r\n    }\r\n  });\r\n\r\n  var observeHandle = new ObserveHandle(multiplexer, callbacks);\r\n\r\n  if (firstHandle) {\r\n    var matcher, sorter;\r\n    var canUseOplog = _.all([\r\n      function () {\r\n        // At a bare minimum, using the oplog requires us to have an oplog, to\r\n        // want unordered callbacks, and to not want a callback on the polls\r\n        // that won't happen.\r\n        return self._oplogHandle && !ordered &&\r\n          !callbacks._testOnlyPollCallback;\r\n      }, function () {\r\n        // We need to be able to compile the selector. Fall back to polling for\r\n        // some newfangled $selector that minimongo doesn't support yet.\r\n        try {\r\n          matcher = new Minimongo.Matcher(cursorDescription.selector);\r\n          return true;\r\n        } catch (e) {\r\n          // XXX make all compilation errors MinimongoError or something\r\n          //     so that this doesn't ignore unrelated exceptions\r\n          return false;\r\n        }\r\n      }, function () {\r\n        // ... and the selector itself needs to support oplog.\r\n        return OplogObserveDriver.cursorSupported(cursorDescription, matcher);\r\n      }, function () {\r\n        // And we need to be able to compile the sort, if any.  eg, can't be\r\n        // {$natural: 1}.\r\n        if (!cursorDescription.options.sort)\r\n          return true;\r\n        try {\r\n          sorter = new Minimongo.Sorter(cursorDescription.options.sort,\r\n                                        { matcher: matcher });\r\n          return true;\r\n        } catch (e) {\r\n          // XXX make all compilation errors MinimongoError or something\r\n          //     so that this doesn't ignore unrelated exceptions\r\n          return false;\r\n        }\r\n      }], function (f) { return f(); });  // invoke each function\r\n\r\n    var driverClass = canUseOplog ? OplogObserveDriver : PollingObserveDriver;\r\n    observeDriver = new driverClass({\r\n      cursorDescription: cursorDescription,\r\n      mongoHandle: self,\r\n      multiplexer: multiplexer,\r\n      ordered: ordered,\r\n      matcher: matcher,  // ignored by polling\r\n      sorter: sorter,  // ignored by polling\r\n      _testOnlyPollCallback: callbacks._testOnlyPollCallback\r\n    });\r\n\r\n    // This field is only set for use in tests.\r\n    multiplexer._observeDriver = observeDriver;\r\n  }\r\n\r\n  // Blocks until the initial adds have been sent.\r\n  multiplexer.addHandleAndSendInitialAdds(observeHandle);\r\n\r\n  return observeHandle;\r\n};\r\n\r\n// Listen for the invalidation messages that will trigger us to poll the\r\n// database for changes. If this selector specifies specific IDs, specify them\r\n// here, so that updates to different specific IDs don't cause us to poll.\r\n// listenCallback is the same kind of (notification, complete) callback passed\r\n// to InvalidationCrossbar.listen.\r\n\r\nlistenAll = function (cursorDescription, listenCallback) {\r\n  var listeners = [];\r\n  forEachTrigger(cursorDescription, function (trigger) {\r\n    listeners.push(DDPServer._InvalidationCrossbar.listen(\r\n      trigger, listenCallback));\r\n  });\r\n\r\n  return {\r\n    stop: function () {\r\n      _.each(listeners, function (listener) {\r\n        listener.stop();\r\n      });\r\n    }\r\n  };\r\n};\r\n\r\nforEachTrigger = function (cursorDescription, triggerCallback) {\r\n  var key = {collection: cursorDescription.collectionName};\r\n  var specificIds = LocalCollection._idsMatchedBySelector(\r\n    cursorDescription.selector);\r\n  if (specificIds) {\r\n    _.each(specificIds, function (id) {\r\n      triggerCallback(_.extend({id: id}, key));\r\n    });\r\n    triggerCallback(_.extend({dropCollection: true, id: null}, key));\r\n  } else {\r\n    triggerCallback(key);\r\n  }\r\n};\r\n\r\n// observeChanges for tailable cursors on capped collections.\r\n//\r\n// Some differences from normal cursors:\r\n//   - Will never produce anything other than 'added' or 'addedBefore'. If you\r\n//     do update a document that has already been produced, this will not notice\r\n//     it.\r\n//   - If you disconnect and reconnect from Mongo, it will essentially restart\r\n//     the query, which will lead to duplicate results. This is pretty bad,\r\n//     but if you include a field called 'ts' which is inserted as\r\n//     new MongoInternals.MongoTimestamp(0, 0) (which is initialized to the\r\n//     current Mongo-style timestamp), we'll be able to find the place to\r\n//     restart properly. (This field is specifically understood by Mongo with an\r\n//     optimization which allows it to find the right place to start without\r\n//     an index on ts. It's how the oplog works.)\r\n//   - No callbacks are triggered synchronously with the call (there's no\r\n//     differentiation between \"initial data\" and \"later changes\"; everything\r\n//     that matches the query gets sent asynchronously).\r\n//   - De-duplication is not implemented.\r\n//   - Does not yet interact with the write fence. Probably, this should work by\r\n//     ignoring removes (which don't work on capped collections) and updates\r\n//     (which don't affect tailable cursors), and just keeping track of the ID\r\n//     of the inserted object, and closing the write fence once you get to that\r\n//     ID (or timestamp?).  This doesn't work well if the document doesn't match\r\n//     the query, though.  On the other hand, the write fence can close\r\n//     immediately if it does not match the query. So if we trust minimongo\r\n//     enough to accurately evaluate the query against the write fence, we\r\n//     should be able to do this...  Of course, minimongo doesn't even support\r\n//     Mongo Timestamps yet.\r\nMongoConnection.prototype._observeChangesTailable = function (\r\n    cursorDescription, ordered, callbacks) {\r\n  var self = this;\r\n\r\n  // Tailable cursors only ever call added/addedBefore callbacks, so it's an\r\n  // error if you didn't provide them.\r\n  if ((ordered && !callbacks.addedBefore) ||\r\n      (!ordered && !callbacks.added)) {\r\n    throw new Error(\"Can't observe an \" + (ordered ? \"ordered\" : \"unordered\")\r\n                    + \" tailable cursor without a \"\r\n                    + (ordered ? \"addedBefore\" : \"added\") + \" callback\");\r\n  }\r\n\r\n  return self.tail(cursorDescription, function (doc) {\r\n    var id = doc._id;\r\n    delete doc._id;\r\n    // The ts is an implementation detail. Hide it.\r\n    delete doc.ts;\r\n    if (ordered) {\r\n      callbacks.addedBefore(id, doc, null);\r\n    } else {\r\n      callbacks.added(id, doc);\r\n    }\r\n  });\r\n};\r\n\r\n// XXX We probably need to find a better way to expose this. Right now\r\n// it's only used by tests, but in fact you need it in normal\r\n// operation to interact with capped collections (eg, Galaxy uses it).\r\nMongoInternals.MongoTimestamp = MongoDB.Timestamp;\r\n\r\nMongoInternals.Connection = MongoConnection;\r\nMongoInternals.NpmModule = MongoDB;\r\n","var Future = Npm.require('fibers/future');\r\n\r\nOPLOG_COLLECTION = 'oplog.rs';\r\nvar REPLSET_COLLECTION = 'system.replset';\r\n\r\n// Like Perl's quotemeta: quotes all regexp metacharacters. See\r\n//   https://github.com/substack/quotemeta/blob/master/index.js\r\n// XXX this is duplicated with accounts_server.js\r\nvar quotemeta = function (str) {\r\n    return String(str).replace(/(\\W)/g, '\\\\$1');\r\n};\r\n\r\nvar showTS = function (ts) {\r\n  return \"Timestamp(\" + ts.getHighBits() + \", \" + ts.getLowBits() + \")\";\r\n};\r\n\r\nidForOp = function (op) {\r\n  if (op.op === 'd')\r\n    return op.o._id;\r\n  else if (op.op === 'i')\r\n    return op.o._id;\r\n  else if (op.op === 'u')\r\n    return op.o2._id;\r\n  else if (op.op === 'c')\r\n    throw Error(\"Operator 'c' doesn't supply an object with id: \" +\r\n                EJSON.stringify(op));\r\n  else\r\n    throw Error(\"Unknown op: \" + EJSON.stringify(op));\r\n};\r\n\r\nOplogHandle = function (oplogUrl, dbName) {\r\n  var self = this;\r\n  self._oplogUrl = oplogUrl;\r\n  self._dbName = dbName;\r\n\r\n  self._oplogLastEntryConnection = null;\r\n  self._oplogTailConnection = null;\r\n  self._stopped = false;\r\n  self._tailHandle = null;\r\n  self._readyFuture = new Future();\r\n  self._crossbar = new DDPServer._Crossbar({\r\n    factPackage: \"mongo-livedata\", factName: \"oplog-watchers\"\r\n  });\r\n  self._lastProcessedTS = null;\r\n  self._baseOplogSelector = {\r\n    ns: new RegExp('^' + quotemeta(self._dbName) + '\\\\.'),\r\n    $or: [\r\n      { op: {$in: ['i', 'u', 'd']} },\r\n      // If it is not db.collection.drop(), ignore it\r\n      { op: 'c', 'o.drop': { $exists: true } }]\r\n  };\r\n  // XXX doc\r\n  self._catchingUpFutures = [];\r\n\r\n  self._startTailing();\r\n};\r\n\r\n_.extend(OplogHandle.prototype, {\r\n  stop: function () {\r\n    var self = this;\r\n    if (self._stopped)\r\n      return;\r\n    self._stopped = true;\r\n    if (self._tailHandle)\r\n      self._tailHandle.stop();\r\n    // XXX should close connections too\r\n  },\r\n  onOplogEntry: function (trigger, callback) {\r\n    var self = this;\r\n    if (self._stopped)\r\n      throw new Error(\"Called onOplogEntry on stopped handle!\");\r\n\r\n    // Calling onOplogEntry requires us to wait for the tailing to be ready.\r\n    self._readyFuture.wait();\r\n\r\n    var originalCallback = callback;\r\n    callback = Meteor.bindEnvironment(function (notification) {\r\n      // XXX can we avoid this clone by making oplog.js careful?\r\n      originalCallback(EJSON.clone(notification));\r\n    }, function (err) {\r\n      Meteor._debug(\"Error in oplog callback\", err.stack);\r\n    });\r\n    var listenHandle = self._crossbar.listen(trigger, callback);\r\n    return {\r\n      stop: function () {\r\n        listenHandle.stop();\r\n      }\r\n    };\r\n  },\r\n  // Calls `callback` once the oplog has been processed up to a point that is\r\n  // roughly \"now\": specifically, once we've processed all ops that are\r\n  // currently visible.\r\n  // XXX become convinced that this is actually safe even if oplogConnection\r\n  // is some kind of pool\r\n  waitUntilCaughtUp: function () {\r\n    var self = this;\r\n    if (self._stopped)\r\n      throw new Error(\"Called waitUntilCaughtUp on stopped handle!\");\r\n\r\n    // Calling waitUntilCaughtUp requries us to wait for the oplog connection to\r\n    // be ready.\r\n    self._readyFuture.wait();\r\n\r\n    while (!self._stopped) {\r\n      // We need to make the selector at least as restrictive as the actual\r\n      // tailing selector (ie, we need to specify the DB name) or else we might\r\n      // find a TS that won't show up in the actual tail stream.\r\n      try {\r\n        var lastEntry = self._oplogLastEntryConnection.findOne(\r\n          OPLOG_COLLECTION, self._baseOplogSelector,\r\n          {fields: {ts: 1}, sort: {$natural: -1}});\r\n        break;\r\n      } catch (e) {\r\n        // During failover (eg) if we get an exception we should log and retry\r\n        // instead of crashing.\r\n        Meteor._debug(\"Got exception while reading last entry: \" + e);\r\n        Meteor._sleepForMs(100);\r\n      }\r\n    }\r\n\r\n    if (self._stopped)\r\n      return;\r\n\r\n    if (!lastEntry) {\r\n      // Really, nothing in the oplog? Well, we've processed everything.\r\n      return;\r\n    }\r\n\r\n    var ts = lastEntry.ts;\r\n    if (!ts)\r\n      throw Error(\"oplog entry without ts: \" + EJSON.stringify(lastEntry));\r\n\r\n    if (self._lastProcessedTS && ts.lessThanOrEqual(self._lastProcessedTS)) {\r\n      // We've already caught up to here.\r\n      return;\r\n    }\r\n\r\n\r\n    // Insert the future into our list. Almost always, this will be at the end,\r\n    // but it's conceivable that if we fail over from one primary to another,\r\n    // the oplog entries we see will go backwards.\r\n    var insertAfter = self._catchingUpFutures.length;\r\n    while (insertAfter - 1 > 0\r\n           && self._catchingUpFutures[insertAfter - 1].ts.greaterThan(ts)) {\r\n      insertAfter--;\r\n    }\r\n    var f = new Future;\r\n    self._catchingUpFutures.splice(insertAfter, 0, {ts: ts, future: f});\r\n    f.wait();\r\n  },\r\n  _startTailing: function () {\r\n    var self = this;\r\n    // We make two separate connections to Mongo. The Node Mongo driver\r\n    // implements a naive round-robin connection pool: each \"connection\" is a\r\n    // pool of several (5 by default) TCP connections, and each request is\r\n    // rotated through the pools. Tailable cursor queries block on the server\r\n    // until there is some data to return (or until a few seconds have\r\n    // passed). So if the connection pool used for tailing cursors is the same\r\n    // pool used for other queries, the other queries will be delayed by seconds\r\n    // 1/5 of the time.\r\n    //\r\n    // The tail connection will only ever be running a single tail command, so\r\n    // it only needs to make one underlying TCP connection.\r\n    self._oplogTailConnection = new MongoConnection(\r\n      self._oplogUrl, {poolSize: 1});\r\n    // XXX better docs, but: it's to get monotonic results\r\n    // XXX is it safe to say \"if there's an in flight query, just use its\r\n    //     results\"? I don't think so but should consider that\r\n    self._oplogLastEntryConnection = new MongoConnection(\r\n      self._oplogUrl, {poolSize: 1});\r\n\r\n    // First, make sure that there actually is a repl set here. If not, oplog\r\n    // tailing won't ever find anything! (Blocks until the connection is ready.)\r\n    var replSetInfo = self._oplogLastEntryConnection.findOne(\r\n      REPLSET_COLLECTION, {});\r\n    if (!replSetInfo)\r\n      throw Error(\"$MONGO_OPLOG_URL must be set to the 'local' database of \" +\r\n                  \"a Mongo replica set\");\r\n\r\n    // Find the last oplog entry.\r\n    var lastOplogEntry = self._oplogLastEntryConnection.findOne(\r\n      OPLOG_COLLECTION, {}, {sort: {$natural: -1}, fields: {ts: 1}});\r\n\r\n    var oplogSelector = _.clone(self._baseOplogSelector);\r\n    if (lastOplogEntry) {\r\n      // Start after the last entry that currently exists.\r\n      oplogSelector.ts = {$gt: lastOplogEntry.ts};\r\n      // If there are any calls to callWhenProcessedLatest before any other\r\n      // oplog entries show up, allow callWhenProcessedLatest to call its\r\n      // callback immediately.\r\n      self._lastProcessedTS = lastOplogEntry.ts;\r\n    }\r\n\r\n    var cursorDescription = new CursorDescription(\r\n      OPLOG_COLLECTION, oplogSelector, {tailable: true});\r\n\r\n    self._tailHandle = self._oplogTailConnection.tail(\r\n      cursorDescription, function (doc) {\r\n        if (!(doc.ns && doc.ns.length > self._dbName.length + 1 &&\r\n              doc.ns.substr(0, self._dbName.length + 1) ===\r\n              (self._dbName + '.'))) {\r\n          throw new Error(\"Unexpected ns\");\r\n        }\r\n\r\n        var trigger = {collection: doc.ns.substr(self._dbName.length + 1),\r\n                       dropCollection: false,\r\n                       op: doc};\r\n\r\n        // Is it a special command and the collection name is hidden somewhere\r\n        // in operator?\r\n        if (trigger.collection === \"$cmd\") {\r\n          trigger.collection = doc.o.drop;\r\n          trigger.dropCollection = true;\r\n          trigger.id = null;\r\n        } else {\r\n          // All other ops have an id.\r\n          trigger.id = idForOp(doc);\r\n        }\r\n\r\n        self._crossbar.fire(trigger);\r\n\r\n        // Now that we've processed this operation, process pending sequencers.\r\n        if (!doc.ts)\r\n          throw Error(\"oplog entry without ts: \" + EJSON.stringify(doc));\r\n        self._lastProcessedTS = doc.ts;\r\n        while (!_.isEmpty(self._catchingUpFutures)\r\n               && self._catchingUpFutures[0].ts.lessThanOrEqual(\r\n                 self._lastProcessedTS)) {\r\n          var sequencer = self._catchingUpFutures.shift();\r\n          sequencer.future.return();\r\n        }\r\n      });\r\n    self._readyFuture.return();\r\n  }\r\n});\r\n","var Future = Npm.require('fibers/future');\r\n\r\nObserveMultiplexer = function (options) {\r\n  var self = this;\r\n\r\n  if (!options || !_.has(options, 'ordered'))\r\n    throw Error(\"must specified ordered\");\r\n\r\n  Package.facts && Package.facts.Facts.incrementServerFact(\r\n    \"mongo-livedata\", \"observe-multiplexers\", 1);\r\n\r\n  self._ordered = options.ordered;\r\n  self._onStop = options.onStop || function () {};\r\n  self._queue = new Meteor._SynchronousQueue();\r\n  self._handles = {};\r\n  self._readyFuture = new Future;\r\n  self._cache = new LocalCollection._CachingChangeObserver({\r\n    ordered: options.ordered});\r\n  // Number of addHandleAndSendInitialAdds tasks scheduled but not yet\r\n  // running. removeHandle uses this to know if it's time to call the onStop\r\n  // callback.\r\n  self._addHandleTasksScheduledButNotPerformed = 0;\r\n\r\n  _.each(self.callbackNames(), function (callbackName) {\r\n    self[callbackName] = function (/* ... */) {\r\n      self._applyCallback(callbackName, _.toArray(arguments));\r\n    };\r\n  });\r\n};\r\n\r\n_.extend(ObserveMultiplexer.prototype, {\r\n  addHandleAndSendInitialAdds: function (handle) {\r\n    var self = this;\r\n\r\n    // Check this before calling runTask (even though runTask does the same\r\n    // check) so that we don't leak an ObserveMultiplexer on error by\r\n    // incrementing _addHandleTasksScheduledButNotPerformed and never\r\n    // decrementing it.\r\n    if (!self._queue.safeToRunTask())\r\n      throw new Error(\r\n        \"Can't call observeChanges from an observe callback on the same query\");\r\n    ++self._addHandleTasksScheduledButNotPerformed;\r\n\r\n    Package.facts && Package.facts.Facts.incrementServerFact(\r\n      \"mongo-livedata\", \"observe-handles\", 1);\r\n\r\n    self._queue.runTask(function () {\r\n      self._handles[handle._id] = handle;\r\n      // Send out whatever adds we have so far (whether or not we the\r\n      // multiplexer is ready).\r\n      self._sendAdds(handle);\r\n      --self._addHandleTasksScheduledButNotPerformed;\r\n    });\r\n    // *outside* the task, since otherwise we'd deadlock\r\n    self._readyFuture.wait();\r\n  },\r\n\r\n  // Remove an observe handle. If it was the last observe handle, call the\r\n  // onStop callback; you cannot add any more observe handles after this.\r\n  //\r\n  // This is not synchronized with polls and handle additions: this means that\r\n  // you can safely call it from within an observe callback, but it also means\r\n  // that we have to be careful when we iterate over _handles.\r\n  removeHandle: function (id) {\r\n    var self = this;\r\n\r\n    // This should not be possible: you can only call removeHandle by having\r\n    // access to the ObserveHandle, which isn't returned to user code until the\r\n    // multiplex is ready.\r\n    if (!self._ready())\r\n      throw new Error(\"Can't remove handles until the multiplex is ready\");\r\n\r\n    delete self._handles[id];\r\n\r\n    Package.facts && Package.facts.Facts.incrementServerFact(\r\n      \"mongo-livedata\", \"observe-handles\", -1);\r\n\r\n    if (_.isEmpty(self._handles) &&\r\n        self._addHandleTasksScheduledButNotPerformed === 0) {\r\n      self._stop();\r\n    }\r\n  },\r\n  _stop: function () {\r\n    var self = this;\r\n    // It shouldn't be possible for us to stop when all our handles still\r\n    // haven't been returned from observeChanges!\r\n    if (!self._ready())\r\n      throw Error(\"surprising _stop: not ready\");\r\n\r\n    // Call stop callback (which kills the underlying process which sends us\r\n    // callbacks and removes us from the connection's dictionary).\r\n    self._onStop();\r\n    Package.facts && Package.facts.Facts.incrementServerFact(\r\n      \"mongo-livedata\", \"observe-multiplexers\", -1);\r\n\r\n    // Cause future addHandleAndSendInitialAdds calls to throw (but the onStop\r\n    // callback should make our connection forget about us).\r\n    self._handles = null;\r\n  },\r\n  // Allows all addHandleAndSendInitialAdds calls to return, once all preceding\r\n  // adds have been processed. Does not block.\r\n  ready: function () {\r\n    var self = this;\r\n    self._queue.queueTask(function () {\r\n      if (self._ready())\r\n        throw Error(\"can't make ObserveMultiplex ready twice!\");\r\n      self._readyFuture.return();\r\n    });\r\n  },\r\n  // Calls \"cb\" once the effects of all \"ready\", \"addHandleAndSendInitialAdds\"\r\n  // and observe callbacks which came before this call have been propagated to\r\n  // all handles. \"ready\" must have already been called on this multiplexer.\r\n  onFlush: function (cb) {\r\n    var self = this;\r\n    self._queue.queueTask(function () {\r\n      if (!self._ready())\r\n        throw Error(\"only call onFlush on a multiplexer that will be ready\");\r\n      cb();\r\n    });\r\n  },\r\n  callbackNames: function () {\r\n    var self = this;\r\n    if (self._ordered)\r\n      return [\"addedBefore\", \"changed\", \"movedBefore\", \"removed\"];\r\n    else\r\n      return [\"added\", \"changed\", \"removed\"];\r\n  },\r\n  _ready: function () {\r\n    return this._readyFuture.isResolved();\r\n  },\r\n  _applyCallback: function (callbackName, args) {\r\n    var self = this;\r\n    self._queue.queueTask(function () {\r\n      // If we stopped in the meantime, do nothing.\r\n      if (!self._handles)\r\n        return;\r\n\r\n      // First, apply the change to the cache.\r\n      // XXX We could make applyChange callbacks promise not to hang on to any\r\n      // state from their arguments (assuming that their supplied callbacks\r\n      // don't) and skip this clone. Currently 'changed' hangs on to state\r\n      // though.\r\n      self._cache.applyChange[callbackName].apply(null, EJSON.clone(args));\r\n\r\n      // If we haven't finished the initial adds, then we should only be getting\r\n      // adds.\r\n      if (!self._ready() &&\r\n          (callbackName !== 'added' && callbackName !== 'addedBefore')) {\r\n        throw new Error(\"Got \" + callbackName + \" during initial adds\");\r\n      }\r\n\r\n      // Now multiplex the callbacks out to all observe handles. It's OK if\r\n      // these calls yield; since we're inside a task, no other use of our queue\r\n      // can continue until these are done. (But we do have to be careful to not\r\n      // use a handle that got removed, because removeHandle does not use the\r\n      // queue; thus, we iterate over an array of keys that we control.)\r\n      _.each(_.keys(self._handles), function (handleId) {\r\n        var handle = self._handles && self._handles[handleId];\r\n        if (!handle)\r\n          return;\r\n        var callback = handle['_' + callbackName];\r\n        // clone arguments so that callbacks can mutate their arguments\r\n        callback && callback.apply(null, EJSON.clone(args));\r\n      });\r\n    });\r\n  },\r\n\r\n  // Sends initial adds to a handle. It should only be called from within a task\r\n  // (the task that is processing the addHandleAndSendInitialAdds call). It\r\n  // synchronously invokes the handle's added or addedBefore; there's no need to\r\n  // flush the queue afterwards to ensure that the callbacks get out.\r\n  _sendAdds: function (handle) {\r\n    var self = this;\r\n    if (self._queue.safeToRunTask())\r\n      throw Error(\"_sendAdds may only be called from within a task!\");\r\n    var add = self._ordered ? handle._addedBefore : handle._added;\r\n    if (!add)\r\n      return;\r\n    // note: docs may be an _IdMap or an OrderedDict\r\n    self._cache.docs.forEach(function (doc, id) {\r\n      if (!_.has(self._handles, handle._id))\r\n        throw Error(\"handle got removed before sending initial adds!\");\r\n      var fields = EJSON.clone(doc);\r\n      delete fields._id;\r\n      if (self._ordered)\r\n        add(id, fields, null); // we're going in order, so add at end\r\n      else\r\n        add(id, fields);\r\n    });\r\n  }\r\n});\r\n\r\n\r\nvar nextObserveHandleId = 1;\r\nObserveHandle = function (multiplexer, callbacks) {\r\n  var self = this;\r\n  // The end user is only supposed to call stop().  The other fields are\r\n  // accessible to the multiplexer, though.\r\n  self._multiplexer = multiplexer;\r\n  _.each(multiplexer.callbackNames(), function (name) {\r\n    if (callbacks[name]) {\r\n      self['_' + name] = callbacks[name];\r\n    } else if (name === \"addedBefore\" && callbacks.added) {\r\n      // Special case: if you specify \"added\" and \"movedBefore\", you get an\r\n      // ordered observe where for some reason you don't get ordering data on\r\n      // the adds.  I dunno, we wrote tests for it, there must have been a\r\n      // reason.\r\n      self._addedBefore = function (id, fields, before) {\r\n        callbacks.added(id, fields);\r\n      };\r\n    }\r\n  });\r\n  self._stopped = false;\r\n  self._id = nextObserveHandleId++;\r\n};\r\nObserveHandle.prototype.stop = function () {\r\n  var self = this;\r\n  if (self._stopped)\r\n    return;\r\n  self._stopped = true;\r\n  self._multiplexer.removeHandle(self._id);\r\n};\r\n","var Fiber = Npm.require('fibers');\r\nvar Future = Npm.require('fibers/future');\r\n\r\nDocFetcher = function (mongoConnection) {\r\n  var self = this;\r\n  self._mongoConnection = mongoConnection;\r\n  // Map from cache key -> [callback]\r\n  self._callbacksForCacheKey = {};\r\n};\r\n\r\n_.extend(DocFetcher.prototype, {\r\n  // Fetches document \"id\" from collectionName, returning it or null if not\r\n  // found.\r\n  //\r\n  // If you make multiple calls to fetch() with the same cacheKey (a string),\r\n  // DocFetcher may assume that they all return the same document. (It does\r\n  // not check to see if collectionName/id match.)\r\n  //\r\n  // You may assume that callback is never called synchronously (and in fact\r\n  // OplogObserveDriver does so).\r\n  fetch: function (collectionName, id, cacheKey, callback) {\r\n    var self = this;\r\n\r\n    check(collectionName, String);\r\n    // id is some sort of scalar\r\n    check(cacheKey, String);\r\n\r\n    // If there's already an in-progress fetch for this cache key, yield until\r\n    // it's done and return whatever it returns.\r\n    if (_.has(self._callbacksForCacheKey, cacheKey)) {\r\n      self._callbacksForCacheKey[cacheKey].push(callback);\r\n      return;\r\n    }\r\n\r\n    var callbacks = self._callbacksForCacheKey[cacheKey] = [callback];\r\n\r\n    Fiber(function () {\r\n      try {\r\n        var doc = self._mongoConnection.findOne(\r\n          collectionName, {_id: id}) || null;\r\n        // Return doc to all relevant callbacks. Note that this array can\r\n        // continue to grow during callback excecution.\r\n        while (!_.isEmpty(callbacks)) {\r\n          // Clone the document so that the various calls to fetch don't return\r\n          // objects that are intertwingled with each other. Clone before\r\n          // popping the future, so that if clone throws, the error gets passed\r\n          // to the next callback.\r\n          var clonedDoc = EJSON.clone(doc);\r\n          callbacks.pop()(null, clonedDoc);\r\n        }\r\n      } catch (e) {\r\n        while (!_.isEmpty(callbacks)) {\r\n          callbacks.pop()(e);\r\n        }\r\n      } finally {\r\n        // XXX consider keeping the doc around for a period of time before\r\n        // removing from the cache\r\n        delete self._callbacksForCacheKey[cacheKey];\r\n      }\r\n    }).run();\r\n  }\r\n});\r\n\r\nMongoTest.DocFetcher = DocFetcher;\r\n","PollingObserveDriver = function (options) {\r\n  var self = this;\r\n\r\n  self._cursorDescription = options.cursorDescription;\r\n  self._mongoHandle = options.mongoHandle;\r\n  self._ordered = options.ordered;\r\n  self._multiplexer = options.multiplexer;\r\n  self._stopCallbacks = [];\r\n  self._stopped = false;\r\n\r\n  self._synchronousCursor = self._mongoHandle._createSynchronousCursor(\r\n    self._cursorDescription);\r\n\r\n  // previous results snapshot.  on each poll cycle, diffs against\r\n  // results drives the callbacks.\r\n  self._results = null;\r\n\r\n  // The number of _pollMongo calls that have been added to self._taskQueue but\r\n  // have not started running. Used to make sure we never schedule more than one\r\n  // _pollMongo (other than possibly the one that is currently running). It's\r\n  // also used by _suspendPolling to pretend there's a poll scheduled. Usually,\r\n  // it's either 0 (for \"no polls scheduled other than maybe one currently\r\n  // running\") or 1 (for \"a poll scheduled that isn't running yet\"), but it can\r\n  // also be 2 if incremented by _suspendPolling.\r\n  self._pollsScheduledButNotStarted = 0;\r\n  self._pendingWrites = []; // people to notify when polling completes\r\n\r\n  // Make sure to create a separately throttled function for each\r\n  // PollingObserveDriver object.\r\n  self._ensurePollIsScheduled = _.throttle(\r\n    self._unthrottledEnsurePollIsScheduled, 50 /* ms */);\r\n\r\n  // XXX figure out if we still need a queue\r\n  self._taskQueue = new Meteor._SynchronousQueue();\r\n\r\n  var listenersHandle = listenAll(\r\n    self._cursorDescription, function (notification) {\r\n      // When someone does a transaction that might affect us, schedule a poll\r\n      // of the database. If that transaction happens inside of a write fence,\r\n      // block the fence until we've polled and notified observers.\r\n      var fence = DDPServer._CurrentWriteFence.get();\r\n      if (fence)\r\n        self._pendingWrites.push(fence.beginWrite());\r\n      // Ensure a poll is scheduled... but if we already know that one is,\r\n      // don't hit the throttled _ensurePollIsScheduled function (which might\r\n      // lead to us calling it unnecessarily in 50ms).\r\n      if (self._pollsScheduledButNotStarted === 0)\r\n        self._ensurePollIsScheduled();\r\n    }\r\n  );\r\n  self._stopCallbacks.push(function () { listenersHandle.stop(); });\r\n\r\n  // every once and a while, poll even if we don't think we're dirty, for\r\n  // eventual consistency with database writes from outside the Meteor\r\n  // universe.\r\n  //\r\n  // For testing, there's an undocumented callback argument to observeChanges\r\n  // which disables time-based polling and gets called at the beginning of each\r\n  // poll.\r\n  if (options._testOnlyPollCallback) {\r\n    self._testOnlyPollCallback = options._testOnlyPollCallback;\r\n  } else {\r\n    var intervalHandle = Meteor.setInterval(\r\n      _.bind(self._ensurePollIsScheduled, self), 10 * 1000);\r\n    self._stopCallbacks.push(function () {\r\n      Meteor.clearInterval(intervalHandle);\r\n    });\r\n  }\r\n\r\n  // Make sure we actually poll soon!\r\n  self._unthrottledEnsurePollIsScheduled();\r\n\r\n  Package.facts && Package.facts.Facts.incrementServerFact(\r\n    \"mongo-livedata\", \"observe-drivers-polling\", 1);\r\n};\r\n\r\n_.extend(PollingObserveDriver.prototype, {\r\n  // This is always called through _.throttle (except once at startup).\r\n  _unthrottledEnsurePollIsScheduled: function () {\r\n    var self = this;\r\n    if (self._pollsScheduledButNotStarted > 0)\r\n      return;\r\n    ++self._pollsScheduledButNotStarted;\r\n    self._taskQueue.queueTask(function () {\r\n      self._pollMongo();\r\n    });\r\n  },\r\n\r\n  // test-only interface for controlling polling.\r\n  //\r\n  // _suspendPolling blocks until any currently running and scheduled polls are\r\n  // done, and prevents any further polls from being scheduled. (new\r\n  // ObserveHandles can be added and receive their initial added callbacks,\r\n  // though.)\r\n  //\r\n  // _resumePolling immediately polls, and allows further polls to occur.\r\n  _suspendPolling: function() {\r\n    var self = this;\r\n    // Pretend that there's another poll scheduled (which will prevent\r\n    // _ensurePollIsScheduled from queueing any more polls).\r\n    ++self._pollsScheduledButNotStarted;\r\n    // Now block until all currently running or scheduled polls are done.\r\n    self._taskQueue.runTask(function() {});\r\n\r\n    // Confirm that there is only one \"poll\" (the fake one we're pretending to\r\n    // have) scheduled.\r\n    if (self._pollsScheduledButNotStarted !== 1)\r\n      throw new Error(\"_pollsScheduledButNotStarted is \" +\r\n                      self._pollsScheduledButNotStarted);\r\n  },\r\n  _resumePolling: function() {\r\n    var self = this;\r\n    // We should be in the same state as in the end of _suspendPolling.\r\n    if (self._pollsScheduledButNotStarted !== 1)\r\n      throw new Error(\"_pollsScheduledButNotStarted is \" +\r\n                      self._pollsScheduledButNotStarted);\r\n    // Run a poll synchronously (which will counteract the\r\n    // ++_pollsScheduledButNotStarted from _suspendPolling).\r\n    self._taskQueue.runTask(function () {\r\n      self._pollMongo();\r\n    });\r\n  },\r\n\r\n  _pollMongo: function () {\r\n    var self = this;\r\n    --self._pollsScheduledButNotStarted;\r\n\r\n    var first = false;\r\n    var oldResults = self._results;\r\n    if (!oldResults) {\r\n      first = true;\r\n      // XXX maybe use OrderedDict instead?\r\n      oldResults = self._ordered ? [] : new LocalCollection._IdMap;\r\n    }\r\n\r\n    self._testOnlyPollCallback && self._testOnlyPollCallback();\r\n\r\n    // Save the list of pending writes which this round will commit.\r\n    var writesForCycle = self._pendingWrites;\r\n    self._pendingWrites = [];\r\n\r\n    // Get the new query results. (This yields.)\r\n    try {\r\n      var newResults = self._synchronousCursor.getRawObjects(self._ordered);\r\n    } catch (e) {\r\n      // getRawObjects can throw if we're having trouble talking to the\r\n      // database.  That's fine --- we will repoll later anyway. But we should\r\n      // make sure not to lose track of this cycle's writes.\r\n      Array.prototype.push.apply(self._pendingWrites, writesForCycle);\r\n      throw e;\r\n    }\r\n\r\n    // Run diffs.\r\n    if (!self._stopped) {\r\n      LocalCollection._diffQueryChanges(\r\n        self._ordered, oldResults, newResults, self._multiplexer);\r\n    }\r\n\r\n    // Signals the multiplexer to allow all observeChanges calls that share this\r\n    // multiplexer to return. (This happens asynchronously, via the\r\n    // multiplexer's queue.)\r\n    if (first)\r\n      self._multiplexer.ready();\r\n\r\n    // Replace self._results atomically.  (This assignment is what makes `first`\r\n    // stay through on the next cycle, so we've waited until after we've\r\n    // committed to ready-ing the multiplexer.)\r\n    self._results = newResults;\r\n\r\n    // Once the ObserveMultiplexer has processed everything we've done in this\r\n    // round, mark all the writes which existed before this call as\r\n    // commmitted. (If new writes have shown up in the meantime, there'll\r\n    // already be another _pollMongo task scheduled.)\r\n    self._multiplexer.onFlush(function () {\r\n      _.each(writesForCycle, function (w) {\r\n        w.committed();\r\n      });\r\n    });\r\n  },\r\n\r\n  stop: function () {\r\n    var self = this;\r\n    self._stopped = true;\r\n    _.each(self._stopCallbacks, function (c) { c(); });\r\n    Package.facts && Package.facts.Facts.incrementServerFact(\r\n      \"mongo-livedata\", \"observe-drivers-polling\", -1);\r\n  }\r\n});\r\n","var Fiber = Npm.require('fibers');\r\nvar Future = Npm.require('fibers/future');\r\n\r\nvar PHASE = {\r\n  QUERYING: \"QUERYING\",\r\n  FETCHING: \"FETCHING\",\r\n  STEADY: \"STEADY\"\r\n};\r\n\r\n// Exception thrown by _needToPollQuery which unrolls the stack up to the\r\n// enclosing call to finishIfNeedToPollQuery.\r\nvar SwitchedToQuery = function () {};\r\nvar finishIfNeedToPollQuery = function (f) {\r\n  return function () {\r\n    try {\r\n      f.apply(this, arguments);\r\n    } catch (e) {\r\n      if (!(e instanceof SwitchedToQuery))\r\n        throw e;\r\n    }\r\n  };\r\n};\r\n\r\n// OplogObserveDriver is an alternative to PollingObserveDriver which follows\r\n// the Mongo operation log instead of just re-polling the query. It obeys the\r\n// same simple interface: constructing it starts sending observeChanges\r\n// callbacks (and a ready() invocation) to the ObserveMultiplexer, and you stop\r\n// it by calling the stop() method.\r\nOplogObserveDriver = function (options) {\r\n  var self = this;\r\n  self._usesOplog = true;  // tests look at this\r\n\r\n  self._cursorDescription = options.cursorDescription;\r\n  self._mongoHandle = options.mongoHandle;\r\n  self._multiplexer = options.multiplexer;\r\n\r\n  if (options.ordered) {\r\n    throw Error(\"OplogObserveDriver only supports unordered observeChanges\");\r\n  }\r\n\r\n  var sorter = options.sorter;\r\n  // We don't support $near and other geo-queries so it's OK to initialize the\r\n  // comparator only once in the constructor.\r\n  var comparator = sorter && sorter.getComparator();\r\n\r\n  if (options.cursorDescription.options.limit) {\r\n    // There are several properties ordered driver implements:\r\n    // - _limit is a positive number\r\n    // - _comparator is a function-comparator by which the query is ordered\r\n    // - _unpublishedBuffer is non-null Min/Max Heap,\r\n    //                      the empty buffer in STEADY phase implies that the\r\n    //                      everything that matches the queries selector fits\r\n    //                      into published set.\r\n    // - _published - Min Heap (also implements IdMap methods)\r\n\r\n    var heapOptions = { IdMap: LocalCollection._IdMap };\r\n    self._limit = self._cursorDescription.options.limit;\r\n    self._comparator = comparator;\r\n    self._sorter = sorter;\r\n    self._unpublishedBuffer = new MinMaxHeap(comparator, heapOptions);\r\n    // We need something that can find Max value in addition to IdMap interface\r\n    self._published = new MaxHeap(comparator, heapOptions);\r\n  } else {\r\n    self._limit = 0;\r\n    self._comparator = null;\r\n    self._sorter = null;\r\n    self._unpublishedBuffer = null;\r\n    self._published = new LocalCollection._IdMap;\r\n  }\r\n\r\n  // Indicates if it is safe to insert a new document at the end of the buffer\r\n  // for this query. i.e. it is known that there are no documents matching the\r\n  // selector those are not in published or buffer.\r\n  self._safeAppendToBuffer = false;\r\n\r\n  self._stopped = false;\r\n  self._stopHandles = [];\r\n\r\n  Package.facts && Package.facts.Facts.incrementServerFact(\r\n    \"mongo-livedata\", \"observe-drivers-oplog\", 1);\r\n\r\n  self._registerPhaseChange(PHASE.QUERYING);\r\n\r\n  var selector = self._cursorDescription.selector;\r\n  self._matcher = options.matcher;\r\n  var projection = self._cursorDescription.options.fields || {};\r\n  self._projectionFn = LocalCollection._compileProjection(projection);\r\n  // Projection function, result of combining important fields for selector and\r\n  // existing fields projection\r\n  self._sharedProjection = self._matcher.combineIntoProjection(projection);\r\n  if (sorter)\r\n    self._sharedProjection = sorter.combineIntoProjection(self._sharedProjection);\r\n  self._sharedProjectionFn = LocalCollection._compileProjection(\r\n    self._sharedProjection);\r\n\r\n  self._needToFetch = new LocalCollection._IdMap;\r\n  self._currentlyFetching = null;\r\n  self._fetchGeneration = 0;\r\n\r\n  self._requeryWhenDoneThisQuery = false;\r\n  self._writesToCommitWhenWeReachSteady = [];\r\n\r\n  forEachTrigger(self._cursorDescription, function (trigger) {\r\n    self._stopHandles.push(self._mongoHandle._oplogHandle.onOplogEntry(\r\n      trigger, function (notification) {\r\n        Meteor._noYieldsAllowed(finishIfNeedToPollQuery(function () {\r\n          var op = notification.op;\r\n          if (notification.dropCollection) {\r\n            // Note: this call is not allowed to block on anything (especially\r\n            // on waiting for oplog entries to catch up) because that will block\r\n            // onOplogEntry!\r\n            self._needToPollQuery();\r\n          } else {\r\n            // All other operators should be handled depending on phase\r\n            if (self._phase === PHASE.QUERYING)\r\n              self._handleOplogEntryQuerying(op);\r\n            else\r\n              self._handleOplogEntrySteadyOrFetching(op);\r\n          }\r\n        }));\r\n      }\r\n    ));\r\n  });\r\n\r\n  // XXX ordering w.r.t. everything else?\r\n  self._stopHandles.push(listenAll(\r\n    self._cursorDescription, function (notification) {\r\n      // If we're not in a write fence, we don't have to do anything.\r\n      var fence = DDPServer._CurrentWriteFence.get();\r\n      if (!fence)\r\n        return;\r\n      var write = fence.beginWrite();\r\n      // This write cannot complete until we've caught up to \"this point\" in the\r\n      // oplog, and then made it back to the steady state.\r\n      Meteor.defer(function () {\r\n        self._mongoHandle._oplogHandle.waitUntilCaughtUp();\r\n        if (self._stopped) {\r\n          // We're stopped, so just immediately commit.\r\n          write.committed();\r\n        } else if (self._phase === PHASE.STEADY) {\r\n          // Make sure that all of the callbacks have made it through the\r\n          // multiplexer and been delivered to ObserveHandles before committing\r\n          // writes.\r\n          self._multiplexer.onFlush(function () {\r\n            write.committed();\r\n          });\r\n        } else {\r\n          self._writesToCommitWhenWeReachSteady.push(write);\r\n        }\r\n      });\r\n    }\r\n  ));\r\n\r\n  // When Mongo fails over, we need to repoll the query, in case we processed an\r\n  // oplog entry that got rolled back.\r\n  self._stopHandles.push(self._mongoHandle._onFailover(finishIfNeedToPollQuery(\r\n    function () {\r\n      self._needToPollQuery();\r\n    })));\r\n\r\n  // Give _observeChanges a chance to add the new ObserveHandle to our\r\n  // multiplexer, so that the added calls get streamed.\r\n  Meteor.defer(finishIfNeedToPollQuery(function () {\r\n    self._runInitialQuery();\r\n  }));\r\n};\r\n\r\n_.extend(OplogObserveDriver.prototype, {\r\n  _addPublished: function (id, doc) {\r\n    var self = this;\r\n    var fields = _.clone(doc);\r\n    delete fields._id;\r\n    self._published.set(id, self._sharedProjectionFn(doc));\r\n    self._multiplexer.added(id, self._projectionFn(fields));\r\n\r\n    // After adding this document, the published set might be overflowed\r\n    // (exceeding capacity specified by limit). If so, push the maximum element\r\n    // to the buffer, we might want to save it in memory to reduce the amount of\r\n    // Mongo lookups in the future.\r\n    if (self._limit && self._published.size() > self._limit) {\r\n      // XXX in theory the size of published is no more than limit+1\r\n      if (self._published.size() !== self._limit + 1) {\r\n        throw new Error(\"After adding to published, \" +\r\n                        (self._published.size() - self._limit) +\r\n                        \" documents are overflowing the set\");\r\n      }\r\n\r\n      var overflowingDocId = self._published.maxElementId();\r\n      var overflowingDoc = self._published.get(overflowingDocId);\r\n\r\n      if (EJSON.equals(overflowingDocId, id)) {\r\n        throw new Error(\"The document just added is overflowing the published set\");\r\n      }\r\n\r\n      self._published.remove(overflowingDocId);\r\n      self._multiplexer.removed(overflowingDocId);\r\n      self._addBuffered(overflowingDocId, overflowingDoc);\r\n    }\r\n  },\r\n  _removePublished: function (id) {\r\n    var self = this;\r\n    self._published.remove(id);\r\n    self._multiplexer.removed(id);\r\n    if (! self._limit || self._published.size() === self._limit)\r\n      return;\r\n\r\n    if (self._published.size() > self._limit)\r\n      throw Error(\"self._published got too big\");\r\n\r\n    // OK, we are publishing less than the limit. Maybe we should look in the\r\n    // buffer to find the next element past what we were publishing before.\r\n\r\n    if (!self._unpublishedBuffer.empty()) {\r\n      // There's something in the buffer; move the first thing in it to\r\n      // _published.\r\n      var newDocId = self._unpublishedBuffer.minElementId();\r\n      var newDoc = self._unpublishedBuffer.get(newDocId);\r\n      self._removeBuffered(newDocId);\r\n      self._addPublished(newDocId, newDoc);\r\n      return;\r\n    }\r\n\r\n    // There's nothing in the buffer.  This could mean one of a few things.\r\n\r\n    // (a) We could be in the middle of re-running the query (specifically, we\r\n    // could be in _publishNewResults). In that case, _unpublishedBuffer is\r\n    // empty because we clear it at the beginning of _publishNewResults. In this\r\n    // case, our caller already knows the entire answer to the query and we\r\n    // don't need to do anything fancy here.  Just return.\r\n    if (self._phase === PHASE.QUERYING)\r\n      return;\r\n\r\n    // (b) We're pretty confident that the union of _published and\r\n    // _unpublishedBuffer contain all documents that match selector. Because\r\n    // _unpublishedBuffer is empty, that means we're confident that _published\r\n    // contains all documents that match selector. So we have nothing to do.\r\n    if (self._safeAppendToBuffer)\r\n      return;\r\n\r\n    // (c) Maybe there are other documents out there that should be in our\r\n    // buffer. But in that case, when we emptied _unpublishedBuffer in\r\n    // _removeBuffered, we should have called _needToPollQuery, which will\r\n    // either put something in _unpublishedBuffer or set _safeAppendToBuffer (or\r\n    // both), and it will put us in QUERYING for that whole time. So in fact, we\r\n    // shouldn't be able to get here.\r\n\r\n    throw new Error(\"Buffer inexplicably empty\");\r\n  },\r\n  _changePublished: function (id, oldDoc, newDoc) {\r\n    var self = this;\r\n    self._published.set(id, self._sharedProjectionFn(newDoc));\r\n    var changed = LocalCollection._makeChangedFields(_.clone(newDoc), oldDoc);\r\n    changed = self._projectionFn(changed);\r\n    if (!_.isEmpty(changed))\r\n      self._multiplexer.changed(id, changed);\r\n  },\r\n  _addBuffered: function (id, doc) {\r\n    var self = this;\r\n    self._unpublishedBuffer.set(id, self._sharedProjectionFn(doc));\r\n\r\n    // If something is overflowing the buffer, we just remove it from cache\r\n    if (self._unpublishedBuffer.size() > self._limit) {\r\n      var maxBufferedId = self._unpublishedBuffer.maxElementId();\r\n\r\n      self._unpublishedBuffer.remove(maxBufferedId);\r\n\r\n      // Since something matching is removed from cache (both published set and\r\n      // buffer), set flag to false\r\n      self._safeAppendToBuffer = false;\r\n    }\r\n  },\r\n  // Is called either to remove the doc completely from matching set or to move\r\n  // it to the published set later.\r\n  _removeBuffered: function (id) {\r\n    var self = this;\r\n    self._unpublishedBuffer.remove(id);\r\n    // To keep the contract \"buffer is never empty in STEADY phase unless the\r\n    // everything matching fits into published\" true, we poll everything as soon\r\n    // as we see the buffer becoming empty.\r\n    if (! self._unpublishedBuffer.size() && ! self._safeAppendToBuffer)\r\n      self._needToPollQuery();\r\n  },\r\n  // Called when a document has joined the \"Matching\" results set.\r\n  // Takes responsibility of keeping _unpublishedBuffer in sync with _published\r\n  // and the effect of limit enforced.\r\n  _addMatching: function (doc) {\r\n    var self = this;\r\n    var id = doc._id;\r\n    if (self._published.has(id))\r\n      throw Error(\"tried to add something already published \" + id);\r\n    if (self._limit && self._unpublishedBuffer.has(id))\r\n      throw Error(\"tried to add something already existed in buffer \" + id);\r\n\r\n    var limit = self._limit;\r\n    var comparator = self._comparator;\r\n    var maxPublished = (limit && self._published.size() > 0) ?\r\n      self._published.get(self._published.maxElementId()) : null;\r\n    var maxBuffered = (limit && self._unpublishedBuffer.size() > 0) ?\r\n      self._unpublishedBuffer.get(self._unpublishedBuffer.maxElementId()) : null;\r\n    // The query is unlimited or didn't publish enough documents yet or the new\r\n    // document would fit into published set pushing the maximum element out,\r\n    // then we need to publish the doc.\r\n    var toPublish = ! limit || self._published.size() < limit ||\r\n                    comparator(doc, maxPublished) < 0;\r\n\r\n    // Otherwise we might need to buffer it (only in case of limited query).\r\n    // Buffering is allowed if the buffer is not filled up yet and all matching\r\n    // docs are either in the published set or in the buffer.\r\n    var canAppendToBuffer = !toPublish && self._safeAppendToBuffer &&\r\n                            self._unpublishedBuffer.size() < limit;\r\n\r\n    // Or if it is small enough to be safely inserted to the middle or the\r\n    // beginning of the buffer.\r\n    var canInsertIntoBuffer = !toPublish && maxBuffered &&\r\n                              comparator(doc, maxBuffered) <= 0;\r\n\r\n    var toBuffer = canAppendToBuffer || canInsertIntoBuffer;\r\n\r\n    if (toPublish) {\r\n      self._addPublished(id, doc);\r\n    } else if (toBuffer) {\r\n      self._addBuffered(id, doc);\r\n    } else {\r\n      // dropping it and not saving to the cache\r\n      self._safeAppendToBuffer = false;\r\n    }\r\n  },\r\n  // Called when a document leaves the \"Matching\" results set.\r\n  // Takes responsibility of keeping _unpublishedBuffer in sync with _published\r\n  // and the effect of limit enforced.\r\n  _removeMatching: function (id) {\r\n    var self = this;\r\n    if (! self._published.has(id) && ! self._limit)\r\n      throw Error(\"tried to remove something matching but not cached \" + id);\r\n\r\n    if (self._published.has(id)) {\r\n      self._removePublished(id);\r\n    } else if (self._unpublishedBuffer.has(id)) {\r\n      self._removeBuffered(id);\r\n    }\r\n  },\r\n  _handleDoc: function (id, newDoc) {\r\n    var self = this;\r\n    var matchesNow = newDoc && self._matcher.documentMatches(newDoc).result;\r\n\r\n    var publishedBefore = self._published.has(id);\r\n    var bufferedBefore = self._limit && self._unpublishedBuffer.has(id);\r\n    var cachedBefore = publishedBefore || bufferedBefore;\r\n\r\n    if (matchesNow && !cachedBefore) {\r\n      self._addMatching(newDoc);\r\n    } else if (cachedBefore && !matchesNow) {\r\n      self._removeMatching(id);\r\n    } else if (cachedBefore && matchesNow) {\r\n      var oldDoc = self._published.get(id);\r\n      var comparator = self._comparator;\r\n      var minBuffered = self._limit && self._unpublishedBuffer.size() &&\r\n        self._unpublishedBuffer.get(self._unpublishedBuffer.minElementId());\r\n\r\n      if (publishedBefore) {\r\n        // Unlimited case where the document stays in published once it matches\r\n        // or the case when we don't have enough matching docs to publish or the\r\n        // changed but matching doc will stay in published anyways.\r\n        // XXX: We rely on the emptiness of buffer. Be sure to maintain the fact\r\n        // that buffer can't be empty if there are matching documents not\r\n        // published. Notably, we don't want to schedule repoll and continue\r\n        // relying on this property.\r\n        var staysInPublished = ! self._limit ||\r\n                               self._unpublishedBuffer.size() === 0 ||\r\n                               comparator(newDoc, minBuffered) <= 0;\r\n\r\n        if (staysInPublished) {\r\n          self._changePublished(id, oldDoc, newDoc);\r\n        } else {\r\n          // after the change doc doesn't stay in the published, remove it\r\n          self._removePublished(id);\r\n          // but it can move into buffered now, check it\r\n          var maxBuffered = self._unpublishedBuffer.get(self._unpublishedBuffer.maxElementId());\r\n\r\n          var toBuffer = self._safeAppendToBuffer ||\r\n                         (maxBuffered && comparator(newDoc, maxBuffered) <= 0);\r\n\r\n          if (toBuffer) {\r\n            self._addBuffered(id, newDoc);\r\n          } else {\r\n            // Throw away from both published set and buffer\r\n            self._safeAppendToBuffer = false;\r\n          }\r\n        }\r\n      } else if (bufferedBefore) {\r\n        oldDoc = self._unpublishedBuffer.get(id);\r\n        // remove the old version manually instead of using _removeBuffered so\r\n        // we don't trigger the querying immediately.  if we end this block with\r\n        // the buffer empty, we will need to trigger the query poll manually\r\n        // too.\r\n        self._unpublishedBuffer.remove(id);\r\n\r\n        var maxPublished = self._published.get(self._published.maxElementId());\r\n        var maxBuffered = self._unpublishedBuffer.size() && self._unpublishedBuffer.get(self._unpublishedBuffer.maxElementId());\r\n\r\n        // the buffered doc was updated, it could move to published\r\n        var toPublish = comparator(newDoc, maxPublished) < 0;\r\n\r\n        // or stays in buffer even after the change\r\n        var staysInBuffer = (! toPublish && self._safeAppendToBuffer) ||\r\n          (!toPublish && maxBuffered && comparator(newDoc, maxBuffered) <= 0);\r\n\r\n        if (toPublish) {\r\n          self._addPublished(id, newDoc);\r\n        } else if (staysInBuffer) {\r\n          // stays in buffer but changes\r\n          self._unpublishedBuffer.set(id, newDoc);\r\n        } else {\r\n          // Throw away from both published set and buffer\r\n          self._safeAppendToBuffer = false;\r\n          // Normally this check would have been done in _removeBuffered but we\r\n          // didn't use it, so we need to do it ourself now.\r\n          if (! self._unpublishedBuffer.size()) {\r\n            self._needToPollQuery();\r\n          }\r\n        }\r\n      } else {\r\n        throw new Error(\"cachedBefore implies either of publishedBefore or bufferedBefore is true.\");\r\n      }\r\n    }\r\n  },\r\n  _fetchModifiedDocuments: function () {\r\n    var self = this;\r\n    self._registerPhaseChange(PHASE.FETCHING);\r\n    // Defer, because nothing called from the oplog entry handler may yield, but\r\n    // fetch() yields.\r\n    Meteor.defer(finishIfNeedToPollQuery(function () {\r\n      while (!self._stopped && !self._needToFetch.empty()) {\r\n        if (self._phase === PHASE.QUERYING) {\r\n          // While fetching, we decided to go into QUERYING mode, and then we\r\n          // saw another oplog entry, so _needToFetch is not empty. But we\r\n          // shouldn't fetch these documents until AFTER the query is done.\r\n          break;\r\n        }\r\n\r\n        // Being in steady phase here would be surprising.\r\n        if (self._phase !== PHASE.FETCHING)\r\n          throw new Error(\"phase in fetchModifiedDocuments: \" + self._phase);\r\n\r\n        self._currentlyFetching = self._needToFetch;\r\n        var thisGeneration = ++self._fetchGeneration;\r\n        self._needToFetch = new LocalCollection._IdMap;\r\n        var waiting = 0;\r\n        var fut = new Future;\r\n        // This loop is safe, because _currentlyFetching will not be updated\r\n        // during this loop (in fact, it is never mutated).\r\n        self._currentlyFetching.forEach(function (cacheKey, id) {\r\n          waiting++;\r\n          self._mongoHandle._docFetcher.fetch(\r\n            self._cursorDescription.collectionName, id, cacheKey,\r\n            finishIfNeedToPollQuery(function (err, doc) {\r\n              try {\r\n                if (err) {\r\n                  Meteor._debug(\"Got exception while fetching documents: \" +\r\n                                err);\r\n                  // If we get an error from the fetcher (eg, trouble connecting\r\n                  // to Mongo), let's just abandon the fetch phase altogether\r\n                  // and fall back to polling. It's not like we're getting live\r\n                  // updates anyway.\r\n                  if (self._phase !== PHASE.QUERYING) {\r\n                    self._needToPollQuery();\r\n                  }\r\n                } else if (!self._stopped && self._phase === PHASE.FETCHING\r\n                           && self._fetchGeneration === thisGeneration) {\r\n                  // We re-check the generation in case we've had an explicit\r\n                  // _pollQuery call (eg, in another fiber) which should\r\n                  // effectively cancel this round of fetches.  (_pollQuery\r\n                  // increments the generation.)\r\n                  self._handleDoc(id, doc);\r\n                }\r\n              } finally {\r\n                waiting--;\r\n                // Because fetch() never calls its callback synchronously, this\r\n                // is safe (ie, we won't call fut.return() before the forEach is\r\n                // done).\r\n                if (waiting === 0)\r\n                  fut.return();\r\n              }\r\n            }));\r\n        });\r\n        fut.wait();\r\n        // Exit now if we've had a _pollQuery call (here or in another fiber).\r\n        if (self._phase === PHASE.QUERYING)\r\n          return;\r\n        self._currentlyFetching = null;\r\n      }\r\n      // We're done fetching, so we can be steady, unless we've had a _pollQuery\r\n      // call (here or in another fiber).\r\n      if (self._phase !== PHASE.QUERYING)\r\n        self._beSteady();\r\n    }));\r\n  },\r\n  _beSteady: function () {\r\n    var self = this;\r\n    self._registerPhaseChange(PHASE.STEADY);\r\n    var writes = self._writesToCommitWhenWeReachSteady;\r\n    self._writesToCommitWhenWeReachSteady = [];\r\n    self._multiplexer.onFlush(function () {\r\n      _.each(writes, function (w) {\r\n        w.committed();\r\n      });\r\n    });\r\n  },\r\n  _handleOplogEntryQuerying: function (op) {\r\n    var self = this;\r\n    self._needToFetch.set(idForOp(op), op.ts.toString());\r\n  },\r\n  _handleOplogEntrySteadyOrFetching: function (op) {\r\n    var self = this;\r\n    var id = idForOp(op);\r\n    // If we're already fetching this one, or about to, we can't optimize; make\r\n    // sure that we fetch it again if necessary.\r\n    if (self._phase === PHASE.FETCHING &&\r\n        ((self._currentlyFetching && self._currentlyFetching.has(id)) ||\r\n         self._needToFetch.has(id))) {\r\n      self._needToFetch.set(id, op.ts.toString());\r\n      return;\r\n    }\r\n\r\n    if (op.op === 'd') {\r\n      if (self._published.has(id) || (self._limit && self._unpublishedBuffer.has(id)))\r\n        self._removeMatching(id);\r\n    } else if (op.op === 'i') {\r\n      if (self._published.has(id))\r\n        throw new Error(\"insert found for already-existing ID in published\");\r\n      if (self._unpublishedBuffer && self._unpublishedBuffer.has(id))\r\n        throw new Error(\"insert found for already-existing ID in buffer\");\r\n\r\n      // XXX what if selector yields?  for now it can't but later it could have\r\n      // $where\r\n      if (self._matcher.documentMatches(op.o).result)\r\n        self._addMatching(op.o);\r\n    } else if (op.op === 'u') {\r\n      // Is this a modifier ($set/$unset, which may require us to poll the\r\n      // database to figure out if the whole document matches the selector) or a\r\n      // replacement (in which case we can just directly re-evaluate the\r\n      // selector)?\r\n      var isReplace = !_.has(op.o, '$set') && !_.has(op.o, '$unset');\r\n      // If this modifier modifies something inside an EJSON custom type (ie,\r\n      // anything with EJSON$), then we can't try to use\r\n      // LocalCollection._modify, since that just mutates the EJSON encoding,\r\n      // not the actual object.\r\n      var canDirectlyModifyDoc =\r\n            !isReplace && modifierCanBeDirectlyApplied(op.o);\r\n\r\n      var publishedBefore = self._published.has(id);\r\n      var bufferedBefore = self._limit && self._unpublishedBuffer.has(id);\r\n\r\n      if (isReplace) {\r\n        self._handleDoc(id, _.extend({_id: id}, op.o));\r\n      } else if ((publishedBefore || bufferedBefore) && canDirectlyModifyDoc) {\r\n        // Oh great, we actually know what the document is, so we can apply\r\n        // this directly.\r\n        var newDoc = self._published.has(id) ?\r\n          self._published.get(id) :\r\n          self._unpublishedBuffer.get(id);\r\n        newDoc = EJSON.clone(newDoc);\r\n\r\n        newDoc._id = id;\r\n        LocalCollection._modify(newDoc, op.o);\r\n        self._handleDoc(id, self._sharedProjectionFn(newDoc));\r\n      } else if (!canDirectlyModifyDoc ||\r\n                 self._matcher.canBecomeTrueByModifier(op.o) ||\r\n                 (self._sorter && self._sorter.affectedByModifier(op.o))) {\r\n        self._needToFetch.set(id, op.ts.toString());\r\n        if (self._phase === PHASE.STEADY)\r\n          self._fetchModifiedDocuments();\r\n      }\r\n    } else {\r\n      throw Error(\"XXX SURPRISING OPERATION: \" + op);\r\n    }\r\n  },\r\n  _runInitialQuery: function () {\r\n    var self = this;\r\n    if (self._stopped)\r\n      throw new Error(\"oplog stopped surprisingly early\");\r\n\r\n    self._runQuery();\r\n\r\n    if (self._stopped)\r\n      throw new Error(\"oplog stopped quite early\");\r\n    // Allow observeChanges calls to return. (After this, it's possible for\r\n    // stop() to be called.)\r\n    self._multiplexer.ready();\r\n\r\n    self._doneQuerying();\r\n  },\r\n\r\n  // In various circumstances, we may just want to stop processing the oplog and\r\n  // re-run the initial query, just as if we were a PollingObserveDriver.\r\n  //\r\n  // This function may not block, because it is called from an oplog entry\r\n  // handler.\r\n  //\r\n  // XXX We should call this when we detect that we've been in FETCHING for \"too\r\n  // long\".\r\n  //\r\n  // XXX We should call this when we detect Mongo failover (since that might\r\n  // mean that some of the oplog entries we have processed have been rolled\r\n  // back). The Node Mongo driver is in the middle of a bunch of huge\r\n  // refactorings, including the way that it notifies you when primary\r\n  // changes. Will put off implementing this until driver 1.4 is out.\r\n  _pollQuery: function () {\r\n    var self = this;\r\n\r\n    if (self._stopped)\r\n      return;\r\n\r\n    // Yay, we get to forget about all the things we thought we had to fetch.\r\n    self._needToFetch = new LocalCollection._IdMap;\r\n    self._currentlyFetching = null;\r\n    ++self._fetchGeneration;  // ignore any in-flight fetches\r\n    self._registerPhaseChange(PHASE.QUERYING);\r\n\r\n    // Defer so that we don't block.  We don't need finishIfNeedToPollQuery here\r\n    // because SwitchedToQuery is not called in QUERYING mode.\r\n    Meteor.defer(function () {\r\n      self._runQuery();\r\n      self._doneQuerying();\r\n    });\r\n  },\r\n\r\n  _runQuery: function () {\r\n    var self = this;\r\n    var newResults, newBuffer;\r\n\r\n    // This while loop is just to retry failures.\r\n    while (true) {\r\n      // If we've been stopped, we don't have to run anything any more.\r\n      if (self._stopped)\r\n        return;\r\n\r\n      newResults = new LocalCollection._IdMap;\r\n      newBuffer = new LocalCollection._IdMap;\r\n\r\n      // Query 2x documents as the half excluded from the original query will go\r\n      // into unpublished buffer to reduce additional Mongo lookups in cases\r\n      // when documents are removed from the published set and need a\r\n      // replacement.\r\n      // XXX needs more thought on non-zero skip\r\n      // XXX 2 is a \"magic number\" meaning there is an extra chunk of docs for\r\n      // buffer if such is needed.\r\n      var cursor = self._cursorForQuery({ limit: self._limit * 2 });\r\n      try {\r\n        cursor.forEach(function (doc, i) {\r\n          if (!self._limit || i < self._limit)\r\n            newResults.set(doc._id, doc);\r\n          else\r\n            newBuffer.set(doc._id, doc);\r\n        });\r\n        break;\r\n      } catch (e) {\r\n        // During failover (eg) if we get an exception we should log and retry\r\n        // instead of crashing.\r\n        Meteor._debug(\"Got exception while polling query: \" + e);\r\n        Meteor._sleepForMs(100);\r\n      }\r\n    }\r\n\r\n    if (self._stopped)\r\n      return;\r\n\r\n    self._publishNewResults(newResults, newBuffer);\r\n  },\r\n\r\n  // Transitions to QUERYING and runs another query, or (if already in QUERYING)\r\n  // ensures that we will query again later.\r\n  //\r\n  // This function may not block, because it is called from an oplog entry\r\n  // handler. However, if we were not already in the QUERYING phase, it throws\r\n  // an exception that is caught by the closest surrounding\r\n  // finishIfNeedToPollQuery call; this ensures that we don't continue running\r\n  // close that was designed for another phase inside PHASE.QUERYING.\r\n  //\r\n  // (It's also necessary whenever logic in this file yields to check that other\r\n  // phases haven't put us into QUERYING mode, though; eg,\r\n  // _fetchModifiedDocuments does this.)\r\n  _needToPollQuery: function () {\r\n    var self = this;\r\n    if (self._stopped)\r\n      return;\r\n\r\n    // If we're not already in the middle of a query, we can query now (possibly\r\n    // pausing FETCHING).\r\n    if (self._phase !== PHASE.QUERYING) {\r\n      self._pollQuery();\r\n      throw new SwitchedToQuery;\r\n    }\r\n\r\n    // We're currently in QUERYING. Set a flag to ensure that we run another\r\n    // query when we're done.\r\n    self._requeryWhenDoneThisQuery = true;\r\n  },\r\n\r\n  _doneQuerying: function () {\r\n    var self = this;\r\n\r\n    if (self._stopped)\r\n      return;\r\n    self._mongoHandle._oplogHandle.waitUntilCaughtUp();\r\n\r\n    if (self._stopped)\r\n      return;\r\n    if (self._phase !== PHASE.QUERYING)\r\n      throw Error(\"Phase unexpectedly \" + self._phase);\r\n\r\n    if (self._requeryWhenDoneThisQuery) {\r\n      self._requeryWhenDoneThisQuery = false;\r\n      self._pollQuery();\r\n    } else if (self._needToFetch.empty()) {\r\n      self._beSteady();\r\n    } else {\r\n      self._fetchModifiedDocuments();\r\n    }\r\n  },\r\n\r\n  _cursorForQuery: function (optionsOverwrite) {\r\n    var self = this;\r\n\r\n    // The query we run is almost the same as the cursor we are observing, with\r\n    // a few changes. We need to read all the fields that are relevant to the\r\n    // selector, not just the fields we are going to publish (that's the\r\n    // \"shared\" projection). And we don't want to apply any transform in the\r\n    // cursor, because observeChanges shouldn't use the transform.\r\n    var options = _.clone(self._cursorDescription.options);\r\n\r\n    // Allow the caller to modify the options. Useful to specify different skip\r\n    // and limit values.\r\n    _.extend(options, optionsOverwrite);\r\n\r\n    options.fields = self._sharedProjection;\r\n    delete options.transform;\r\n    // We are NOT deep cloning fields or selector here, which should be OK.\r\n    var description = new CursorDescription(\r\n      self._cursorDescription.collectionName,\r\n      self._cursorDescription.selector,\r\n      options);\r\n    return new Cursor(self._mongoHandle, description);\r\n  },\r\n\r\n\r\n  // Replace self._published with newResults (both are IdMaps), invoking observe\r\n  // callbacks on the multiplexer.\r\n  // Replace self._unpublishedBuffer with newBuffer.\r\n  //\r\n  // XXX This is very similar to LocalCollection._diffQueryUnorderedChanges. We\r\n  // should really: (a) Unify IdMap and OrderedDict into Unordered/OrderedDict (b)\r\n  // Rewrite diff.js to use these classes instead of arrays and objects.\r\n  _publishNewResults: function (newResults, newBuffer) {\r\n    var self = this;\r\n\r\n    // If the query is limited and there is a buffer, shut down so it doesn't\r\n    // stay in a way.\r\n    if (self._limit) {\r\n      self._unpublishedBuffer.clear();\r\n    }\r\n\r\n    // First remove anything that's gone. Be careful not to modify\r\n    // self._published while iterating over it.\r\n    var idsToRemove = [];\r\n    self._published.forEach(function (doc, id) {\r\n      if (!newResults.has(id))\r\n        idsToRemove.push(id);\r\n    });\r\n    _.each(idsToRemove, function (id) {\r\n      self._removePublished(id);\r\n    });\r\n\r\n    // Now do adds and changes.\r\n    // If self has a buffer and limit, the new fetched result will be\r\n    // limited correctly as the query has sort specifier.\r\n    newResults.forEach(function (doc, id) {\r\n      self._handleDoc(id, doc);\r\n    });\r\n\r\n    // Sanity-check that everything we tried to put into _published ended up\r\n    // there.\r\n    // XXX if this is slow, remove it later\r\n    if (self._published.size() !== newResults.size()) {\r\n      throw Error(\"failed to copy newResults into _published!\");\r\n    }\r\n    self._published.forEach(function (doc, id) {\r\n      if (!newResults.has(id))\r\n        throw Error(\"_published has a doc that newResults doesn't; \" + id);\r\n    });\r\n\r\n    // Finally, replace the buffer\r\n    newBuffer.forEach(function (doc, id) {\r\n      self._addBuffered(id, doc);\r\n    });\r\n\r\n    self._safeAppendToBuffer = newBuffer.size() < self._limit;\r\n  },\r\n\r\n  // This stop function is invoked from the onStop of the ObserveMultiplexer, so\r\n  // it shouldn't actually be possible to call it until the multiplexer is\r\n  // ready.\r\n  //\r\n  // It's important to check self._stopped after every call in this file that\r\n  // can yield!\r\n  stop: function () {\r\n    var self = this;\r\n    if (self._stopped)\r\n      return;\r\n    self._stopped = true;\r\n    _.each(self._stopHandles, function (handle) {\r\n      handle.stop();\r\n    });\r\n\r\n    // Note: we *don't* use multiplexer.onFlush here because this stop\r\n    // callback is actually invoked by the multiplexer itself when it has\r\n    // determined that there are no handles left. So nothing is actually going\r\n    // to get flushed (and it's probably not valid to call methods on the\r\n    // dying multiplexer).\r\n    _.each(self._writesToCommitWhenWeReachSteady, function (w) {\r\n      w.committed();\r\n    });\r\n    self._writesToCommitWhenWeReachSteady = null;\r\n\r\n    // Proactively drop references to potentially big things.\r\n    self._published = null;\r\n    self._unpublishedBuffer = null;\r\n    self._needToFetch = null;\r\n    self._currentlyFetching = null;\r\n    self._oplogEntryHandle = null;\r\n    self._listenersHandle = null;\r\n\r\n    Package.facts && Package.facts.Facts.incrementServerFact(\r\n      \"mongo-livedata\", \"observe-drivers-oplog\", -1);\r\n  },\r\n\r\n  _registerPhaseChange: function (phase) {\r\n    var self = this;\r\n    var now = new Date;\r\n\r\n    if (self._phase) {\r\n      var timeDiff = now - self._phaseStartTime;\r\n      Package.facts && Package.facts.Facts.incrementServerFact(\r\n        \"mongo-livedata\", \"time-spent-in-\" + self._phase + \"-phase\", timeDiff);\r\n    }\r\n\r\n    self._phase = phase;\r\n    self._phaseStartTime = now;\r\n  }\r\n});\r\n\r\n// Does our oplog tailing code support this cursor? For now, we are being very\r\n// conservative and allowing only simple queries with simple options.\r\n// (This is a \"static method\".)\r\nOplogObserveDriver.cursorSupported = function (cursorDescription, matcher) {\r\n  // First, check the options.\r\n  var options = cursorDescription.options;\r\n\r\n  // Did the user say no explicitly?\r\n  if (options._disableOplog)\r\n    return false;\r\n\r\n  // skip is not supported: to support it we would need to keep track of all\r\n  // \"skipped\" documents or at least their ids.\r\n  // limit w/o a sort specifier is not supported: current implementation needs a\r\n  // deterministic way to order documents.\r\n  if (options.skip || (options.limit && !options.sort)) return false;\r\n\r\n  // If a fields projection option is given check if it is supported by\r\n  // minimongo (some operators are not supported).\r\n  if (options.fields) {\r\n    try {\r\n      LocalCollection._checkSupportedProjection(options.fields);\r\n    } catch (e) {\r\n      if (e.name === \"MinimongoError\")\r\n        return false;\r\n      else\r\n        throw e;\r\n    }\r\n  }\r\n\r\n  // We don't allow the following selectors:\r\n  //   - $where (not confident that we provide the same JS environment\r\n  //             as Mongo, and can yield!)\r\n  //   - $near (has \"interesting\" properties in MongoDB, like the possibility\r\n  //            of returning an ID multiple times, though even polling maybe\r\n  //            have a bug there)\r\n  //           XXX: once we support it, we would need to think more on how we\r\n  //           initialize the comparators when we create the driver.\r\n  return !matcher.hasWhere() && !matcher.hasGeoQuery();\r\n};\r\n\r\nvar modifierCanBeDirectlyApplied = function (modifier) {\r\n  return _.all(modifier, function (fields, operation) {\r\n    return _.all(fields, function (value, field) {\r\n      return !/EJSON\\$/.test(field);\r\n    });\r\n  });\r\n};\r\n\r\nMongoInternals.OplogObserveDriver = OplogObserveDriver;\r\n","LocalCollectionDriver = function () {\r\n  var self = this;\r\n  self.noConnCollections = {};\r\n};\r\n\r\nvar ensureCollection = function (name, collections) {\r\n  if (!(name in collections))\r\n    collections[name] = new LocalCollection(name);\r\n  return collections[name];\r\n};\r\n\r\n_.extend(LocalCollectionDriver.prototype, {\r\n  open: function (name, conn) {\r\n    var self = this;\r\n    if (!name)\r\n      return new LocalCollection;\r\n    if (! conn) {\r\n      return ensureCollection(name, self.noConnCollections);\r\n    }\r\n    if (! conn._mongo_livedata_collections)\r\n      conn._mongo_livedata_collections = {};\r\n    // XXX is there a way to keep track of a connection's collections without\r\n    // dangling it off the connection object?\r\n    return ensureCollection(name, conn._mongo_livedata_collections);\r\n  }\r\n});\r\n\r\n// singleton\r\nLocalCollectionDriver = new LocalCollectionDriver;\r\n","MongoInternals.RemoteCollectionDriver = function (\r\n  mongo_url, options) {\r\n  var self = this;\r\n  self.mongo = new MongoConnection(mongo_url, options);\r\n};\r\n\r\n_.extend(MongoInternals.RemoteCollectionDriver.prototype, {\r\n  open: function (name) {\r\n    var self = this;\r\n    var ret = {};\r\n    _.each(\r\n      ['find', 'findOne', 'insert', 'update', , 'upsert',\r\n       'remove', '_ensureIndex', '_dropIndex', '_createCappedCollection',\r\n       'dropCollection'],\r\n      function (m) {\r\n        ret[m] = _.bind(self.mongo[m], self.mongo, name);\r\n      });\r\n    return ret;\r\n  }\r\n});\r\n\r\n\r\n// Create the singleton RemoteCollectionDriver only on demand, so we\r\n// only require Mongo configuration if it's actually used (eg, not if\r\n// you're only trying to receive data from a remote DDP server.)\r\nMongoInternals.defaultRemoteCollectionDriver = _.once(function () {\r\n  var mongoUrl;\r\n  var connectionOptions = {};\r\n\r\n  AppConfig.configurePackage(\"mongo-livedata\", function (config) {\r\n    // This will keep running if mongo gets reconfigured.  That's not ideal, but\r\n    // should be ok for now.\r\n    mongoUrl = config.url;\r\n\r\n    if (config.oplog)\r\n      connectionOptions.oplogUrl = config.oplog;\r\n  });\r\n\r\n  // XXX bad error since it could also be set directly in METEOR_DEPLOY_CONFIG\r\n  if (! mongoUrl)\r\n    throw new Error(\"MONGO_URL must be set in environment\");\r\n\r\n\r\n  return new MongoInternals.RemoteCollectionDriver(mongoUrl, connectionOptions);\r\n});\r\n","// options.connection, if given, is a LivedataClient or LivedataServer\r\n// XXX presently there is no way to destroy/clean up a Collection\r\n\r\nMeteor.Collection = function (name, options) {\r\n  var self = this;\r\n  if (! (self instanceof Meteor.Collection))\r\n    throw new Error('use \"new\" to construct a Meteor.Collection');\r\n\r\n  if (!name && (name !== null)) {\r\n    Meteor._debug(\"Warning: creating anonymous collection. It will not be \" +\r\n                  \"saved or synchronized over the network. (Pass null for \" +\r\n                  \"the collection name to turn off this warning.)\");\r\n    name = null;\r\n  }\r\n\r\n  if (name !== null && typeof name !== \"string\") {\r\n    throw new Error(\r\n      \"First argument to new Meteor.Collection must be a string or null\");\r\n  }\r\n\r\n  if (options && options.methods) {\r\n    // Backwards compatibility hack with original signature (which passed\r\n    // \"connection\" directly instead of in options. (Connections must have a \"methods\"\r\n    // method.)\r\n    // XXX remove before 1.0\r\n    options = {connection: options};\r\n  }\r\n  // Backwards compatibility: \"connection\" used to be called \"manager\".\r\n  if (options && options.manager && !options.connection) {\r\n    options.connection = options.manager;\r\n  }\r\n  options = _.extend({\r\n    connection: undefined,\r\n    idGeneration: 'STRING',\r\n    transform: null,\r\n    _driver: undefined,\r\n    _preventAutopublish: false\r\n  }, options);\r\n\r\n  switch (options.idGeneration) {\r\n  case 'MONGO':\r\n    self._makeNewID = function () {\r\n      var src = name ? DDP.randomStream('/collection/' + name) : Random;\r\n      return new Meteor.Collection.ObjectID(src.hexString(24));\r\n    };\r\n    break;\r\n  case 'STRING':\r\n  default:\r\n    self._makeNewID = function () {\r\n      var src = name ? DDP.randomStream('/collection/' + name) : Random;\r\n      return src.id();\r\n    };\r\n    break;\r\n  }\r\n\r\n  self._transform = LocalCollection.wrapTransform(options.transform);\r\n\r\n  if (! name || options.connection === null)\r\n    // note: nameless collections never have a connection\r\n    self._connection = null;\r\n  else if (options.connection)\r\n    self._connection = options.connection;\r\n  else if (Meteor.isClient)\r\n    self._connection = Meteor.connection;\r\n  else\r\n    self._connection = Meteor.server;\r\n\r\n  if (!options._driver) {\r\n    if (name && self._connection === Meteor.server &&\r\n        typeof MongoInternals !== \"undefined\" &&\r\n        MongoInternals.defaultRemoteCollectionDriver) {\r\n      options._driver = MongoInternals.defaultRemoteCollectionDriver();\r\n    } else {\r\n      options._driver = LocalCollectionDriver;\r\n    }\r\n  }\r\n\r\n  self._collection = options._driver.open(name, self._connection);\r\n  self._name = name;\r\n\r\n  if (self._connection && self._connection.registerStore) {\r\n    // OK, we're going to be a slave, replicating some remote\r\n    // database, except possibly with some temporary divergence while\r\n    // we have unacknowledged RPC's.\r\n    var ok = self._connection.registerStore(name, {\r\n      // Called at the beginning of a batch of updates. batchSize is the number\r\n      // of update calls to expect.\r\n      //\r\n      // XXX This interface is pretty janky. reset probably ought to go back to\r\n      // being its own function, and callers shouldn't have to calculate\r\n      // batchSize. The optimization of not calling pause/remove should be\r\n      // delayed until later: the first call to update() should buffer its\r\n      // message, and then we can either directly apply it at endUpdate time if\r\n      // it was the only update, or do pauseObservers/apply/apply at the next\r\n      // update() if there's another one.\r\n      beginUpdate: function (batchSize, reset) {\r\n        // pause observers so users don't see flicker when updating several\r\n        // objects at once (including the post-reconnect reset-and-reapply\r\n        // stage), and so that a re-sorting of a query can take advantage of the\r\n        // full _diffQuery moved calculation instead of applying change one at a\r\n        // time.\r\n        if (batchSize > 1 || reset)\r\n          self._collection.pauseObservers();\r\n\r\n        if (reset)\r\n          self._collection.remove({});\r\n      },\r\n\r\n      // Apply an update.\r\n      // XXX better specify this interface (not in terms of a wire message)?\r\n      update: function (msg) {\r\n        var mongoId = LocalCollection._idParse(msg.id);\r\n        var doc = self._collection.findOne(mongoId);\r\n\r\n        // Is this a \"replace the whole doc\" message coming from the quiescence\r\n        // of method writes to an object? (Note that 'undefined' is a valid\r\n        // value meaning \"remove it\".)\r\n        if (msg.msg === 'replace') {\r\n          var replace = msg.replace;\r\n          if (!replace) {\r\n            if (doc)\r\n              self._collection.remove(mongoId);\r\n          } else if (!doc) {\r\n            self._collection.insert(replace);\r\n          } else {\r\n            // XXX check that replace has no $ ops\r\n            self._collection.update(mongoId, replace);\r\n          }\r\n          return;\r\n        } else if (msg.msg === 'added') {\r\n          if (doc) {\r\n            throw new Error(\"Expected not to find a document already present for an add\");\r\n          }\r\n          self._collection.insert(_.extend({_id: mongoId}, msg.fields));\r\n        } else if (msg.msg === 'removed') {\r\n          if (!doc)\r\n            throw new Error(\"Expected to find a document already present for removed\");\r\n          self._collection.remove(mongoId);\r\n        } else if (msg.msg === 'changed') {\r\n          if (!doc)\r\n            throw new Error(\"Expected to find a document to change\");\r\n          if (!_.isEmpty(msg.fields)) {\r\n            var modifier = {};\r\n            _.each(msg.fields, function (value, key) {\r\n              if (value === undefined) {\r\n                if (!modifier.$unset)\r\n                  modifier.$unset = {};\r\n                modifier.$unset[key] = 1;\r\n              } else {\r\n                if (!modifier.$set)\r\n                  modifier.$set = {};\r\n                modifier.$set[key] = value;\r\n              }\r\n            });\r\n            self._collection.update(mongoId, modifier);\r\n          }\r\n        } else {\r\n          throw new Error(\"I don't know how to deal with this message\");\r\n        }\r\n\r\n      },\r\n\r\n      // Called at the end of a batch of updates.\r\n      endUpdate: function () {\r\n        self._collection.resumeObservers();\r\n      },\r\n\r\n      // Called around method stub invocations to capture the original versions\r\n      // of modified documents.\r\n      saveOriginals: function () {\r\n        self._collection.saveOriginals();\r\n      },\r\n      retrieveOriginals: function () {\r\n        return self._collection.retrieveOriginals();\r\n      }\r\n    });\r\n\r\n    if (!ok)\r\n      throw new Error(\"There is already a collection named '\" + name + \"'\");\r\n  }\r\n\r\n  self._defineMutationMethods();\r\n\r\n  // autopublish\r\n  if (Package.autopublish && !options._preventAutopublish && self._connection\r\n      && self._connection.publish) {\r\n    self._connection.publish(null, function () {\r\n      return self.find();\r\n    }, {is_auto: true});\r\n  }\r\n};\r\n\r\n///\r\n/// Main collection API\r\n///\r\n\r\n\r\n_.extend(Meteor.Collection.prototype, {\r\n\r\n  _getFindSelector: function (args) {\r\n    if (args.length == 0)\r\n      return {};\r\n    else\r\n      return args[0];\r\n  },\r\n\r\n  _getFindOptions: function (args) {\r\n    var self = this;\r\n    if (args.length < 2) {\r\n      return { transform: self._transform };\r\n    } else {\r\n      check(args[1], Match.Optional(Match.ObjectIncluding({\r\n        fields: Match.Optional(Match.OneOf(Object, undefined)),\r\n        sort: Match.Optional(Match.OneOf(Object, Array, undefined)),\r\n        limit: Match.Optional(Match.OneOf(Number, undefined)),\r\n        skip: Match.Optional(Match.OneOf(Number, undefined))\r\n     })));\r\n\r\n      return _.extend({\r\n        transform: self._transform\r\n      }, args[1]);\r\n    }\r\n  },\r\n\r\n  find: function (/* selector, options */) {\r\n    // Collection.find() (return all docs) behaves differently\r\n    // from Collection.find(undefined) (return 0 docs).  so be\r\n    // careful about the length of arguments.\r\n    var self = this;\r\n    var argArray = _.toArray(arguments);\r\n    return self._collection.find(self._getFindSelector(argArray),\r\n                                 self._getFindOptions(argArray));\r\n  },\r\n\r\n  findOne: function (/* selector, options */) {\r\n    var self = this;\r\n    var argArray = _.toArray(arguments);\r\n    return self._collection.findOne(self._getFindSelector(argArray),\r\n                                    self._getFindOptions(argArray));\r\n  }\r\n\r\n});\r\n\r\nMeteor.Collection._publishCursor = function (cursor, sub, collection) {\r\n  var observeHandle = cursor.observeChanges({\r\n    added: function (id, fields) {\r\n      sub.added(collection, id, fields);\r\n    },\r\n    changed: function (id, fields) {\r\n      sub.changed(collection, id, fields);\r\n    },\r\n    removed: function (id) {\r\n      sub.removed(collection, id);\r\n    }\r\n  });\r\n\r\n  // We don't call sub.ready() here: it gets called in livedata_server, after\r\n  // possibly calling _publishCursor on multiple returned cursors.\r\n\r\n  // register stop callback (expects lambda w/ no args).\r\n  sub.onStop(function () {observeHandle.stop();});\r\n};\r\n\r\n// protect against dangerous selectors.  falsey and {_id: falsey} are both\r\n// likely programmer error, and not what you want, particularly for destructive\r\n// operations.  JS regexps don't serialize over DDP but can be trivially\r\n// replaced by $regex.\r\nMeteor.Collection._rewriteSelector = function (selector) {\r\n  // shorthand -- scalars match _id\r\n  if (LocalCollection._selectorIsId(selector))\r\n    selector = {_id: selector};\r\n\r\n  if (!selector || (('_id' in selector) && !selector._id))\r\n    // can't match anything\r\n    return {_id: Random.id()};\r\n\r\n  var ret = {};\r\n  _.each(selector, function (value, key) {\r\n    // Mongo supports both {field: /foo/} and {field: {$regex: /foo/}}\r\n    if (value instanceof RegExp) {\r\n      ret[key] = convertRegexpToMongoSelector(value);\r\n    } else if (value && value.$regex instanceof RegExp) {\r\n      ret[key] = convertRegexpToMongoSelector(value.$regex);\r\n      // if value is {$regex: /foo/, $options: ...} then $options\r\n      // override the ones set on $regex.\r\n      if (value.$options !== undefined)\r\n        ret[key].$options = value.$options;\r\n    }\r\n    else if (_.contains(['$or','$and','$nor'], key)) {\r\n      // Translate lower levels of $and/$or/$nor\r\n      ret[key] = _.map(value, function (v) {\r\n        return Meteor.Collection._rewriteSelector(v);\r\n      });\r\n    } else {\r\n      ret[key] = value;\r\n    }\r\n  });\r\n  return ret;\r\n};\r\n\r\n// convert a JS RegExp object to a Mongo {$regex: ..., $options: ...}\r\n// selector\r\nvar convertRegexpToMongoSelector = function (regexp) {\r\n  check(regexp, RegExp); // safety belt\r\n\r\n  var selector = {$regex: regexp.source};\r\n  var regexOptions = '';\r\n  // JS RegExp objects support 'i', 'm', and 'g'. Mongo regex $options\r\n  // support 'i', 'm', 'x', and 's'. So we support 'i' and 'm' here.\r\n  if (regexp.ignoreCase)\r\n    regexOptions += 'i';\r\n  if (regexp.multiline)\r\n    regexOptions += 'm';\r\n  if (regexOptions)\r\n    selector.$options = regexOptions;\r\n\r\n  return selector;\r\n};\r\n\r\nvar throwIfSelectorIsNotId = function (selector, methodName) {\r\n  if (!LocalCollection._selectorIsIdPerhapsAsObject(selector)) {\r\n    throw new Meteor.Error(\r\n      403, \"Not permitted. Untrusted code may only \" + methodName +\r\n        \" documents by ID.\");\r\n  }\r\n};\r\n\r\n// 'insert' immediately returns the inserted document's new _id.\r\n// The others return values immediately if you are in a stub, an in-memory\r\n// unmanaged collection, or a mongo-backed collection and you don't pass a\r\n// callback. 'update' and 'remove' return the number of affected\r\n// documents. 'upsert' returns an object with keys 'numberAffected' and, if an\r\n// insert happened, 'insertedId'.\r\n//\r\n// Otherwise, the semantics are exactly like other methods: they take\r\n// a callback as an optional last argument; if no callback is\r\n// provided, they block until the operation is complete, and throw an\r\n// exception if it fails; if a callback is provided, then they don't\r\n// necessarily block, and they call the callback when they finish with error and\r\n// result arguments.  (The insert method provides the document ID as its result;\r\n// update and remove provide the number of affected docs as the result; upsert\r\n// provides an object with numberAffected and maybe insertedId.)\r\n//\r\n// On the client, blocking is impossible, so if a callback\r\n// isn't provided, they just return immediately and any error\r\n// information is lost.\r\n//\r\n// There's one more tweak. On the client, if you don't provide a\r\n// callback, then if there is an error, a message will be logged with\r\n// Meteor._debug.\r\n//\r\n// The intent (though this is actually determined by the underlying\r\n// drivers) is that the operations should be done synchronously, not\r\n// generating their result until the database has acknowledged\r\n// them. In the future maybe we should provide a flag to turn this\r\n// off.\r\n_.each([\"insert\", \"update\", \"remove\"], function (name) {\r\n  Meteor.Collection.prototype[name] = function (/* arguments */) {\r\n    var self = this;\r\n    var args = _.toArray(arguments);\r\n    var callback;\r\n    var insertId;\r\n    var ret;\r\n\r\n    if (args.length && args[args.length - 1] instanceof Function)\r\n      callback = args.pop();\r\n\r\n    if (name === \"insert\") {\r\n      if (!args.length)\r\n        throw new Error(\"insert requires an argument\");\r\n      // shallow-copy the document and generate an ID\r\n      args[0] = _.extend({}, args[0]);\r\n      if ('_id' in args[0]) {\r\n        insertId = args[0]._id;\r\n        if (!insertId || !(typeof insertId === 'string'\r\n              || insertId instanceof Meteor.Collection.ObjectID))\r\n          throw new Error(\"Meteor requires document _id fields to be non-empty strings or ObjectIDs\");\r\n      } else {\r\n        var generateId = true;\r\n        // Don't generate the id if we're the client and the 'outermost' call\r\n        // This optimization saves us passing both the randomSeed and the id\r\n        // Passing both is redundant.\r\n        if (self._connection && self._connection !== Meteor.server) {\r\n          var enclosing = DDP._CurrentInvocation.get();\r\n          if (!enclosing) {\r\n            generateId = false;\r\n          }\r\n        }\r\n        if (generateId) {\r\n          insertId = args[0]._id = self._makeNewID();\r\n        }\r\n      }\r\n    } else {\r\n      args[0] = Meteor.Collection._rewriteSelector(args[0]);\r\n\r\n      if (name === \"update\") {\r\n        // Mutate args but copy the original options object. We need to add\r\n        // insertedId to options, but don't want to mutate the caller's options\r\n        // object. We need to mutate `args` because we pass `args` into the\r\n        // driver below.\r\n        var options = args[2] = _.clone(args[2]) || {};\r\n        if (options && typeof options !== \"function\" && options.upsert) {\r\n          // set `insertedId` if absent.  `insertedId` is a Meteor extension.\r\n          if (options.insertedId) {\r\n            if (!(typeof options.insertedId === 'string'\r\n                  || options.insertedId instanceof Meteor.Collection.ObjectID))\r\n              throw new Error(\"insertedId must be string or ObjectID\");\r\n          } else {\r\n            options.insertedId = self._makeNewID();\r\n          }\r\n        }\r\n      }\r\n    }\r\n\r\n    // On inserts, always return the id that we generated; on all other\r\n    // operations, just return the result from the collection.\r\n    var chooseReturnValueFromCollectionResult = function (result) {\r\n      if (name === \"insert\") {\r\n        if (!insertId && result) {\r\n          insertId = result;\r\n        }\r\n        return insertId;\r\n      } else {\r\n        return result;\r\n      }\r\n    };\r\n\r\n    var wrappedCallback;\r\n    if (callback) {\r\n      wrappedCallback = function (error, result) {\r\n        callback(error, ! error && chooseReturnValueFromCollectionResult(result));\r\n      };\r\n    }\r\n\r\n    if (self._connection && self._connection !== Meteor.server) {\r\n      // just remote to another endpoint, propagate return value or\r\n      // exception.\r\n\r\n      var enclosing = DDP._CurrentInvocation.get();\r\n      var alreadyInSimulation = enclosing && enclosing.isSimulation;\r\n\r\n      if (Meteor.isClient && !wrappedCallback && ! alreadyInSimulation) {\r\n        // Client can't block, so it can't report errors by exception,\r\n        // only by callback. If they forget the callback, give them a\r\n        // default one that logs the error, so they aren't totally\r\n        // baffled if their writes don't work because their database is\r\n        // down.\r\n        // Don't give a default callback in simulation, because inside stubs we\r\n        // want to return the results from the local collection immediately and\r\n        // not force a callback.\r\n        wrappedCallback = function (err) {\r\n          if (err)\r\n            Meteor._debug(name + \" failed: \" + (err.reason || err.stack));\r\n        };\r\n      }\r\n\r\n      if (!alreadyInSimulation && name !== \"insert\") {\r\n        // If we're about to actually send an RPC, we should throw an error if\r\n        // this is a non-ID selector, because the mutation methods only allow\r\n        // single-ID selectors. (If we don't throw here, we'll see flicker.)\r\n        throwIfSelectorIsNotId(args[0], name);\r\n      }\r\n\r\n      ret = chooseReturnValueFromCollectionResult(\r\n        self._connection.apply(self._prefix + name, args, {returnStubValue: true}, wrappedCallback)\r\n      );\r\n\r\n    } else {\r\n      // it's my collection.  descend into the collection object\r\n      // and propagate any exception.\r\n      args.push(wrappedCallback);\r\n      try {\r\n        // If the user provided a callback and the collection implements this\r\n        // operation asynchronously, then queryRet will be undefined, and the\r\n        // result will be returned through the callback instead.\r\n        var queryRet = self._collection[name].apply(self._collection, args);\r\n        ret = chooseReturnValueFromCollectionResult(queryRet);\r\n      } catch (e) {\r\n        if (callback) {\r\n          callback(e);\r\n          return null;\r\n        }\r\n        throw e;\r\n      }\r\n    }\r\n\r\n    // both sync and async, unless we threw an exception, return ret\r\n    // (new document ID for insert, num affected for update/remove, object with\r\n    // numberAffected and maybe insertedId for upsert).\r\n    return ret;\r\n  };\r\n});\r\n\r\nMeteor.Collection.prototype.upsert = function (selector, modifier,\r\n                                               options, callback) {\r\n  var self = this;\r\n  if (! callback && typeof options === \"function\") {\r\n    callback = options;\r\n    options = {};\r\n  }\r\n  return self.update(selector, modifier,\r\n              _.extend({}, options, { _returnObject: true, upsert: true }),\r\n              callback);\r\n};\r\n\r\n// We'll actually design an index API later. For now, we just pass through to\r\n// Mongo's, but make it synchronous.\r\nMeteor.Collection.prototype._ensureIndex = function (index, options) {\r\n  var self = this;\r\n  if (!self._collection._ensureIndex)\r\n    throw new Error(\"Can only call _ensureIndex on server collections\");\r\n  self._collection._ensureIndex(index, options);\r\n};\r\nMeteor.Collection.prototype._dropIndex = function (index) {\r\n  var self = this;\r\n  if (!self._collection._dropIndex)\r\n    throw new Error(\"Can only call _dropIndex on server collections\");\r\n  self._collection._dropIndex(index);\r\n};\r\nMeteor.Collection.prototype._dropCollection = function () {\r\n  var self = this;\r\n  if (!self._collection.dropCollection)\r\n    throw new Error(\"Can only call _dropCollection on server collections\");\r\n  self._collection.dropCollection();\r\n};\r\nMeteor.Collection.prototype._createCappedCollection = function (byteSize) {\r\n  var self = this;\r\n  if (!self._collection._createCappedCollection)\r\n    throw new Error(\"Can only call _createCappedCollection on server collections\");\r\n  self._collection._createCappedCollection(byteSize);\r\n};\r\n\r\nMeteor.Collection.ObjectID = LocalCollection._ObjectID;\r\n\r\n///\r\n/// Remote methods and access control.\r\n///\r\n\r\n// Restrict default mutators on collection. allow() and deny() take the\r\n// same options:\r\n//\r\n// options.insert {Function(userId, doc)}\r\n//   return true to allow/deny adding this document\r\n//\r\n// options.update {Function(userId, docs, fields, modifier)}\r\n//   return true to allow/deny updating these documents.\r\n//   `fields` is passed as an array of fields that are to be modified\r\n//\r\n// options.remove {Function(userId, docs)}\r\n//   return true to allow/deny removing these documents\r\n//\r\n// options.fetch {Array}\r\n//   Fields to fetch for these validators. If any call to allow or deny\r\n//   does not have this option then all fields are loaded.\r\n//\r\n// allow and deny can be called multiple times. The validators are\r\n// evaluated as follows:\r\n// - If neither deny() nor allow() has been called on the collection,\r\n//   then the request is allowed if and only if the \"insecure\" smart\r\n//   package is in use.\r\n// - Otherwise, if any deny() function returns true, the request is denied.\r\n// - Otherwise, if any allow() function returns true, the request is allowed.\r\n// - Otherwise, the request is denied.\r\n//\r\n// Meteor may call your deny() and allow() functions in any order, and may not\r\n// call all of them if it is able to make a decision without calling them all\r\n// (so don't include side effects).\r\n\r\n(function () {\r\n  var addValidator = function(allowOrDeny, options) {\r\n    // validate keys\r\n    var VALID_KEYS = ['insert', 'update', 'remove', 'fetch', 'transform'];\r\n    _.each(_.keys(options), function (key) {\r\n      if (!_.contains(VALID_KEYS, key))\r\n        throw new Error(allowOrDeny + \": Invalid key: \" + key);\r\n    });\r\n\r\n    var self = this;\r\n    self._restricted = true;\r\n\r\n    _.each(['insert', 'update', 'remove'], function (name) {\r\n      if (options[name]) {\r\n        if (!(options[name] instanceof Function)) {\r\n          throw new Error(allowOrDeny + \": Value for `\" + name + \"` must be a function\");\r\n        }\r\n\r\n        // If the transform is specified at all (including as 'null') in this\r\n        // call, then take that; otherwise, take the transform from the\r\n        // collection.\r\n        if (options.transform === undefined) {\r\n          options[name].transform = self._transform;  // already wrapped\r\n        } else {\r\n          options[name].transform = LocalCollection.wrapTransform(\r\n            options.transform);\r\n        }\r\n\r\n        self._validators[name][allowOrDeny].push(options[name]);\r\n      }\r\n    });\r\n\r\n    // Only update the fetch fields if we're passed things that affect\r\n    // fetching. This way allow({}) and allow({insert: f}) don't result in\r\n    // setting fetchAllFields\r\n    if (options.update || options.remove || options.fetch) {\r\n      if (options.fetch && !(options.fetch instanceof Array)) {\r\n        throw new Error(allowOrDeny + \": Value for `fetch` must be an array\");\r\n      }\r\n      self._updateFetch(options.fetch);\r\n    }\r\n  };\r\n\r\n  Meteor.Collection.prototype.allow = function(options) {\r\n    addValidator.call(this, 'allow', options);\r\n  };\r\n  Meteor.Collection.prototype.deny = function(options) {\r\n    addValidator.call(this, 'deny', options);\r\n  };\r\n})();\r\n\r\n\r\nMeteor.Collection.prototype._defineMutationMethods = function() {\r\n  var self = this;\r\n\r\n  // set to true once we call any allow or deny methods. If true, use\r\n  // allow/deny semantics. If false, use insecure mode semantics.\r\n  self._restricted = false;\r\n\r\n  // Insecure mode (default to allowing writes). Defaults to 'undefined' which\r\n  // means insecure iff the insecure package is loaded. This property can be\r\n  // overriden by tests or packages wishing to change insecure mode behavior of\r\n  // their collections.\r\n  self._insecure = undefined;\r\n\r\n  self._validators = {\r\n    insert: {allow: [], deny: []},\r\n    update: {allow: [], deny: []},\r\n    remove: {allow: [], deny: []},\r\n    upsert: {allow: [], deny: []}, // dummy arrays; can't set these!\r\n    fetch: [],\r\n    fetchAllFields: false\r\n  };\r\n\r\n  if (!self._name)\r\n    return; // anonymous collection\r\n\r\n  // XXX Think about method namespacing. Maybe methods should be\r\n  // \"Meteor:Mongo:insert/NAME\"?\r\n  self._prefix = '/' + self._name + '/';\r\n\r\n  // mutation methods\r\n  if (self._connection) {\r\n    var m = {};\r\n\r\n    _.each(['insert', 'update', 'remove'], function (method) {\r\n      m[self._prefix + method] = function (/* ... */) {\r\n        // All the methods do their own validation, instead of using check().\r\n        check(arguments, [Match.Any]);\r\n        var args = _.toArray(arguments);\r\n        try {\r\n          // For an insert, if the client didn't specify an _id, generate one\r\n          // now; because this uses DDP.randomStream, it will be consistent with\r\n          // what the client generated. We generate it now rather than later so\r\n          // that if (eg) an allow/deny rule does an insert to the same\r\n          // collection (not that it really should), the generated _id will\r\n          // still be the first use of the stream and will be consistent.\r\n          //\r\n          // However, we don't actually stick the _id onto the document yet,\r\n          // because we want allow/deny rules to be able to differentiate\r\n          // between arbitrary client-specified _id fields and merely\r\n          // client-controlled-via-randomSeed fields.\r\n          var generatedId = null;\r\n          if (method === \"insert\" && !_.has(args[0], '_id')) {\r\n            generatedId = self._makeNewID();\r\n          }\r\n\r\n          if (this.isSimulation) {\r\n            // In a client simulation, you can do any mutation (even with a\r\n            // complex selector).\r\n            if (generatedId !== null)\r\n              args[0]._id = generatedId;\r\n            return self._collection[method].apply(\r\n              self._collection, args);\r\n          }\r\n\r\n          // This is the server receiving a method call from the client.\r\n\r\n          // We don't allow arbitrary selectors in mutations from the client: only\r\n          // single-ID selectors.\r\n          if (method !== 'insert')\r\n            throwIfSelectorIsNotId(args[0], method);\r\n\r\n          if (self._restricted) {\r\n            // short circuit if there is no way it will pass.\r\n            if (self._validators[method].allow.length === 0) {\r\n              throw new Meteor.Error(\r\n                403, \"Access denied. No allow validators set on restricted \" +\r\n                  \"collection for method '\" + method + \"'.\");\r\n            }\r\n\r\n            var validatedMethodName =\r\n                  '_validated' + method.charAt(0).toUpperCase() + method.slice(1);\r\n            args.unshift(this.userId);\r\n            method === 'insert' && args.push(generatedId);\r\n            return self[validatedMethodName].apply(self, args);\r\n          } else if (self._isInsecure()) {\r\n            if (generatedId !== null)\r\n              args[0]._id = generatedId;\r\n            // In insecure mode, allow any mutation (with a simple selector).\r\n            return self._collection[method].apply(self._collection, args);\r\n          } else {\r\n            // In secure mode, if we haven't called allow or deny, then nothing\r\n            // is permitted.\r\n            throw new Meteor.Error(403, \"Access denied\");\r\n          }\r\n        } catch (e) {\r\n          if (e.name === 'MongoError' || e.name === 'MinimongoError') {\r\n            throw new Meteor.Error(409, e.toString());\r\n          } else {\r\n            throw e;\r\n          }\r\n        }\r\n      };\r\n    });\r\n    // Minimongo on the server gets no stubs; instead, by default\r\n    // it wait()s until its result is ready, yielding.\r\n    // This matches the behavior of macromongo on the server better.\r\n    if (Meteor.isClient || self._connection === Meteor.server)\r\n      self._connection.methods(m);\r\n  }\r\n};\r\n\r\n\r\nMeteor.Collection.prototype._updateFetch = function (fields) {\r\n  var self = this;\r\n\r\n  if (!self._validators.fetchAllFields) {\r\n    if (fields) {\r\n      self._validators.fetch = _.union(self._validators.fetch, fields);\r\n    } else {\r\n      self._validators.fetchAllFields = true;\r\n      // clear fetch just to make sure we don't accidentally read it\r\n      self._validators.fetch = null;\r\n    }\r\n  }\r\n};\r\n\r\nMeteor.Collection.prototype._isInsecure = function () {\r\n  var self = this;\r\n  if (self._insecure === undefined)\r\n    return !!Package.insecure;\r\n  return self._insecure;\r\n};\r\n\r\nvar docToValidate = function (validator, doc, generatedId) {\r\n  var ret = doc;\r\n  if (validator.transform) {\r\n    ret = EJSON.clone(doc);\r\n    // If you set a server-side transform on your collection, then you don't get\r\n    // to tell the difference between \"client specified the ID\" and \"server\r\n    // generated the ID\", because transforms expect to get _id.  If you want to\r\n    // do that check, you can do it with a specific\r\n    // `C.allow({insert: f, transform: null})` validator.\r\n    if (generatedId !== null) {\r\n      ret._id = generatedId;\r\n    }\r\n    ret = validator.transform(ret);\r\n  }\r\n  return ret;\r\n};\r\n\r\nMeteor.Collection.prototype._validatedInsert = function (userId, doc,\r\n                                                         generatedId) {\r\n  var self = this;\r\n\r\n  // call user validators.\r\n  // Any deny returns true means denied.\r\n  if (_.any(self._validators.insert.deny, function(validator) {\r\n    return validator(userId, docToValidate(validator, doc, generatedId));\r\n  })) {\r\n    throw new Meteor.Error(403, \"Access denied\");\r\n  }\r\n  // Any allow returns true means proceed. Throw error if they all fail.\r\n  if (_.all(self._validators.insert.allow, function(validator) {\r\n    return !validator(userId, docToValidate(validator, doc, generatedId));\r\n  })) {\r\n    throw new Meteor.Error(403, \"Access denied\");\r\n  }\r\n\r\n  // If we generated an ID above, insert it now: after the validation, but\r\n  // before actually inserting.\r\n  if (generatedId !== null)\r\n    doc._id = generatedId;\r\n\r\n  self._collection.insert.call(self._collection, doc);\r\n};\r\n\r\nvar transformDoc = function (validator, doc) {\r\n  if (validator.transform)\r\n    return validator.transform(doc);\r\n  return doc;\r\n};\r\n\r\n// Simulate a mongo `update` operation while validating that the access\r\n// control rules set by calls to `allow/deny` are satisfied. If all\r\n// pass, rewrite the mongo operation to use $in to set the list of\r\n// document ids to change ##ValidatedChange\r\nMeteor.Collection.prototype._validatedUpdate = function(\r\n    userId, selector, mutator, options) {\r\n  var self = this;\r\n\r\n  options = options || {};\r\n\r\n  if (!LocalCollection._selectorIsIdPerhapsAsObject(selector))\r\n    throw new Error(\"validated update should be of a single ID\");\r\n\r\n  // We don't support upserts because they don't fit nicely into allow/deny\r\n  // rules.\r\n  if (options.upsert)\r\n    throw new Meteor.Error(403, \"Access denied. Upserts not \" +\r\n                           \"allowed in a restricted collection.\");\r\n\r\n  // compute modified fields\r\n  var fields = [];\r\n  _.each(mutator, function (params, op) {\r\n    if (op.charAt(0) !== '$') {\r\n      throw new Meteor.Error(\r\n        403, \"Access denied. In a restricted collection you can only update documents, not replace them. Use a Mongo update operator, such as '$set'.\");\r\n    } else if (!_.has(ALLOWED_UPDATE_OPERATIONS, op)) {\r\n      throw new Meteor.Error(\r\n        403, \"Access denied. Operator \" + op + \" not allowed in a restricted collection.\");\r\n    } else {\r\n      _.each(_.keys(params), function (field) {\r\n        // treat dotted fields as if they are replacing their\r\n        // top-level part\r\n        if (field.indexOf('.') !== -1)\r\n          field = field.substring(0, field.indexOf('.'));\r\n\r\n        // record the field we are trying to change\r\n        if (!_.contains(fields, field))\r\n          fields.push(field);\r\n      });\r\n    }\r\n  });\r\n\r\n  var findOptions = {transform: null};\r\n  if (!self._validators.fetchAllFields) {\r\n    findOptions.fields = {};\r\n    _.each(self._validators.fetch, function(fieldName) {\r\n      findOptions.fields[fieldName] = 1;\r\n    });\r\n  }\r\n\r\n  var doc = self._collection.findOne(selector, findOptions);\r\n  if (!doc)  // none satisfied!\r\n    return 0;\r\n\r\n  var factoriedDoc;\r\n\r\n  // call user validators.\r\n  // Any deny returns true means denied.\r\n  if (_.any(self._validators.update.deny, function(validator) {\r\n    if (!factoriedDoc)\r\n      factoriedDoc = transformDoc(validator, doc);\r\n    return validator(userId,\r\n                     factoriedDoc,\r\n                     fields,\r\n                     mutator);\r\n  })) {\r\n    throw new Meteor.Error(403, \"Access denied\");\r\n  }\r\n  // Any allow returns true means proceed. Throw error if they all fail.\r\n  if (_.all(self._validators.update.allow, function(validator) {\r\n    if (!factoriedDoc)\r\n      factoriedDoc = transformDoc(validator, doc);\r\n    return !validator(userId,\r\n                      factoriedDoc,\r\n                      fields,\r\n                      mutator);\r\n  })) {\r\n    throw new Meteor.Error(403, \"Access denied\");\r\n  }\r\n\r\n  // Back when we supported arbitrary client-provided selectors, we actually\r\n  // rewrote the selector to include an _id clause before passing to Mongo to\r\n  // avoid races, but since selector is guaranteed to already just be an ID, we\r\n  // don't have to any more.\r\n\r\n  return self._collection.update.call(\r\n    self._collection, selector, mutator, options);\r\n};\r\n\r\n// Only allow these operations in validated updates. Specifically\r\n// whitelist operations, rather than blacklist, so new complex\r\n// operations that are added aren't automatically allowed. A complex\r\n// operation is one that does more than just modify its target\r\n// field. For now this contains all update operations except '$rename'.\r\n// http://docs.mongodb.org/manual/reference/operators/#update\r\nvar ALLOWED_UPDATE_OPERATIONS = {\r\n  $inc:1, $set:1, $unset:1, $addToSet:1, $pop:1, $pullAll:1, $pull:1,\r\n  $pushAll:1, $push:1, $bit:1\r\n};\r\n\r\n// Simulate a mongo `remove` operation while validating access control\r\n// rules. See #ValidatedChange\r\nMeteor.Collection.prototype._validatedRemove = function(userId, selector) {\r\n  var self = this;\r\n\r\n  var findOptions = {transform: null};\r\n  if (!self._validators.fetchAllFields) {\r\n    findOptions.fields = {};\r\n    _.each(self._validators.fetch, function(fieldName) {\r\n      findOptions.fields[fieldName] = 1;\r\n    });\r\n  }\r\n\r\n  var doc = self._collection.findOne(selector, findOptions);\r\n  if (!doc)\r\n    return 0;\r\n\r\n  // call user validators.\r\n  // Any deny returns true means denied.\r\n  if (_.any(self._validators.remove.deny, function(validator) {\r\n    return validator(userId, transformDoc(validator, doc));\r\n  })) {\r\n    throw new Meteor.Error(403, \"Access denied\");\r\n  }\r\n  // Any allow returns true means proceed. Throw error if they all fail.\r\n  if (_.all(self._validators.remove.allow, function(validator) {\r\n    return !validator(userId, transformDoc(validator, doc));\r\n  })) {\r\n    throw new Meteor.Error(403, \"Access denied\");\r\n  }\r\n\r\n  // Back when we supported arbitrary client-provided selectors, we actually\r\n  // rewrote the selector to {_id: {$in: [ids that we found]}} before passing to\r\n  // Mongo to avoid races, but since selector is guaranteed to already just be\r\n  // an ID, we don't have to any more.\r\n\r\n  return self._collection.remove.call(self._collection, selector);\r\n};\r\n"]}